<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; 7.1 이 장의 목표 – Modern Statistics for Modern Biology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./08-chap.html" rel="next">
<link href="./06-chap.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7bf12d62aa84b4fa538b342f1416a45b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="msmb.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07-chap.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">7.1 이 장의 목표</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modern Statistics for Modern Biology</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">홈</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">주제: 이질성</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">1.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">2.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">3.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">4.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">5.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">6.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-chap.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">7.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">8.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">9.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">10.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">11.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">12.1 Goals for this chapter</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">13.1 Goals for this chapter</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">14-chap.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">15-chap.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">16-chap.html</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#데이터란-무엇인가-행렬과-그-동기" id="toc-데이터란-무엇인가-행렬과-그-동기" class="nav-link active" data-scroll-target="#데이터란-무엇인가-행렬과-그-동기"><span class="header-section-number">9.1</span> 7.2 데이터란 무엇인가? 행렬과 그 동기</a>
  <ul class="collapse">
  <li><a href="#low-dimensional-data-summaries-and-preparation" id="toc-low-dimensional-data-summaries-and-preparation" class="nav-link" data-scroll-target="#low-dimensional-data-summaries-and-preparation"><span class="header-section-number">9.1.1</span> 7.2.1 Low-dimensional data summaries and preparation</a></li>
  <li><a href="#데이터-전처리" id="toc-데이터-전처리" class="nav-link" data-scroll-target="#데이터-전처리"><span class="header-section-number">9.1.2</span> 7.2.2 데이터 전처리</a></li>
  </ul></li>
  <li><a href="#차원-축소dimension-reduction" id="toc-차원-축소dimension-reduction" class="nav-link" data-scroll-target="#차원-축소dimension-reduction"><span class="header-section-number">9.2</span> 7.3 차원 축소(Dimension reduction)</a>
  <ul class="collapse">
  <li><a href="#저차원-투영" id="toc-저차원-투영" class="nav-link" data-scroll-target="#저차원-투영"><span class="header-section-number">9.2.1</span> 7.3.1 저차원 투영</a></li>
  <li><a href="#차원-데이터를-어떻게-선으로-요약할까요" id="toc-차원-데이터를-어떻게-선으로-요약할까요" class="nav-link" data-scroll-target="#차원-데이터를-어떻게-선으로-요약할까요"><span class="header-section-number">9.2.2</span> 7.3.2 2차원 데이터를 어떻게 선으로 요약할까요?</a></li>
  </ul></li>
  <li><a href="#새로운-선형-결합" id="toc-새로운-선형-결합" class="nav-link" data-scroll-target="#새로운-선형-결합"><span class="header-section-number">9.3</span> 7.4 새로운 선형 결합</a>
  <ul class="collapse">
  <li><a href="#최적의-선" id="toc-최적의-선" class="nav-link" data-scroll-target="#최적의-선"><span class="header-section-number">9.3.1</span> 7.4.1 최적의 선</a></li>
  </ul></li>
  <li><a href="#pca-워크플로" id="toc-pca-워크플로" class="nav-link" data-scroll-target="#pca-워크플로"><span class="header-section-number">9.4</span> 7.5 PCA 워크플로</a></li>
  <li><a href="#pca의-내부-구조-계수-축소rank-reduction" id="toc-pca의-내부-구조-계수-축소rank-reduction" class="nav-link" data-scroll-target="#pca의-내부-구조-계수-축소rank-reduction"><span class="header-section-number">9.5</span> 7.6 PCA의 내부 구조: 계수 축소(Rank reduction)</a>
  <ul class="collapse">
  <li><a href="#계수-1-행렬rank-one-matrices" id="toc-계수-1-행렬rank-one-matrices" class="nav-link" data-scroll-target="#계수-1-행렬rank-one-matrices"><span class="header-section-number">9.5.1</span> 7.6.1 계수 1 행렬(Rank-one matrices)</a></li>
  <li><a href="#how-do-we-find-such-a-decomposition-in-a-unique-way" id="toc-how-do-we-find-such-a-decomposition-in-a-unique-way" class="nav-link" data-scroll-target="#how-do-we-find-such-a-decomposition-in-a-unique-way"><span class="header-section-number">9.5.2</span> 7.6.2 How do we find such a decomposition in a unique way?</a></li>
  <li><a href="#특잇값-분해singular-value-decomposition" id="toc-특잇값-분해singular-value-decomposition" class="nav-link" data-scroll-target="#특잇값-분해singular-value-decomposition"><span class="header-section-number">9.5.3</span> 7.6.3 특잇값 분해(Singular value decomposition)</a></li>
  <li><a href="#주성분principal-components" id="toc-주성분principal-components" class="nav-link" data-scroll-target="#주성분principal-components"><span class="header-section-number">9.5.4</span> 7.6.4 주성분(Principal components)</a></li>
  </ul></li>
  <li><a href="#주평면에-관측치-플롯하기" id="toc-주평면에-관측치-플롯하기" class="nav-link" data-scroll-target="#주평면에-관측치-플롯하기"><span class="header-section-number">9.6</span> 7.7 주평면에 관측치 플롯하기</a>
  <ul class="collapse">
  <li><a href="#pca-of-the-turtles-data" id="toc-pca-of-the-turtles-data" class="nav-link" data-scroll-target="#pca-of-the-turtles-data"><span class="header-section-number">9.6.1</span> 7.7.1 PCA of the turtles data</a></li>
  <li><a href="#a-complete-analysis-the-decathlon-athletes" id="toc-a-complete-analysis-the-decathlon-athletes" class="nav-link" data-scroll-target="#a-complete-analysis-the-decathlon-athletes"><span class="header-section-number">9.6.2</span> 7.7.2 A complete analysis: the decathlon athletes</a></li>
  <li><a href="#차원-수-k를-어떻게-선택할까요" id="toc-차원-수-k를-어떻게-선택할까요" class="nav-link" data-scroll-target="#차원-수-k를-어떻게-선택할까요"><span class="header-section-number">9.6.3</span> 7.7.3 차원 수 k를 어떻게 선택할까요?</a></li>
  </ul></li>
  <li><a href="#탐색적-도구로서의-pca-추가-정보-사용하기" id="toc-탐색적-도구로서의-pca-추가-정보-사용하기" class="nav-link" data-scroll-target="#탐색적-도구로서의-pca-추가-정보-사용하기"><span class="header-section-number">9.7</span> 7.8 탐색적 도구로서의 PCA: 추가 정보 사용하기</a>
  <ul class="collapse">
  <li><a href="#질량-분석-데이터-분석" id="toc-질량-분석-데이터-분석" class="nav-link" data-scroll-target="#질량-분석-데이터-분석"><span class="header-section-number">9.7.1</span> 7.8.1 질량 분석 데이터 분석</a></li>
  <li><a href="#바이플롯-및-스케일링" id="toc-바이플롯-및-스케일링" class="nav-link" data-scroll-target="#바이플롯-및-스케일링"><span class="header-section-number">9.7.2</span> 7.8.2 바이플롯 및 스케일링</a></li>
  <li><a href="#an-example-of-weighted-pca" id="toc-an-example-of-weighted-pca" class="nav-link" data-scroll-target="#an-example-of-weighted-pca"><span class="header-section-number">9.7.3</span> 7.8.3 An example of weighted PCA</a></li>
  </ul></li>
  <li><a href="#이-장의-요약" id="toc-이-장의-요약" class="nav-link" data-scroll-target="#이-장의-요약"><span class="header-section-number">9.8</span> 7.9 이 장의 요약</a></li>
  <li><a href="#더-읽을거리" id="toc-더-읽을거리" class="nav-link" data-scroll-target="#더-읽을거리"><span class="header-section-number">9.9</span> 7.10 더 읽을거리</a></li>
  <li><a href="#연습-문제" id="toc-연습-문제" class="nav-link" data-scroll-target="#연습-문제"><span class="header-section-number">9.10</span> 7.11 연습 문제</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">7.1 이 장의 목표</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><img src="imgs/TheMatrix.jpg" class="img-fluid"></p>
<p>많은 데이터 세트는 동일한 대상(환자, 샘플 또는 유기체)에 대해 측정된 여러 변수로 구성됩니다. 예를 들어, 우리는 천 명의 환자에 대해 키, 몸무게, 나이와 같은 생체 정보뿐만 아니라 혈압, 혈당, 심박수와 같은 임상 변수 및 유전 데이터를 가질 수 있습니다. 다변량 분석(multivariate analysis)의 존재 이유(<em>raison d’être</em>)는 측정된 서로 다른 변수들 간의 연결 또는 연관성을 조사하는 것입니다. 대개 데이터는 각 대상에 대해 하나의 행, 각 변수가 하나의 열을 가진 표 형식의 데이터 구조로 보고됩니다. 이하에서는 각 변수가 수치형인 특수한 경우에 초점을 맞출 것이며, 따라서 R에서 데이터 구조를 _행렬(matrix)_로 나타낼 수 있습니다.</p>
<p>행렬의 열들이 모두 서로 독립적(무관)이라면, 우리는 단순히 각 열을 별도로 공부하고 표준 “단변량(univariate)” 통계 처리를 하나씩 수행할 수 있습니다. 이들을 행렬로 공부해서 얻는 이점은 없을 것입니다.</p>
<p>더 자주, 패턴과 의존성이 존재할 것입니다. 예를 들어 세포 생물학에서 우리는 증식률(proliferation rate)이 많은 유전자의 발현에 동시에 영향을 미친다는 것을 알고 있습니다. 환자 유래 세포의 많은 샘플(행)에 대해 25,000개의 유전자(열) 발현을 공부하면서, 우리는 많은 유전자가 함께 작용하여 양(+)의 상관관계를 갖거나 음(-)의 상관관계를 갖는다는 것을 알아차립니다. 각 유전자를 별도로만 공부한다면 우리는 많은 중요한 정보를 놓칠 것입니다. 유전자들 사이의 중요한 연결은 우리가 데이터를 전체적으로 고려할 때만 감지 가능합니다: 각 행은 동일한 관찰 단위에 대해 이루어진 많은 측정값들을 나타냅니다. 그러나 한꺼번에 고려해야 할 25,000차원의 변동을 갖는 것은 벅찬 일입니다. 우리는 너무 많은 정보를 잃지 않으면서 우리 데이터를 더 적은 수의 가장 중요한 차원1으로 줄이는 방법을 보여줄 것입니다.</p>
<p>1 우리는 아래에서 이러한 차원 축소(dimension reduction)의 아이디어를 훨씬 더 자세히 설명할 것입니다. 당분간은 우리가 4차원 세계에 살고 있다는 것을 기억합시다.</p>
<p>이 장에서는 고처리량 실험에서 마주치는 다변량 데이터 행렬의 많은 예시뿐만 아니라, 여러분의 직관을 높여줄 좀 더 기초적인 예시들을 제시합니다. 우리는 이 장에서 <strong>차원 축소</strong> 방법인 <strong>주성분 분석(Principal Component Analysis)</strong>, 약어로 <strong>PCA</strong>에 초점을 맞출 것입니다. 우리는 알고리즘에 대한 기하학적 설명뿐만 아니라 PCA 분석의 출력을 해석하는 데 도움이 되는 시각화 자료들을 제공할 것입니다.</p>
<p>이 장에서 우리는 다음을 수행할 것입니다:</p>
<ul>
<li><p>생물학적 데이터 연구에서 나타나는 행렬의 예시들을 살펴봅니다.</p></li>
<li><p>변수 간의 상관관계를 이해하기 위해 차원 축소를 수행합니다.</p></li>
<li><p>다변량 분석을 시작하기 전에 데이터를 전처리하고, 스케일을 조정하고, 중앙에 맞춥니다(center).</p></li>
<li><p>원래의 측정값보다 더 유용한, 주성분(principal components, PC)이라 불리는 새로운 변수들을 구축합니다.</p></li>
<li><p>PCA의 “내부 구조”인 행렬의 특잇값 분해(singular value decomposition, SVD)를 살펴봅니다.</p></li>
<li><p>이 분해가 무엇을 달성하는지 시각화하고 주성분의 수를 선택하는 방법을 배웁니다.</p></li>
<li><p>처음부터 끝까지 완전한 PCA 분석을 실행해 봅니다.</p></li>
<li><p>결과의 더 유용한 해석을 가능하게 하기 위해 요인 공변량(factor covariates)을 PCA 맵에 투영합니다.</p></li>
</ul>
<section id="데이터란-무엇인가-행렬과-그-동기" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="데이터란-무엇인가-행렬과-그-동기"><span class="header-section-number">9.1</span> 7.2 데이터란 무엇인가? 행렬과 그 동기</h2>
<p>먼저, 측정값 표를 나타내는 데 사용되는 직사각형 <strong>행렬(matrices)</strong>의 예시들을 살펴보겠습니다. 각 행렬에서 행과 열은 특정 개체를 나타냅니다.</p>
<p><strong>거북이(Turtles):</strong> 기본 원리를 이해하는 데 도움이 될 간단한 데이터 세트는 거북이(painted turtles)에 대한 세 가지 차원의 생체 측정값 행렬입니다 (<a href="16-chap.html#ref-Jolicoeur1960">Jolicoeur and Mosimann 1960</a>).</p>
<pre><code>turtles = read.table("../data/PaintedTurtles.txt", header = TRUE)
turtles[1:4, ]__


  sex length width height
1   f     98    81     38
2   f    103    84     38
3   f    103    86     42
4   f    105    86     40</code></pre>
<p>마지막 세 열은 길이 측정값(밀리미터 단위)인 반면, 첫 번째 열은 각 동물의 성별을 알려주는 요인 변수입니다.</p>
<p><strong>운동선수(Athletes):</strong> 이 행렬은 스포츠 세계의 흥미로운 예시입니다. 10종 경기(decathlon)의 10개 종목에 대한 33명 선수의 성적을 보고합니다: <code>m100</code>, <code>m400</code> 및 <code>m1500</code>은 각각 100미터, 400미터, 1500미터 달리기 시간(초)입니다. <code>m110</code>은 110미터 허들 완주 시간입니다. <code>pole</code>은 장대높이뛰기 높이, <code>high</code>와 <code>long</code>은 각각 높이뛰기와 멀리뛰기 결과이며 모두 미터 단위입니다. <code>weight</code>, <code>disc</code>, <code>javel</code>은 선수들이 던진 포환, 원반, 창의 거리(미터)입니다. 처음 세 명의 선수에 대한 변수들은 다음과 같습니다:</p>
<pre><code>data("olympic", package = "ade4")
athletes = setNames(olympic$tab, 
  c("m100", "long", "weight", "high", "m400", "m110", "disc", pole, "javel", "m1500"))
athletes[1:3, ]__


   m100 long weight high  m400  m110  disc pole javel  m1500
1 11.25 7.43  15.48 2.27 48.90 15.13 49.28  4.7 61.32 268.95
2 10.87 7.45  14.97 1.97 47.71 14.46 44.36  5.1 61.76 273.02
3 11.18 7.44  14.20 1.97 48.29 14.81 43.66  5.2 64.16 263.20</code></pre>
<p><strong>Cell Types:</strong> Holmes et al.&nbsp;(<a href="16-chap.html#ref-holmes2005memory">2005</a>) studied gene expression profiles of sorted T-cell populations from different subjects. The columns are a subset of gene expression measurements, they correspond to 156 genes that show differential expression between cell types.</p>
<pre><code>load("../data/Msig3transp.RData")
round(Msig3transp,2)[1:5, 1:6]__


             X3968 X14831 X13492 X5108 X16348  X585
HEA26_EFFE_1 -2.61  -1.19  -0.06 -0.15   0.52 -0.02
HEA26_MEM_1  -2.26  -0.47   0.28  0.54  -0.37  0.11
HEA26_NAI_1  -0.27   0.82   0.81  0.72  -0.90  0.75
MEL36_EFFE_1 -2.24  -1.08  -0.24 -0.18   0.64  0.01
MEL36_MEM_1  -2.68  -0.15   0.25  0.95  -0.20  0.17</code></pre>
<p><strong>Bacterial Species Abundances:</strong> Matrices of counts are used in microbial ecology studies (as we saw in <a href="04-chap.html">Chapter 4</a>). Here the columns represent different species (or operational taxonomic units, OTUs) of bacteria, which are identified by numerical tags. The rows are labeled according to the samples in which they were measured, and the (integer) numbers represent the number of times of each of the OTUs was observed in each of the samples.</p>
<pre><code>data("GlobalPatterns", package = "phyloseq")
GPOTUs = as.matrix(t(phyloseq::otu_table(GlobalPatterns)))
GPOTUs[1:4, 6:13]__


OTU Table:          [4 taxa and 8 samples]
                     taxa are rows
        246140 143239 244960 255340 144887 141782 215972 31759
CL3          0      7      0    153      3      9      0     0
CC1          0      1      0    194      5     35      3     1
SV1          0      0      0      0      0      0      0     0
M31Fcsw      0      0      0      0      0      0      0     0</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="Notice the propensity of the matrix entries to be zero; we call such data sparse."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>Notice the propensity of the matrix entries to be zero; we call such data sparse.</figcaption>
</figure>
</div>
<p>Notice the propensity of the matrix entries to be zero; we call such data <strong>sparse</strong>.</p>
<p><strong>mRNA reads:</strong> RNA-Seq transcriptome data report the number of sequence reads matching each gene2 in each of several biological samples. We will study this type of data in detail in <a href="08-chap.html">Chapter 8</a></p>
<p>2 Or sub-gene structures, such as exons.</p>
<pre><code>library("SummarizedExperiment")
data("airway", package = "airway")
assay(airway)[1:3, 1:4]__


                SRR1039508 SRR1039509 SRR1039512 SRR1039513
ENSG00000000003        679        448        873        408
ENSG00000000005          0          0          0          0
ENSG00000000419        467        515        621        365</code></pre>
<p>It is customary in the RNA-Seq field—and so it is for the <code>airway</code> data above—to report the genes in the rows and the samples in the columns. Compared to the other matrices we look at here, this is <em>transposed</em> : rows and columns are swapped. Such different conventions easily lead to errors, so they are worthwhile paying attention to3. <strong>Proteomic profiles:</strong> Here, the columns are aligned <strong>mass spectroscopy</strong> peaks or molecules identified through their \(m/z\)-ratios; the entries in the matrix are the measured intensities4.</p>
<p>3 The Bioconductor project tries to help users and developers to avoid such ambiguities by defining data containers in which such conventions are explicitly fixed. In <a href="08-chap.html">Chapter 8</a>, we will see the example of the <em>SummarizedExperiment</em> class.</p>
<p>4 More details can be found, e.g., on <a href="https://en.wikipedia.org/wiki/Mass_spectrum">Wikipedia</a>.</p>
<pre><code>metab = t(as.matrix(read.csv("../data/metabolites.csv", row.names = 1)))
metab[1:4, 1:4]__


         146.0985388 148.7053275 310.1505057 132.4512963
KOGCHUM1    29932.36    17055.70     1132.82    785.5129
KOGCHUM2    94067.61    74631.69    28240.85   5232.0499
KOGCHUM3   146411.33   147788.71    64950.49  10283.0037
WTGCHUM1   229912.57   384932.56   220730.39  26115.2007</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="In many of the matrices we have seen here, important information about the samples (subjects) and the measured features is stored in the row or column names, often through some ad hoc string concatenation. This is not the best place to store all available information, and quickly becomes limiting and error-prone. A much better approach is the Bioconductor SummarizedExperiment class."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>In many of the matrices we have seen here, important information about the samples (subjects) and the measured features is stored in the row or column names, often through some ad hoc string concatenation. This is not the best place to store all available information, and quickly becomes limiting and error-prone. A much better approach is the Bioconductor SummarizedExperiment class.</figcaption>
</figure>
</div>
<p>In many of the matrices we have seen here, important information about the samples (subjects) and the measured features is stored in the row or column names, often through some ad hoc string concatenation. This is not the best place to store all available information, and quickly becomes limiting and error-prone. A much better approach is the Bioconductor <em>SummarizedExperiment</em> class.</p>
<p>__</p>
<p>Task</p>
<p>When a peak was not detected for a particular \(m/z\) score in the mass spectrometry run, a zero was recorded in <code>metab</code>. Similarly, zeros in <code>GPOTUs</code> or in the <code>airway</code> object occur when there were no matching sequence reads detected. Tabulate the frequencies of zeros in these data matrices.</p>
<p>__</p>
<p>Question 7.1</p>
<ol type="1">
<li><p>What are the columns of these data matrices usually called?</p></li>
<li><p>In each of these examples, what are the rows of the matrix?</p></li>
<li><p>What does a cell in a matrix represent?</p></li>
<li><p>If the data matrix is called <code>athletes</code> and you want to see the value of the third variable for the fifth athlete, what do you type into R?</p></li>
</ol>
<section id="low-dimensional-data-summaries-and-preparation" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="low-dimensional-data-summaries-and-preparation"><span class="header-section-number">9.1.1</span> 7.2.1 Low-dimensional data summaries and preparation</h3>
<p><a href="imgs/flatland.png" title="Figure 7.1: xkcd: What do we mean by low-dimensional? We live in 3 dimensions, or 4 if you count time, a plane has 2 dimensions, a line has one dimension. A point is said to be zero- dimensional. For the amusing novel referenced in the cartoon see @Abbott:1884."><img src="imgs/flatland.png" class="img-fluid"></a></p>
<p>Figure 7.1: xkcd: What do we mean by low-dimensional? We live in 3 dimensions, or 4 if you count time, a plane has 2 dimensions, a line has one dimension. A point is said to be zero-dimensional. For the amusing novel referenced in the cartoon see Abbott (<a href="16-chap.html#ref-Abbott:1884">1884</a>).</p>
<p>If we are studying only one variable, i.e., just the third column of the turtles matrix5, we say we are looking at one-dimensional data. Such a vector, say all the turtle weights, can be visualized by plots such as those that we saw in <a href="03-chap.html#sec-graphics-univar">Section 3.6</a>, e.g., a histogram. If we compute a one number summary, say mean or median, we have made a zero- dimensional summary of our one-dimensional data. This is already an example of dimension reduction.</p>
<p>5 The third column of a matrix \(X\) is denoted mathematically by \({x}_{}\) or accessed in R using <code>X[, 3]</code>.</p>
<p>In <a href="03-chap.html">Chapter 3</a> we studied two-dimensional scatterplots. We saw that if there are too many observations, it can be beneficial to group the data into (hexagonal) bins: these are <em>two-dimensional</em> histograms. When considering two variables (\(x\) and \(y\)) measured together on a set of observations, the <strong>correlation coefficient</strong> measures how the variables co- vary. This is a single number summary of two-dimensional data. Its formula involves the summaries \({x}\) and \({y}\):</p>
<p>\[ = { } \]</p>
<p>In R, we use the <code>cor</code> function to calculate its value. Applied to a matrix this function computes all the two way correlations between continuous variables. In <a href="09-chap.html">Chapter 9</a> we will see how to analyse multivariate categorical data.</p>
<p>__</p>
<p>Question 7.2</p>
<p>Compute the matrix of all correlations between the measurements from the turtles data. What do you notice ?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>We take out the categorical variable and compute the matrix.</p>
<pre><code>cor(turtles[, -1])__


          length     width    height
length 1.0000000 0.9783116 0.9646946
width  0.9783116 1.0000000 0.9605705
height 0.9646946 0.9605705 1.0000000</code></pre>
<p>We see that this square matrix is symmetric and the values are all close to 1. The diagonal values are always 1.</p>
<p>It is always beneficial to start a multidimensional analysis by checking these simple one-dimensional and two-dimensional summary statistics using visual displays such as those we look at in the next two questions.</p>
<p>__</p>
<p>Question 7.3</p>
<ol type="1">
<li><p>Produce all pairwise scatterplots, as well as the one-dimensional histograms on the diagonal, for the turtles data. Use the package <strong><a href="https://cran.r-project.org/web/packages/GGally/">GGally</a></strong>.</p></li>
<li><p>Guess the underlying or “true dimension” of these data?</p></li>
</ol>
<p>__</p>
<p>Solution</p>
<p>__</p>
<pre><code>library("ggplot2")
library("dplyr")
library("GGally")
ggpairs(turtles[, -1], axisLabels = "none")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-turtlespairs-1.png" title="Figure 7.2: All pairs of bivariate scatterplots for the three biometric measurements on painted turtles."><img src="07-chap_files/figure-html/fig-turtlespairs-1.png" class="img-fluid"></a></p>
<p>Figure 7.2: All pairs of bivariate scatterplots for the three biometric 그림 7.2를 보면, 세 변수 모두 높은 상관관계를 가지고 있으며 대부분 거북이의 _크기_로 해석될 수 있는 동일한 “기저” 변수를 반영하는 것으로 보입니다.</p>
<p>__</p>
<p>질문 7.4</p>
<p><code>athletes</code> 데이터의 변수들 사이의 모든 쌍별 상관관계를 계산하고 그 행렬을 히트맵으로 표시해 보세요. 무엇을 알 수 있나요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<pre><code>library("pheatmap")
pheatmap(cor(athletes), cell.width = 10, cell.height = 10)__</code></pre>
<p><a href="07-chap_files/figure-html/fig-heatmapathletes-1.png &quot;그림 7.3: athletes 데이터의 변수들 사이의 상관관계 히트맵. 높은 수치는 빨강-주황색으로 색상 코딩되어 있습니다. 계층적 군집화는 서로 관련된 종목들의 그룹화를 보여줍니다.&quot;"><img src="07-chap_files/figure-html/fig- heatmapathletes-1.png" class="img-fluid"></a></p>
<p>그림 7.3: <code>athletes</code> 데이터의 변수들 사이의 상관관계 히트맵. 높은 수치는 빨강-주황색으로 색상 코딩되어 있습니다. 계층적 군집화는 서로 관련된 종목들의 그룹화를 보여줍니다.</p>
<p>그림 7.3은 10개의 변수가 달리기, 던지기, 점프라는 그룹으로 어떻게 군집화되는지 보여줍니다.</p>
</section>
<section id="데이터-전처리" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="데이터-전처리"><span class="header-section-number">9.1.2</span> 7.2.2 데이터 전처리</h3>
<p>많은 경우, 서로 다른 변수들은 서로 다른 단위로 측정되므로, 서로 다른 기준선과 서로 다른 스케일(scales)6을 가집니다. 이들은 원래의 형태로는 직접적으로 비교할 수 없습니다.</p>
<p>6 스케일의 일반적인 척도는 범위와 표준 편차입니다. 예를 들어, 110미터 허들 시간은 표준 편차 0.51과 함께 14.18에서 16.2 사이인 반면, 1500미터 완주 시간은 표준 편차 13.66과 함께 256.64에서 303.17 사이입니다; 이는 10배 이상 더 큽니다. 더욱이 <code>athletes</code> 데이터는 서로 다른 단위(초, 미터)의 측정값도 포함하고 있는데, 이들의 선택은 임의적입니다(길이는 센티미터나 피트로 기록될 수도 있고, 시간은 밀리초로 기록될 수도 있습니다).</p>
<p>따라서 PCA 및 다른 많은 방법들의 경우, 비교를 의미 있게 만들기 위해 수치들을 어떤 공통적인 스케일로 변환해야 합니다. <strong>중앙화(Centering)</strong>는 평균을 빼는 것을 의미하며, 중앙화된 데이터의 평균은 원점에 위치하게 됩니다. <strong>스케일링(Scaling)</strong> 또는 <strong>표준화(Standardizing)</strong>는 표준 편차로 나누는 것을 의미하며, 새로운 표준 편차는 \(1\)이 됩니다. 사실 우리는 상관 계수를 계산할 때(식 7.1) 이미 이러한 연산들을 접했습니다: 상관 계수는 단순히 중앙화되고 스케일링된 변수들의 벡터 곱입니다. 이러한 연산을 수행하기 위해 R에는 <code>scale</code> 함수가 있으며, 행렬이나 데이터 프레임이 주어졌을 때의 기본 거동은 모든 열의 평균을 0으로, 표준 편차를 1로 만드는 것입니다.</p>
<p>__</p>
<p>질문 7.5</p>
<ol type="1">
<li><p><code>turtle</code> 데이터의 평균과 표준 편차를 계산한 다음, <code>scale</code> 함수를 사용하여 연속형 변수들을 중앙화하고 표준화하세요. 이를 <code>scaledTurtles</code>라고 부르고, <code>scaledTurtles</code>의 평균과 표준 편차의 새로운 값을 확인해 보세요.</p></li>
<li><p>거북이 데이터의 스케일링 및 중앙화된 너비(width)와 높이(height) 변수의 산점도를 만들고 점들에 성별에 따른 색상을 입히세요.</p></li>
</ol>
<p>__</p>
<p>해결책</p>
<p>__</p>
<pre><code>apply(turtles[,-1], 2, sd)__


   length     width    height 
20.481602 12.675838  8.392837 


apply(turtles[,-1], 2, mean)__


   length     width    height 
124.68750  95.43750  46.33333 


scaledTurtles = scale(turtles[, -1])
apply(scaledTurtles, 2, mean)__


       length         width        height 
-1.432050e-18  1.940383e-17 -2.870967e-16 


apply(scaledTurtles, 2, sd)__


length  width height 
     1      1      1 


data.frame(scaledTurtles, sex = turtles[, 1]) %&gt;%
  ggplot(aes(x = width, y = height, group = sex)) +
    geom_point(aes(color = sex)) + coord_fixed()__</code></pre>
<p><a href="07-chap_files/figure- html/fig-turtlesDim12-1.png" title="그림 7.4: 너비와 높이 변수에 의해 정의된 평면에 투영된 거북이 데이터: 각 점은 성별에 따라 색상이 입혀져 있습니다."><img src="07-chap_files/figure-html/fig-turtlesDim12-1.png" class="img-fluid"></a></p>
<p>그림 7.4: 너비(width)와 높이(height) 변수에 의해 정의된 평면에 투영된 거북이 데이터: 각 점은 성별에 따라 색상이 입혀져 있습니다.</p>
<p>우리는 이미 <a href="04-chap.html">4장</a>과 <a href="05-chap.html">5장</a>에서 <code>log</code>와 <code>asinh</code> 함수를 사용한 다른 데이터 변환 선택지들을 접했습니다. 이러한 변환의 목적은 (대개) 분산 안정화(variance stabilization)입니다. 즉, 동적 범위의 서로 다른 부분에서 _동일한 변수_의 반복 측정값 분산을 더 비슷하게 만드는 것입니다. 이와 대조적으로 위에서 설명한 표준화 변환은 _서로 다른 변수_의 스케일(평균과 표준 편차로 측정됨)을 동일하게 만드는 것을 목표로 합니다.</p>
<p>때로는 변수들이 진정으로 중요도가 다르기 때문에 서로 다른 스케일로 남겨두는 것이 더 나을 수도 있습니다. 만약 원래의 스케일이 유의미하다면, 데이터를 있는 그대로 두어야 합니다. 다른 경우에, 변수들은 사전적으로 알려진 서로 다른 정밀도를 가집니다. <a href="09-chap.html">9장</a>에서 우리는 그러한 변수들에 가중치를 부여하는 여러 방법들을 살펴볼 것입니다.</p>
<p>데이터를 전처리한 후, 우리는 <strong>차원 축소</strong>를 통한 데이터 _단순화_를 수행할 준비가 되었습니다.</p>
<p><img src="imgs/book_icon.png" class="img-fluid"></p>
<p>관련 장들이 포함된 유용한 책으로는 입문용 설명이 담긴 Flury (<a href="16-chap.html#ref-Flury">1997</a>)와 상세한 수학적 접근 방식이 담긴 Mardia, Kent, Bibby (<a href="16-chap.html#ref-Mardia">1979</a>)가 있습니다.</p>
</section>
</section>
<section id="차원-축소dimension-reduction" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="차원-축소dimension-reduction"><span class="header-section-number">9.2</span> 7.3 차원 축소(Dimension reduction)</h2>
<p>우리는 여러 가지 서로 다른 관점에서 차원 축소를 설명할 것입니다. 이는 1901년에 Karl Pearson (<a href="16-chap.html#ref-Pearson1901">Pearson 1901</a>)에 의해 두 변수 산점도를 단일 좌표로 줄이는 방법으로 발명되었습니다. 1930년대에는 통계학자들에 의해 동일한 대상에 대해 수행된 일련의 심리 테스트 결과를 요약하는 데 사용되었습니다 (<a href="16-chap.html#ref-Hotelling:1933ki">Hotelling 1933</a>); 이로써 한꺼번에 테스트된 많은 변수들을 요약하는 종합 점수(overall scores)를 제공하게 되었습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="Principal과 principle은 서로 다른 뜻을 가진 두 개의 다른 단어입니다. 따라서 이들을 혼동하지 마세요. PCA의 경우, 그것은 항상 principal입니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>Principal과 principle은 서로 다른 뜻을 가진 두 개의 다른 단어입니다. 따라서 이들을 혼동하지 마세요. PCA의 경우, 그것은 항상 principal입니다.</figcaption>
</figure>
</div>
<p>_Principal_과 _principle_은 서로 다른 뜻을 가진 두 개의 다른 단어입니다. 따라서 이들을 혼동하지 마세요. PCA의 경우, 그것은 항상 _principal_입니다.</p>
<p>이러한 <strong>주요(principal)</strong> 점수라는 아이디어가 주성분 분석(Principal Component Analysis, 약어로 PCA)이라는 이름에 영감을 주었습니다. PCA는 군집화에서와 마찬가지로 모든 변수를 동일한 <strong>상태(status)</strong>를 가진 것으로 취급하기 때문에 <strong>비지도 학습(unsupervised learning)</strong> 기법이라 불립니다. 우리는 한 특정한 변수의 값을 다른 변수들로부터 예측하거나 설명하려는 것이 아니라, 오히려 모든 변수들에 대한 기저 구조의 수학적 모델을 찾으려는 것입니다. PCA는 기본적으로 변수들 사이의 관계와 관측치들 사이의 관계를 유용한 방식으로 보여주는 맵(maps)을 생성하는 탐색적 기법입니다.</p>
<p>우리는 먼저 이 다변량 분석이 데이터에 무엇을 하는지에 대한 맛보기를 제공하겠습니다. 선형 대수학을 통한 이러한 방법들의 우아한 수학적 공식화가 존재하지만, 여기서는 그 사용을 최소화하고 시각화와 데이터 예시에 집중할 것입니다.</p>
<p>우리는 고차원 공간의 점들을 낮은 차원으로 투영하는 기하학적 <strong>투영(projections)</strong>을 사용합니다. 그림 7.5는 벡터 \({v}\)에 의해 생성된 선 위로 점 \(A\)를 투영하는 것을 보여줍니다.</p>
<p><a href="07-chap_files/figure- html/fig-projectv-1.png" title="그림 7.5: 점 A가 벡터 v에 의해 생성된 빨간색 선 위로 투영됩니다. 점선 투영선은 빨간색 선에 수직(또는 직교)합니다. 투영선과 빨간색 선의 교차점을 점 A의 벡터 v에 의해 생성된 빨간색 선 위로의 직교 투영이라고 부릅니다."><img src="07-chap_files/figure-html/fig-projectv-1.png" class="img-fluid"></a></p>
<p>그림 7.5: 점 \(A\)가 벡터 \(v\)에 의해 생성된 빨간색 선 위로 투영됩니다. 점선 투영선은 빨간색 선에 수직(또는 <strong>직교(orthogonal)</strong>)합니다. 투영선과 빨간색 선의 교차점을 점 \(A\)의 벡터 \(v\)에 의해 생성된 빨간색 선 위로의 직교 투영이라고 부릅니다.</p>
<p>PCA는 <strong>선형(linear)</strong> 기법으로, 변수들 사이의 선형 관계를 찾고 원래 변수들의 선형 함수인 새로운 변수들을 사용한다는 것을 의미합니다 (\(f(ax+by)=af(x)+b(y)\)). 선형성 제약 조건은 계산을 특히 쉽게 만듭니다. <a href="09-chap.html">9장</a>에서 우리는 비선형 기법들을 살펴볼 것입니다.</p>
<section id="저차원-투영" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="저차원-투영"><span class="header-section-number">9.2.1</span> 7.3.1 저차원 투영</h3>
<p>여기에 <code>athletes</code> 데이터를 사용하여 2차원 데이터를 선 위로 투영하는 한 가지 방법을 보여줍니다. 아래 코드는 그림 7.6을 생성하는 데 사용된 전처리 및 플로팅 단계를 제공합니다:</p>
<pre><code>athletes = data.frame(scale(athletes))
ath_gg = ggplot(athletes, aes(x = weight, y = disc)) +
  geom_point(size = 2, shape = 21)
ath_gg + geom_point(aes(y = 0), colour = "red") +
  geom_segment(aes(xend = weight, yend = 0), linetype = "dashed")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-SimpleScatter-1.png" title="그림 7.6: 가로 x축(y=0으로 정의됨)으로의 투영을 빨간색으로 보여주는 두 변수의 산점도이며 투영선은 점선으로 나타납니다."><img src="07-chap_files/figure-html/fig-SimpleScatter-1.png" class="img-fluid"></a></p>
<p>그림 7.6: 가로 (x)축((y=0)으로 정의됨)으로의 투영을 빨간색으로 보여주는 두 변수의 산점도이며 투영선은 점선으로 나타납니다.</p>
<p>__</p>
<p>태스크</p>
<ol type="1">
<li><p>그림 7.6에서 빨간색 점들의 분산을 계산해 보세요.</p></li>
<li><p>(y)축으로의 투영선과 투영된 점들을 보여주는 플롯을 만들어 보세요.</p></li>
<li><p>수직 (y)축으로 투영된 점들의 분산을 계산해 보세요.</p></li>
</ol>
</section>
<section id="차원-데이터를-어떻게-선으로-요약할까요" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="차원-데이터를-어떻게-선으로-요약할까요"><span class="header-section-number">9.2.2</span> 7.3.2 2차원 데이터를 어떻게 선으로 요약할까요?</h3>
<p>일반적으로 우리가 2차원(평면)에서 1차원(선)으로 투영할 때 점들에 대한 정보를 잃게 됩니다. 그림 7.6에서 <code>weight</code> 변수에 대해 했던 것처럼 원래의 좌표만 사용한다면, 우리는 <code>disc</code> 변수에 대한 모든 정보를 잃게 됩니다. 우리의 목표는 <em>두</em> 변수 모두에 대해 가능한 한 많은 정보를 유지하는 것입니다. 사실 점 구름을 선 위로 투영하는 방법은 여러 가지가 있습니다. 하나는 <strong>회귀선(regression lines)</strong>이라 알려진 것을 사용하는 것입니다. R에서 이러한 선들이 어떻게 구축되는지 살펴보겠습니다.</p>
<section id="한-변수를-다른-변수에-대해-회귀-분석하기" class="level4" data-number="9.2.2.1">
<h4 data-number="9.2.2.1" class="anchored" data-anchor-id="한-변수를-다른-변수에-대해-회귀-분석하기"><span class="header-section-number">9.2.2.1</span> 한 변수를 다른 변수에 대해 회귀 분석하기</h4>
<p>선형 회귀(linear regression)를 보셨다면, 산점도를 요약하는 선을 계산하는 방법을 이미 알고 계실 것입니다. <strong>선형 회귀</strong>는 한 방향, 즉 반응 변수 방향의 잔차 제곱합을 최소화하는 것을 우선시하는 <strong>지도(supervised)</strong> 방법입니다.</p>
</section>
<section id="weight에-대한-disc-변수의-회귀-분석." class="level4" data-number="9.2.2.2">
<h4 data-number="9.2.2.2" class="anchored" data-anchor-id="weight에-대한-disc-변수의-회귀-분석."><span class="header-section-number">9.2.2.2</span> <code>weight</code>에 대한 <code>disc</code> 변수의 회귀 분석.</h4>
<p>그림 7.7에서는 회귀선을 찾기 위해 <code>lm</code>(선형 모델) 함수를 사용합니다. 그 기울기와 절편은 결과 객체 <code>reg1</code>의 <code>coefficients</code> 슬롯에 있는 값들에 의해 주어집니다.</p>
<pre><code>reg1 = lm(disc ~ weight, data = athletes)
a1 = reg1$coefficients[1] # 절편
b1 = reg1$coefficients[2] # 기울기
pline1 = ath_gg + geom_abline(intercept = a1, slope = b1,
    col = "blue", linewidth = 1.5)
pline1 + geom_segment(aes(xend = weight, yend = reg1$fitted),
    colour = "red", arrow = arrow(length = unit(0.15, "cm")))__</code></pre>
<p><a href="07-chap_files/figure-html/fig- Reg1-1.png" title="그림 7.7: 파란색 선은 (빨간색으로 표시된) 수직 잔차의 제곱합을 최소화합니다."><img src="07-chap_files/figure-html/fig-Reg1-1.png" class="img-fluid"></a></p>
<p>그림 7.7: 파란색 선은 (빨간색으로 표시된) 수직 잔차의 제곱합을 최소화합니다.</p>
</section>
<section id="discus에-대한-weight의-회귀-분석." class="level4" data-number="9.2.2.3">
<h4 data-number="9.2.2.3" class="anchored" data-anchor-id="discus에-대한-weight의-회귀-분석."><span class="header-section-number">9.2.2.3</span> <code>discus</code>에 대한 <code>weight</code>의 회귀 분석.</h4>
<p>그림 7.8은 두 변수의 역할을 바꾸었을 때 생성되는 선을 보여줍니다. <code>weight</code>가 반응 변수가 됩니다.</p>
<pre><code>reg2 = lm(weight ~ disc, data = athletes)
a2 = reg2$coefficients[1] # 절편
b2 = reg2$coefficients[2] # 기울기
pline2 = ath_gg + geom_abline(intercept = -a2/b2, slope = 1/b2,
    col = "darkgreen", linewidth = 1.5)
pline2 + geom_segment(aes(xend=reg2$fitted, yend=disc),
    colour = "orange", arrow = arrow(length = unit(0.15, "cm")))__</code></pre>
<p><a href="07-chap_files/figure-html/fig- Reg2-1.png" title="그림 7.8: 녹색 선은 (주황색으로 표시된) 수평 잔차의 제곱합을 최소화합니다."><img src="07-chap_files/figure-html/fig-Reg2-1.png" class="img-fluid"></a></p>
<p>그림 7.8: 녹색 선은 (주황색으로 표시된) 수평 잔차의 제곱합을 최소화합니다.</p>
<p>그림 7.7과 7.8의 각 회귀선은 <code>disc</code>와 <code>weight</code> 사이의 대략적인 선형 관계를 제공합니다. 그러나 그 관계는 우리가 어느 변수를 예측 변수로 선택하느냐에 따라 달라집니다…. which the response.</p>
<p>__</p>
<p>Question 7.6</p>
<p>How large is the variance of the projected points that lie on the blue regression line of Figure 7.7? Compare this to the variance of the data when projected on the original axes, <code>weight</code> and <code>disc</code>.</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>Pythagoras’ theorem tells us that the squared length of the hypotenuse of a right-angled triangle is equal to the sum of the squared lengths of the other two sides, which we apply as follows:</p>
<pre><code>var(athletes$weight) + var(reg1$fitted)__


[1] 1.650204</code></pre>
<p>The variances of the points along the original axes <code>weight</code> and <code>disc</code> are 1, since we scaled the variables.</p>
</section>
<section id="a-line-that-minimizes-distances-in-both-directions" class="level4" data-number="9.2.2.4">
<h4 data-number="9.2.2.4" class="anchored" data-anchor-id="a-line-that-minimizes-distances-in-both-directions"><span class="header-section-number">9.2.2.4</span> A line that minimizes distances in both directions</h4>
<p>Figure 7.9 shows the line chosen to minimize the sum of squares of the orthogonal (perpendicular) projections of data points onto it; we call this the <strong>principal component</strong> line. All our three ways of fitting a line (Figures 7.7–7.9) together in one plot are shown in Figure 7.10.</p>
<pre><code>xy = cbind(athletes$disc, athletes$weight)
svda = svd(xy)
pc = xy %*% svda$v[, 1] %*% t(svda$v[, 1])
bp = svda$v[2, 1] / svda$v[1, 1]
ap = mean(pc[, 2]) - bp * mean(pc[, 1])
ath_gg + geom_segment(xend = pc[, 1], yend = pc[, 2]) +
  geom_abline(intercept = ap, slope = bp, col = "purple", linewidth = 1.5)__</code></pre>
<p><a href="07-chap_files/figure- html/fig-PCAmin-1.png" title="Figure 7.9: The purple principal component line minimizes the sums of squares of the orthogonal projections."><img src="07-chap_files/figure-html/fig-PCAmin-1.png" class="img-fluid"></a></p>
<p>Figure 7.9: The purple <strong>principal component</strong> line minimizes the sums of squares of the orthogonal projections.</p>
<p><a href="07-chap_files/figure- html/fig-PCAR1R2-1-1.png" title="Figure 7.10: The blue line minimizes the sum of squares of the vertical residuals, the green line minimizes the horizontal residuals, the purple line, called the principal component, minimizes the orthogonal projections. Notice the ordering of the slopes of the three lines."><img src="07-chap_files/figure-html/fig-PCAR1R2-1-1.png" class="img-fluid"></a></p>
<p>Figure 7.10: The blue line minimizes the sum of squares of the vertical residuals, the green line minimizes the horizontal residuals, the purple line, called the <strong>principal component</strong> , minimizes the orthogonal projections. Notice the ordering of the slopes of the three lines.</p>
<p>__</p>
<p>Question 7.7</p>
<ol type="1">
<li><p>What is particular about the slope of the purple line?</p></li>
<li><p>Redo the plots on the original (unscaled) variables. What happens?</p></li>
</ol>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>The lines computed here depend on the choice of units. Because we have made the standard deviations equal to one for both variables, the PCA line is the diagonal that cuts exactly in the middle of both regression lines. Since the data were centered by subtracting their means, the line passes through the origin \((0,0)\).</p>
<p>__</p>
<p>Question 7.8</p>
<p>Compute the variance of the points on the purple line.</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>We have computed the coordinates of the points when we made the plot, these are in the <code>pc</code> vector:</p>
<pre><code>apply(pc, 2, var)__


[1] 0.9031761 0.9031761


sum(apply(pc, 2, var))__


[1] 1.806352</code></pre>
<p>우리는 이 축을 따른 분산이 질문 7.6에서 계산한 다른 분산들보다 크다는 것을 알 수 있습니다.</p>
<p>피타고라스 정리는 여기서 두 가지 흥미로운 사실을 알려줍니다:</p>
<ul>
<li><p>수평 및 수직 방향 모두에서 최소화하고 있다면, 사실 우리는 각 점으로부터 선으로의 직교 투영을 최소화하고 있는 것입니다.</p></li>
<li><p>점들의 전체 가변성은 점들을 무게 중심(데이터가 중앙화되어 있다면 원점(0,0))으로 투영한 제곱합으로 측정됩니다. 이를 점 구름의 <em>전체 분산</em> 또는 <strong>관성(inertia)</strong>이라고 합니다. 이 관성은 선 위로의 투영 제곱합과 그 선을 따른 분산의 합으로 분해될 수 있습니다. 고정된 분산에 대해, 투영 거리를 최소화하는 것은 또한 그 선을 따른 분산을 최대화합니다. 종종 우리는 첫 번째 주성분을 분산이 최대인 선으로 정의합니다.</p></li>
</ul>
</section>
</section>
</section>
<section id="새로운-선형-결합" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="새로운-선형-결합"><span class="header-section-number">9.3</span> 7.4 새로운 선형 결합</h2>
<p><img src="imgs/Vegetables_small.jpg" class="img-fluid"></p>
<p>이전 섹션에서 찾은 PC 선은 다음과 같이 쓸 수 있습니다.</p>
<p>이미지 출처: Sara Holmes</p>
<p>\[ PC = + . \]</p>
<p>주성분은 원래 측정된 변수들의 _선형 결합(linear combinations)_이며, _새로운 좌표계_를 제공합니다. <strong>선형 결합</strong>이 실제로 무엇인지 이해하기 위해 비유를 들어보겠습니다. 건강한 주스 믹스를 만들 때 다음과 같은 레시피를 따를 것입니다.</p>
<p>\[ <span class="math display">\[\begin{align} V &amp;= 2 \times \text{Beet} + 1 \times \text{Carrot} \\\ &amp;\+
\tfrac{1}{2} \text{Gala} + \tfrac{1}{2} \text{GrannySmith} \\\ &amp;\+ 0.02 \times
\text{Ginger} + 0.25 \times \text{Lemon}. \end{align}\]</span> \]</p>
<p>이 레시피는 개별 주스 유형(원래 변수들)의 선형 결합입니다. 결과는 새로운 변수 \(V\)이며, 계수 \((2,1,,,0.02,0.25)\)는 <strong>로딩(loadings)</strong>이라고 불립니다.</p>
<p>__</p>
<p>질문 7.9</p>
<p>주스 한 잔의 칼로리를 어떻게 계산하시겠습니까?</p>
<section id="최적의-선" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="최적의-선"><span class="header-section-number">9.3.1</span> 7.4.1 최적의 선</h3>
<p>변수들의 선형 결합은 우리가 2차원 산점도 평면에서 선을 구축했던 것과 같은 방식으로 고차원에서의 선을 정의합니다. 그 사례에서 보았듯이, 데이터를 투영할 선을 선택하는 방법은 여러 가지가 있지만, 우리의 목적에 부합하는 ‘최선의’ 선이 존재합니다.</p>
<p>모든 변수에 걸친 모든 점의 전체 분산은 분해될 수 있습니다. PCA에서 우리는 점들과 임의의 선 사이의 거리 제곱합이 선까지의 거리와 선을 따른 분산으로 분해될 수 있다는 사실을 이용합니다.</p>
<p>우리는 주성분이 선까지의 거리를 최소화하며, 또한 선을 따른 투영의 분산을 최대화한다는 것을 보았습니다.</p>
<p>왜 선을 따른 분산을 최대화하는 것이 좋은 아이디어일까요? 3차원에서 2차원으로의 투영에 대한 또 다른 예시를 살펴봅시다. 사실, 인간의 시각은 그러한 차원 축소에 의존합니다:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/CAM3.png" class="img-fluid figure-img"></p>
<figcaption>그림 7.11: 수수께끼의 실루엣.</figcaption>
</figure>
</div>
<p>그림 7.11: 수수께끼의 실루엣.</p>
<p>__</p>
<p>질문 7.10</p>
<p>그림 7.11에는 3차원 물체의 2차원 투영이 있습니다. 이 물체는 무엇일까요?</p>
<p>__</p>
<p>질문 7.11</p>
<p>그림 7.11과 7.13 중 어느 투영이 더 정보가 많다고 생각하시나요? 그 이유는 무엇인가요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>그림자의 면적을 최대화하는 투영이 더 많은 ’정보’를 보여준다고 주장할 수 있습니다.</p>
</section>
</section>
<section id="pca-워크플로" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="pca-워크플로"><span class="header-section-number">9.4</span> 7.5 PCA 워크플로</h2>
<p><a href="imgs/orgacp1.png" title="그림 7.12: PCA 처리 과정 중 많은 선택이 이루어져야 합니다."><img src="imgs/orgacp1.png" class="img-fluid"></a></p>
<p>그림 7.12: PCA 처리 과정 중 많은 선택이 이루어져야 합니다.</p>
<p>PCA는 가장 큰 관성/가변성을 보여주는 축을 찾고, 그 방향의 가변성을 제거한 다음, 그 다음으로 좋은 직교 축을 찾는 과정을 반복하는 원리에 기반합니다. 사실 반복해서 실행할 필요 없이, <strong>특잇값 분해(Singular Value Decomposition, SVD)</strong>라고 불리는 하나의 선형 대수 연산으로 모든 축을 찾을 수 있습니다(이에 대한 자세한 내용은 아래에서 다룰 것입니다).</p>
<p>그림 7.12의 다이어그램에서, 먼저 평균과 분산이 계산되고 공분산 행렬로 직접 작업할지 아니면 상관 행렬로 작업할지 선택해야 함을 알 수 있습니다. 다음 단계는 데이터에 유의미하다고 간주되는 성분의 수인 \(k\)를 선택하는 것입니다. 우리는 \(k\)를 근사(approximation)의 계수(rank)라고 말합니다. 최적의 \(k\)를 선택하는 것은 어려운 문제이며, 아래에서 어떻게 접근해야 할지 논의할 것입니다. \(k\)를 선택하려면 연속적인 주성분들에 의해 설명되는 분산의 플롯을 살펴보아야 합니다. 일단 \(k\)를 선택했다면, 새로운 \(k\)차원 하위 공간으로의 데이터 투영을 진행할 수 있습니다.</p>
<p>PCA 워크플로의 최종 결과는 변수와 샘플 모두에 대한 유용한 맵(maps)입니다. 이러한 맵들이 어떻게 구축되는지 이해하면 그로부터 얻을 수 있는 정보를 극대화할 수 있을 것입니다.</p>
</section>
<section id="pca의-내부-구조-계수-축소rank-reduction" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="pca의-내부-구조-계수-축소rank-reduction"><span class="header-section-number">9.5</span> 7.6 PCA의 내부 구조: 계수 축소(Rank reduction)</h2>
<p>이 섹션은 선형 대수학 배경 지식이 희미한 기억으로만 남아 있는 분들을 위한 짧은 섹션입니다. 너무 많은 수식 없이 PCA의 기초가 되는 특잇값 분해 방법에 대한 직관을 제공하고자 합니다.</p>
<p><a href="imgs/CAM4.png" title="그림 7.13: 그림 7.11에서 보여준 것과 동일한 물체의 또 다른 2차원 투영. 여기서의 관점이 더 정보가 많습니다. 일반적으로 점들의 퍼짐(다시 말해 분산)이 최대가 되도록 관점을 선택하는 것이 가장 많은 정보를 제공합니다. 우리는 가능한 한 많은 변동을 보고 싶어 하며, 그것이 바로 PCA가 하는 일입니다."><img src="imgs/CAM4.png" class="img-fluid"></a></p>
<p>그림 7.13: 그림 7.11에서 보여준 것과 동일한 물체의 또 다른 2차원 투영. 여기서의 관점이 더 정보가 많습니다. 일반적으로 점들의 퍼짐(다시 말해 분산)이 최대가 되도록 관점을 선택하는 것이 가장 많은 정보를 제공합니다. 우리는 가능한 한 많은 변동을 보고 싶어 하며, 그것이 바로 PCA가 하는 일입니다.</p>
<p>행렬의 특잇값 분해는 수평 및 수직 벡터(특잇값 벡터라 불림)와 정규화 값(특잇값이라 불림)을 찾습니다. 이전과 마찬가지로, 분해를 생성하는 데 사용되는 실제 역설계(reverse engineering)를 수행하기 전에 순방향 생성(forward-generative) 설명을 먼저 제공하겠습니다. 각 단계의 의미를 보정하기 위해, 실제 데이터의 복잡함으로 넘어가기 전에 인위적인 예시부터 시작하겠습니다.</p>
<section id="계수-1-행렬rank-one-matrices" class="level3" data-number="9.5.1">
<h3 data-number="9.5.1" class="anchored" data-anchor-id="계수-1-행렬rank-one-matrices"><span class="header-section-number">9.5.1</span> 7.6.1 계수 1 행렬(Rank-one matrices)</h3>
간단한 생성 모델은 <strong>행렬의 계수(rank of a matrix)</strong>의 의미를 보여주고 우리가 이를 실제로 어떻게 찾는지 설명해 줍니다. 두 개의 벡터 \(u\)(1열 행렬)와 \(v^t=t(v)\)(1행 행렬 — 1열 행렬 \(v\)의 전치)가 있다고 가정해 봅시다. 예를 들어, \(u =(
<span class="math display">\[\begin{smallmatrix} 1\\\2\\\3\\\4 \end{smallmatrix}\]</span>
)\)이고 \(v =(
<span class="math display">\[\begin{smallmatrix} 2\\\4\\\8 \end{smallmatrix}\]</span>
<p>)\)입니다. \(v\)의 전치는 \(v^t = t(v) = (2; 4; 8)\)로 쓰여집니다. 우리는 다음과 같이 \(u\)의 복사본에 \(v^t\)의 각 원소를 차례로 곱합니다:</p>
<p>단계 0:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>2</th>
<th>4</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>2</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>단계 1:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>2</th>
<th>4</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>2</td>
<td>4</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td>6</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td>8</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>단계 2:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>2</th>
<th>4</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>4</td>
<td></td>
</tr>
<tr class="even">
<td>2</td>
<td>4</td>
<td>8</td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td>6</td>
<td>12</td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td>8</td>
<td>16</td>
<td></td>
</tr>
</tbody>
</table>
<p>단계 3:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>2</th>
<th>4</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>4</td>
<td>8</td>
</tr>
<tr class="even">
<td>2</td>
<td>4</td>
<td>8</td>
<td>16</td>
</tr>
<tr class="odd">
<td>3</td>
<td>6</td>
<td>12</td>
<td>24</td>
</tr>
<tr class="even">
<td>4</td>
<td>8</td>
<td>16</td>
<td>32</td>
</tr>
</tbody>
</table>
<p>따라서 행렬 \(X\)의 \((2,3)\) 항목(entry), 즉 \(x_{2,3}\)은 \(u_2\)에 \(v_3\)를 곱하여 얻어집니다. 우리는 이를 다음과 같이 쓸 수 있습니다.</p>
<p>\[ X=]</p>
<p>여기서 우리가 얻은 행렬 \(X\)는 \(u\)와 \(v\) 모두 하나의 열을 가지므로 계수(rank)가 1이라고 합니다.</p>
<p>__</p>
<p>질문 7.12</p>
<p>왜 \(X = u*v^t\)라고 쓰는 것이 전체 행렬 \(X\)를 모두 적는 것보다 더 경제적이라고 말할 수 있을까요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>\(X\)는 \(4=12\)개의 원소를 가지는 반면, \(u\)와 \(v\)를 통해서는 단지 \(4+3=7\)개의 숫자로 표현될 수 있습니다. 이러한 압축은 \(u\)나 \(v\)가 더 길어질수록 더욱 인상적입니다.</p>
<p>반면에, 아래에 주어진 3행 4열(12개 숫자)의 또 다른 행렬 \(X\)를 단순화하기 위해 그 과정을 거꾸로 수행하고 싶다고 가정해 봅시다. 정보의 손실 없이 항상 이를 벡터들의 곱으로 비슷하게 표현할 수 있을까요? 그림 7.14와 7.15에 표시된 다이어그램에서, 색상이 칠해진 상자들은 행렬 (7.4)의 셀에 있는 숫자들에 비례하는 면적을 가집니다.</p>
<p><a href="imgs/SVD-mosaicXplot0.png" title="그림 7.14: 일부 특수한 행렬들은 분해하기 쉬운 숫자들을 포함하고 있습니다. 이 다이어그램의 각 색상 사각형은 그 안의 숫자에 해당하는 면적을 가집니다."><img src="imgs/SVD-mosaicXplot0.png" class="img-fluid"></a></p>
<p>그림 7.14: 일부 특수한 행렬들은 분해하기 쉬운 숫자들을 포함하고 있습니다. 이 다이어그램의 각 색상 사각형은 그 안의 숫자에 해당하는 면적을 가집니다.</p>
<p>__</p>
<p>질문 7.13</p>
<p>여기에 우리가 분해하고 싶은 행렬 \(X\)가 있습니다.</p>
<p>\[ ]</p>
<p>\(X\)는 그림 7.14에서 일련의 사각형들로 다시 그려졌습니다. 사각형의 변의 값들을 곱했을 때 해당 숫자들이 나오도록 하려면 흰색 \(u\)와 \(v\) 상자에 어떤 숫자들을 넣을 수 있을까요?</p>
<p>\(X\)처럼 완벽하게 “직사각형”인 특수한 성질을 가진 행렬을 계수가 1이라고 합니다. 우리는 \(X\)의 숫자들을 사각형의 면적으로 나타낼 수 있으며, 여기서 사각형의 변들은 측면 벡터(\(u\)와 \(v\))에 있는 값들에 의해 주어집니다.</p>
<p><img src="imgs/SVD-mosaicXplot1.png" class="img-fluid">: “)</p>
<ol type="a">
<li></li>
</ol>
<p><img src="imgs/SVD-mosaicXplot2.png" class="img-fluid">: “)</p>
<ol start="2" type="a">
<li></li>
</ol>
<p><img src="imgs/SVD-mosaicXplot3.png" class="img-fluid">: “)</p>
<ol start="3" type="a">
<li></li>
</ol>
<p>그림 7.15: 셀 안의 숫자들은 (a), (b), (c)에서 상응하는 여백(margins)의 곱과 같습니다. 우리는 여러 가지 방식으로 곱을 통해 셀을 만들 수 있습니다. (c)에서는 여백의 노름(norm)이 1이 되도록 강제합니다.</p>
<p>그림 7.15에서 우리는 \(X\)의 분해가 유일하지 않다는 것을 알 수 있습니다: 벡터 \(u\)와 \(v\)에 대해 여러 가지 후보 선택지가 있습니다. 우리는 각 벡터 원소의 제곱합이 1이 되도록 요구함으로써 선택을 유일하게 만들 것입니다 (벡터 \(v\)와 \(u\)가 노름 1을 갖는다고 말합니다). 그러면 우리는 각 곱에 곱해줄, \(X\)의 “전체적인 스케일”을 나타내는 추가적인 숫자 하나를 추적해야 합니다. 이것이 우리가 왼쪽 상단 모서리에 넣은 값입니다. 이를 첫 번째 특잇값 \(s_1\)이라고 부릅니다. 아래 R 코드에서, 우리는 먼저 <code>u</code>, <code>v</code>, <code>s1</code>의 값을 알고 있다고 가정하고 시작하겠습니다. 나중에 우리를 위해 이들을 찾아주는 함수를 볼 것입니다. R에서 곱셈과 노름 속성을 확인해 봅시다:</p>
<pre><code>X = matrix(c(780,  75, 540,
             936,  90, 648,
            1300, 125, 900,
             728,  70, 504), nrow = 3)
u = c(0.8196, 0.0788, 0.5674)
v = c(0.4053, 0.4863, 0.6754, 0.3782)
s1 = 2348.2
sum(u^2)__


[1] 1


sum(v^2)__


[1] 1


s1 * u %*% t(v)__


     [,1] [,2] [,3] [,4]
[1,]  780  936 1300  728
[2,]   75   90  125   70
[3,]  540  648  900  504


X - s1 * u %*% t(v)__


         [,1]   [,2]   [,3]   [,4]
[1,] -0.03419 0.0745 0.1355 0.1221
[2,]  0.00403 0.0159 0.0252 0.0186
[3,] -0.00903 0.0691 0.1182 0.0982</code></pre>
<p>__</p>
<p>Question 7.14</p>
<p>Try <code>svd(X)</code> in R. Look at the components of the output of the <code>svd</code> function carefully. Check the norm of the columns of the matrices that result from this call. Where did the above value of <code>s1</code> = 2348.2 come from?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<pre><code>svd(X)$u[, 1]
svd(X)$v[, 1]
sum(svd(X)$u[, 1]^2)
sum(svd(X)$v[, 1]^2)
svd(X)$d __</code></pre>
<p>In fact, in this particular case we were lucky: we see that the second and third singular values are 0 (up to the numeric precision we care about). That is why we say that \(X\) is of <strong>rank</strong> 1. For a more general matrix \(X\), it is rare to be able to write \(X\) exactly as this type of two- vector product. The next subsection shows how we can decompose \(X\) when it is not of rank 1: we will just need more pieces.</p>
</section>
<section id="how-do-we-find-such-a-decomposition-in-a-unique-way" class="level3" data-number="9.5.2">
<h3 data-number="9.5.2" class="anchored" data-anchor-id="how-do-we-find-such-a-decomposition-in-a-unique-way"><span class="header-section-number">9.5.2</span> 7.6.2 How do we find such a decomposition in a unique way?</h3>
<p>In the above decomposition, there were three elements: the horizontal and vertical singular vectors, and the diagonal corner, called the singular value. These can be found using the singular value decomposition function (<code>svd</code>). For instance:</p>
<pre><code>Xtwo = matrix(c(12.5, 35.0, 25.0, 25, 9, 14, 26, 18, 16, 21, 49, 32,
       18, 28, 52, 36, 18, 10.5, 64.5, 36), ncol = 4, byrow = TRUE)
USV = svd(Xtwo)__</code></pre>
<p>__</p>
<p>Question 7.15</p>
<p>Look at the <code>USV</code> object, the result of calling the <code>svd</code> function. What are its components?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<pre><code>names(USV)__


[1] "d" "u" "v"


USV$d __</code></pre>
<p>따라서 135.1이 첫 번째 특잇값 <code>USV$d[1]</code>입니다.</p>
<p>__</p>
<p>질문 7.16</p>
<p>각각의 연속적인 특잇값 벡터 쌍이 <code>Xtwo</code>에 대한 근사를 어떻게 개선하는지 확인해 보세요. 세 번째와 네 번째 특잇값에 대해 무엇을 알 수 있나요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<pre><code>Xtwo - USV$d[1] * USV$u[, 1] %*% t(USV$v[, 1])
Xtwo - USV$d[1] * USV$u[, 1] %*% t(USV$v[, 1]) -
       USV$d[2] * USV$u[, 2] %*% t(USV$v[, 2])__</code></pre>
<p>세 번째와 네 번째 특잇값은 매우 작아서 (반올림 오차 범위 내에서) 근사를 개선하지 못하므로, 우리는 <code>Xtwo</code>의 계수가 2라고 결론 내릴 수 있습니다.</p>
<p>다시 말하지만, <code>Xtwo</code>와 같은 계수가 2인 행렬을 계수 1인 행렬들의 합으로 쓰는 방법은 여러 가지가 있습니다: 유일성을 보장하기 위해 우리는 특잇값 벡터에 또 다른7 조건을 부과합니다. 특잇값 분해의 출력 벡터들은 노름이 1일 뿐만 아니라, \(U\) 행렬의 각 열 벡터는 이전의 모든 열 벡터들과 직교(orthogonal)합니다. 우리는 이를 \(u_{} u_{}\)라고 쓰며, 이는 동일한 위치에 있는 값들의 곱의 합이 0임을 의미합니다: \(<em>i u</em>{i1} u_{i2} = 0\). \(V\) 행렬에 대해서도 마찬가지입니다.</p>
<p>7 위에서 우리는 벡터의 노름을 1로 선택했었습니다.</p>
<p>__</p>
<p>태스크</p>
<p>\(U\)와 \(V\) 행렬의 교차 곱(cross product)을 계산하여 정규 직교성(orthonormality)을 확인해 보세요:</p>
<pre><code>t(USV$u) %*% USV$u
t(USV$v) %*% USV$v __</code></pre>
<p>우리의 <code>scaledTurtles</code> 행렬을 특잇값 분해해 봅시다.</p>
<pre><code>turtles.svd = svd(scaledTurtles)
turtles.svd$d __


[1] 11.746475  1.419035  1.003329


turtles.svd$v __


          [,1]       [,2]        [,3]
[1,] 0.5787981  0.3250273  0.74789704
[2,] 0.5779840  0.4834699 -0.65741263
[3,] 0.5752628 -0.8127817 -0.09197088


dim(turtles.svd$u)__


[1] 48  3</code></pre>
<p>__</p>
<p>질문 7.17</p>
<p><code>svd</code> 출력으로부터 거북이 행렬에 대해 무엇을 결론지을 수 있나요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p><code>turtles.svd$v</code>의 첫 번째 열은 세 변수에 대한 계수가 거의 동일함을 보여줍니다. 다른 눈에 띄는 “우연”들은 다음과 같습니다:</p>
<pre><code>sum(turtles.svd$v[,1]^2)__


[1] 1


sum(turtles.svd$d^2) / 47 __


[1] 3</code></pre>
<p>계수들이 실제로는 \(\)이며 특잇값의 제곱합이 \((n-1)p\)와 같음을 알 수 있습니다.</p>
</section>
<section id="특잇값-분해singular-value-decomposition" class="level3" data-number="9.5.3">
<h3 data-number="9.5.3" class="anchored" data-anchor-id="특잇값-분해singular-value-decomposition"><span class="header-section-number">9.5.3</span> 7.6.3 특잇값 분해(Singular value decomposition)</h3>
<p><img src="imgs/SumRankOneD.png" class="img-fluid"></p>
<p>\(X\)는 계수 1인 조각들로 가산적으로(additively) 분해됩니다. 각 \(u\) 벡터는 \(U\) 행렬로 결합되고, 각 \(v\) 벡터는 \(V\) 행렬로 결합됩니다. <strong>특잇값 분해</strong>는 다음과 같습니다.</p>
<p>\[ {X} = U S V^t, V^t V={I}, U^t U={I}, \]</p>
<p>여기서 \(S\)는 특잇값들의 대각 행렬(diagonal matrix)이고, \(V^t\)는 \(V\)의 전치 행렬이며, \({I}\)는 단위 행렬(Identity matrix)입니다. 식 7.5는 원소별로 다음과 같이 쓰여질 수 있습니다.</p>
<p>\[ X_{ij} = u_{i1}s_1v_{1j} + u_{i2}s_2v_{2j} + u_{i3}s_3v_{3j} +… + u_{ir}s_rv_{rj}, \]</p>
<p>\(U\)와 \(V\)는 그들 자신의 교차 곱이 단위 행렬이므로 정규 직교(orthonormal)8라고 합니다.</p>
<p>8 정규 분포(normal distribution)와는 아무런 관련이 없으며, 직교(orthogonal)하면서 노름이 1임을 나타냅니다.</p>
</section>
<section id="주성분principal-components" class="level3" data-number="9.5.4">
<h3 data-number="9.5.4" class="anchored" data-anchor-id="주성분principal-components"><span class="header-section-number">9.5.4</span> 7.6.4 주성분(Principal components)</h3>
<p>특잇값 분해(R의 <code>svd</code> 함수에서 제공)에서 얻은 특잇값 벡터는 원래의 변수 앞에 붙여서 우리가 주성분이라고 부르는 더 정보가 많은 변수들을 만드는 계수들을 포함하고 있습니다. 우리는 이를 다음과 같이 씁니다:</p>
<p>\[ Z_1=v_{11} X_{} +v_{21} X_{} + v_{31} X_{}+ + v_{p1} X_{p}. \]</p>
<p>만약 <code>usv = svd(X)</code>라면, \((v_{11},v_{21},v_{31},…)\)은 <code>usv$v</code>의 첫 번째 열에 의해 주어집니다; 유사하게 \(Z_2\)는 <code>usv$v</code>의 두 번째 열에 의해 주어지는 식입니다. \(p\)는 \(X\)의 열의 수이자 \(V\)의 행의 수입니다. 이러한 새로운 변수 \(Z_1, Z_2, Z_3, …\)는 크기가 감소하는 분산을 가집니다: \(s_1^2 s_2^2 s_3^2 …\).</p>
<p>__</p>
<p>질문 7.18</p>
<p>첫 번째 특잇값 <code>d[1]</code>과 <code>u[,1]</code>을 곱하여 거북이 데이터의 첫 번째 주성분을 계산해 보세요. 이를 계산하는 또 다른 방법은 무엇일까요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>다음 코드를 사용하여 이를 보여줍니다:</p>
<pre><code>US = turtles.svd$u[,1, drop = FALSE] %*% turtles.svd$d[1]
XV = scaledTurtles %*% turtles.svd$v[, 1, drop = FALSE]
max(abs(US-XV))__</code></pre>
<p>우리는 또한 행렬 대수를 사용하여 \(XV\)와 \(US\)가 같음을 알 수 있습니다. \(V\)가 직교하므로 \(V^t V={I}\)이고 \(XV = USV^tV=US,{I}\)임을 기억하세요.</p>
<p><em>참고:</em> 아래 코드의 첫 번째 줄에 있는 <code>drop = FALSE</code> 인수는 선택된 행렬 열이 <em>matrix</em> / <em>array</em> 클래스 속성을 유지하도록 하여 행렬 곱셈 연산이 가능하도록 보장합니다. 대안으로 일반 곱셈 연산자 <code>*</code>를 사용할 수도 있습니다. 두 번째 줄에서 <code>drop = FALSE</code>는 엄밀히 말해 필요하지 않지만 대칭을 위해 넣었습니다.</p>
<p>여기에 두 가지 유용한 사실이 있습니다. 먼저 말로 설명하고, 그 다음 수학적 기호로 나타내겠습니다.</p>
<p>주성분의 수 \(k\)는 항상 원래 변수의 수나 관측치 수보다 적게 선택됩니다. 우리는 문제의 차원을 “낮추고” 있는 것입니다:</p>
<p>\[ k(n,p). \]</p>
<p>주성분 변환은 첫 번째 주성분이 가능한 가장 큰 분산을 갖도록(즉, 데이터의 가변성을 가능한 한 많이 설명하도록) 정의되며, 각 후속 성분은 이전 성분들과 직교해야 한다는 제약 조건 하에서 순차적으로 가장 높은 분산을 갖습니다:</p>
<p>\[ <em>{aX bX}(</em>{aX} (X)), bX= \]</p>
</section>
</section>
<section id="주평면에-관측치-플롯하기" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="주평면에-관측치-플롯하기"><span class="header-section-number">9.6</span> 7.7 주평면에 관측치 플롯하기</h2>
<p>우리는 <code>discus</code>와 <code>weight</code> 변수가 있는 두 변수 athletes 데이터를 다시 살펴봅니다. 7.3.2절에서 우리는 첫 번째 주성분을 계산했고 이를 그림 7.10에서 보라색 선으로 나타냈습니다. 우리는 \(Z_1\)이 대각선에 의해 주어진 선형 결합임을 보여주었습니다. 계수들의 제곱합이 1이 되어야 하므로, 우리는 다음과 같은 식을 얻습니다. \[Z_1=-0.707<em>- 0.707</em>.\]</p>
<p>이는 두 좌표가 \(c_1=0.7071\) 및 \(c_2=0.7071\)인 것과 같습니다.</p>
<p>__</p>
<p>질문 7.19</p>
<p><code>svd</code> 함수의 출력 중 어떤 부분이 PC <strong>로딩(loadings)</strong>이라고도 알려진 첫 번째 PC 계수로 우리를 인도하나요?</p>
<p>우리가 두 변수 <code>discus</code>와 <code>weight</code>에 적용했던 <code>svda</code>를 사용한다는 점에 유의하세요.</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<pre><code>svda$v[,1]__


[1] -0.7071068 -0.7071068</code></pre>
<p>보라색 선을 가로 \(x\)축으로 만들어 <code>(discus, weight)</code> 평면을 회전시키면, 첫 번째 <strong>주평면(principal plane)</strong>이라고 알려진 것을 얻게 됩니다.</p>
<pre><code>ppdf = tibble(PC1n = -svda$u[, 1] * svda$d[1],
              PC2n =  svda$u[, 2] * svda$d[2])
gg = ggplot(ppdf, aes(x = PC1n, y = PC2n)) + 
    geom_point() + 
    geom_hline(yintercept = 0, color = "purple", linewidth = 1.5, alpha = 0.5) +
    xlab("PC1 ")+ ylab("PC2") + xlim(-3.5, 2.7) + ylim(-2, 2) + coord_fixed()
gg + geom_point(aes(x = PC1n, y = 0), color = "red") +
     geom_segment(aes(xend = PC1n, yend = 0), color = "red") 
gg + geom_point(aes(x = 0, y = PC2n), color = "blue") +
     geom_segment(aes(yend = PC2n, xend = 0), color = "blue") +
     geom_vline(xintercept = 0, color = "skyblue", linewidth = 1.5, alpha = 0.5) __</code></pre>
<p><a href="07-chap_files/figure- html/fig-pcablue-1.png" title="그림 7.16 (a):"><img src="07-chap_files/figure-html/fig-pcablue-1.png" class="img-fluid"></a></p>
<ol type="a">
<li></li>
</ol>
<p><a href="07-chap_files/figure- html/fig-pcablue-2.png" title="그림 7.16 (b):"><img src="07-chap_files/figure-html/fig-pcablue-2.png" class="img-fluid"></a></p>
<ol start="2" type="a">
<li></li>
</ol>
<p>그림 7.16: 원래 변수가 두 개뿐인 경우, PCA 변환은 단순한 회전입니다. 새로운 좌표는 항상 가로 및 세로 축으로 선택됩니다.</p>
<p>__</p>
<p>질문 7.20</p>
<ol type="1">
<li><p>그림 7.16에서 빨간색 세그먼트의 제곱합의 평균은 무엇과 같습니까?</p></li>
<li><p>이것이 빨간색 점들의 분산과 비교하여 어떤가요?</p></li>
<li><p>그림 7.16에서 파란색 세그먼트와 빨간색 세그먼트의 표준 편차 비율을 계산해 보세요. 이를 첫 번째와 두 번째 특잇값의 비율과 비교해 보세요.</p></li>
</ol>
<p>__</p>
<p>해결책</p>
<p>__</p>
<ol type="1">
<li>빨간색 세그먼트의 제곱합은 두 번째 특잇값의 제곱에 해당합니다:</li>
</ol>
<pre><code>sum(ppdf$PC2n^2) __


[1] 6.196729


svda$d[2]^2 __


[1] 6.196729</code></pre>
<p>빨간색 세그먼트의 평균이 0이므로, 위의 수치들은 또한 분산에 비례합니다:</p>
<pre><code>mean(ppdf$PC2n) __


[1] 5.451106e-16


var(ppdf$PC2n) * (nrow(ppdf)-1)__


[1] 6.196729</code></pre>
<ol start="2" type="1">
<li>The variance of the red points is <code>var(ppdf$PC1n)</code>, which is larger than what we calculated in a) by design of the first PC.</li>
</ol>
<pre><code>var(ppdf$PC1n) __


[1] 1.806352


var(ppdf$PC2n) __


[1] 0.1936478</code></pre>
<ol start="3" type="1">
<li>We take the ratios of the standard deviations explained by the points on the vertical and horizontal axes by computing:</li>
</ol>
<pre><code>sd(ppdf$PC1n) / sd(ppdf$PC2n)__


[1] 3.054182


svda$d[1] / svda$d[2]__


[1] 3.054182</code></pre>
<p>__</p>
<p>Task</p>
<p>Use <code>prcomp</code> to compute the PCA of the first two columns of the athletes data, look at the output. Compare to the singular value decomposition.</p>
<section id="pca-of-the-turtles-data" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="pca-of-the-turtles-data"><span class="header-section-number">9.6.1</span> 7.7.1 PCA of the turtles data</h3>
<p>We now want to do a complete PCA analysis on the turtles data. Remember, we already looked at the summary statistics for the one- and two-dimensional data. Now we are going to answer the question about the “true” dimensionality of these rescaled data.</p>
<p>In the following code, we use the function <code>princomp</code>. Its return value is a list of all the important pieces of information needed to plot and interpret a PCA.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="사실 PCA는 매우 기초적인 기법이라서 다양한 R 패키지에 많은 서로 다른 구현체들이 존재합니다. 불행하게도 입력 인수와 출력의 형식 및 명칭이 표준화되어 있지 않으며, 일부는 출력의 스케일링에 대해 서로 다른 관례를 사용하기도 합니다. 우리는 이러한 선택들에 익숙해지기 위해 몇 가지 서로 다른 것들을 실험해 볼 것입니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>사실 PCA는 매우 기초적인 기법이라서 다양한 R 패키지에 많은 서로 다른 구현체들이 존재합니다. 불행하게도 입력 인수와 출력의 형식 및 명칭이 표준화되어 있지 않으며, 일부는 출력의 스케일링에 대해 서로 다른 관례를 사용하기도 합니다. 우리는 이러한 선택들에 익숙해지기 위해 몇 가지 서로 다른 것들을 실험해 볼 것입니다.</figcaption>
</figure>
</div>
<p>사실 PCA는 매우 기초적인 기법이라서 다양한 R 패키지에 많은 서로 다른 구현체들이 존재합니다. 불행하게도 입력 인수와 출력의 형식 및 명칭이 표준화되어 있지 않으며, 일부는 출력의 스케일링에 대해 서로 다른 관례를 사용하기도 합니다. 우리는 이러한 선택들에 익숙해지기 위해 몇 가지 서로 다른 것들을 실험해 볼 것입니다.</p>
<pre><code>cor(scaledTurtles)__


          length     width    height
length 1.0000000 0.9783116 0.9646946
width  0.9783116 1.0000000 0.9605705
height 0.9646946 0.9605705 1.0000000


pcaturtles = princomp(scaledTurtles)
pcaturtles __


Call:
princomp(x = scaledTurtles)

Standard deviations:
   Comp.1    Comp.2    Comp.3 
1.6954576 0.2048201 0.1448180 

 3  variables and  48 observations.


library("factoextra")
fviz_eig(pcaturtles, geom = "bar", bar_width = 0.4) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-PCAturtles-1.png" title="그림 7.17: 스크리 플롯(screeplot)은 표준화된 거북이 데이터(scaledTurtles)에 대한 고윳값을 보여줍니다: 하나의 큰 값과 두 개의 작은 값이 있습니다. 데이터는 (거의) 1차원적입니다. 우리는 왜 이 차원을 크기의 축(axis of size)이라고 부르는지 보게 될 것인데, 이는 생체 데이터에서 흔히 나타나는 현상입니다 [@Jolicoeur1960]."><img src="07-chap_files/figure-html/fig-PCAturtles-1.png" class="img-fluid"></a></p>
<p>그림 7.17: 스크리 플롯(screeplot)은 표준화된 거북이 데이터(<code>scaledTurtles</code>)에 대한 고윳값을 보여줍니다: 하나의 큰 값과 두 개의 작은 값이 있습니다. 데이터는 (거의) 1차원적입니다. 우리는 왜 이 차원을 크기의 축(axis of size)이라고 부르는지 보게 될 것인데, 이는 생체 데이터에서 흔히 나타나는 현상입니다 (<a href="16-chap.html#ref-Jolicoeur1960">Jolicoeur and Mosimann 1960</a>).</p>
<p>__</p>
<p>질문 7.21</p>
<p>많은 PCA 함수들이 서로 다른 시기에 서로 다른 분야에서 일했던 다양한 팀들에 의해 만들어졌습니다. 이는 특히 명명 규칙이 다르기 때문에 혼란을 줄 수 있습니다. 세 가지를 비교해 봅시다. 다음 코드 라인들을 실행하고 결과 객체들을 살펴보세요:</p>
<pre><code>svd(scaledTurtles)$v[, 1]
prcomp(turtles[, -1])$rotation[, 1]
princomp(scaledTurtles)$loadings[, 1]
library("ade4")
dudi.pca(turtles[, -1], nf = 2, scannf = FALSE)$c1[, 1]__</code></pre>
<p><code>prcomp</code>와 <code>princomp</code> 함수에서 스케일링(scaling)을 비활성화하면 어떤 일이 일어나나요?</p>
<p>이후 내용에서는 항상 행렬 \(X\)가 중앙화되고 스케일링된 행렬을 나타낸다고 가정합니다.</p>
<p>__</p>
<p>질문 7.22</p>
<p><code>prcomp</code> 함수(결과를 <code>res</code>라고 합시다)에서 새로운 변수들에 대한 관측치의 좌표는 결과의 <code>scores</code> 슬롯에 있습니다. 거북이 데이터에 대한 PC1을 살펴보고 이를 <code>res$scores</code>와 비교해 보세요. 표준 편차 <code>sd1</code>을 <code>res</code> 객체에 있는 값 및 점수(scores)들의 표준 편차와 비교해 보세요.</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<pre><code>res = princomp(scaledTurtles)
PC1 = scaledTurtles %*% res$loadings[,1]
sd1 = sqrt(mean(res$scores[, 1]^2))__</code></pre>
<p>__</p>
<p>질문 7.23</p>
<p><code>res$scores</code> 행렬의 직교성(orthogonality)을 확인해 보세요. 왜 이것이 <strong>정규 직교(orthonormal)</strong>한다고 말할 수 없을까요?</p>
<p>이제 우리는 PC 점수(\(US\))와 로딩 계수(\(V\))를 결합할 것입니다. 샘플과 변수가 모두 표시된 플롯을 <strong>바이플롯(biplots)</strong>이라고 합니다. 이는 다음 <strong><a href="https://cran.r-project.org/web/packages/factoextra/">factoextra</a></strong> 패키지 함수를 사용하여 한 줄로 수행할 수 있습니다.</p>
<pre><code>fviz_pca_biplot(pcaturtles, label = "var", habillage = turtles[, 1]) +
  ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-turtlebiplot-1.png" title="그림 7.18: 변수와 관측치를 모두 보여주는 처음 두 차원의 바이플롯. 화살표는 변수를 나타냅니다. 거북이들은 성별에 따라 레이블이 붙어 있습니다. 가로 방향으로 길게 뻗은 것은 두 번째 고윳값보다 훨씬 큰 첫 번째 고윳값의 크기 때문입니다."><img src="07-chap_files/figure-html/fig-turtlebiplot-1.png" class="img-fluid"></a></p>
<p>그림 7.18: 변수와 관측치를 모두 보여주는 처음 두 차원의 바이플롯. 화살표는 변수를 나타냅니다. 거북이들은 성별에 따라 레이블이 붙어 있습니다. 가로 방향으로 길게 뻗은 것은 두 번째 고윳값보다 훨씬 큰 첫 번째 고윳값의 크기 때문입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="PCA를 플로팅할 때 종횡비(aspect ratio)에 주의하십시오. 두 성분의 노름이 비슷한 경우는 드물기 때문에, 정사각형 형태의 플롯은 예외적일 것입니다. 가로(첫 번째) 주성분이 두 번째보다 더 중요하다는 것을 보여주는 길쭉한 형태의 플롯이 더 일반적입니다. 이는 예를 들어 플롯에서 점들 사이의 거리를 해석할 때 중요합니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>PCA를 플로팅할 때 종횡비(aspect ratio)에 주의하십시오. 두 성분의 노름이 비슷한 경우는 드물기 때문에, 정사각형 형태의 플롯은 예외적일 것입니다. 가로(첫 번째) 주성분이 두 번째보다 더 중요하다는 것을 보여주는 길쭉한 형태의 플롯이 더 일반적입니다. 이는 예를 들어 플롯에서 점들 사이의 거리를 해석할 때 중요합니다.</figcaption>
</figure>
</div>
<p>PCA를 플로팅할 때 종횡비(aspect ratio)에 주의하십시오. 두 성분의 노름이 비슷한 경우는 드물기 때문에, 정사각형 형태의 플롯은 예외적일 것입니다. 가로(첫 번째) 주성분이 두 번째보다 더 중요하다는 것을 보여주는 길쭉한 형태의 플롯이 더 일반적입니다. 이는 예를 들어 플롯에서 점들 사이의 거리를 해석할 때 중요합니다.</p>
<p>__</p>
<p>질문 7.24</p>
<p>PC1이 가로축인 PCA 플롯에서 너비보다 높이가 더 길게 나타나는 것이 가능할까요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>PC1 방향으로의 점들의 분산은 \(_1=s_1^2\)이며 이는 항상 \(_2=s_2^2\)보다 큽니다. 따라서 PCA 플롯은 항상 높이보다 너비가 더 넓을 것입니다.</p>
<p>__</p>
<p>질문 7.25</p>
<p>그림 7.18을 보고 답해 보세요: a) 수컷과 암컷 거북이 중 어느 쪽이 더 큰 경향이 있나요?<br>
b) 화살표들은 상관관계에 대해 무엇을 말해주나요?</p>
<p>__</p>
<p>질문 7.26</p>
<p>각 새로운 좌표의 분산을 PCA <code>dudi.pca</code> 함수가 반환하는 고윳값(eigenvalues)과 비교해 보세요.</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<pre><code>pcadudit = dudi.pca(scaledTurtles, nf = 2, scannf = FALSE)
apply(pcadudit$li, 2, function(x) sum(x^2)/48)__


     Axis1      Axis2 
2.93573765 0.04284387 


pcadudit$eig __


[1] 2.93573765 0.04284387 0.02141848</code></pre>
<p>이제 이른바 상관관계 원(correlation circle)을 그려서 기존 변수와 새로운 변수 사이의 관계를 살펴봅니다. 여기서는 종횡비가 1이며 변수들은 그림 7.19에서 보듯이 화살표로 표현됩니다. 화살표의 길이는 첫 번째 주평면으로의 투영 품질을 나타냅니다:</p>
<pre><code>fviz_pca_var(pcaturtles, col.circle = "black") + ggtitle("") +
  xlim(c(-1.2, 1.2)) + ylim(c(-1.2, 1.2))__</code></pre>
<p><a href="07-chap_files/figure-html/fig-turtlesCirclef-1.png &quot;그림 7.19: 원래 변수들을 보여주는 &quot;상관관계 원&quot;의 일부. 서로 간의 상관관계 및 새로운 주성분과의 상관관계는 벡터들 사이의 각도와 축과 벡터 사이의 각도로 주어집니다.&quot;"><img src="07-chap_files/figure-html/fig- turtlesCirclef-1.png" class="img-fluid"></a></p>
<p>그림 7.19: 원래 변수들을 보여주는 “상관관계 원”의 일부. 서로 간의 상관관계 및 새로운 주성분과의 상관관계는 벡터들 사이의 각도와 축과 벡터 사이의 각도로 주어집니다.</p>
<p>__</p>
<p>질문 7.27</p>
<p>우리 거북이 데이터 행렬의 행 수와 다음 숫자들 사이의 관계를 설명해 보세요:</p>
<pre><code>svd(scaledTurtles)$d/pcaturtles$sdev
sqrt(47)__</code></pre>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>분산-공분산 행렬을 계산할 때, 많은 구현체들은 분모로 \(1/(n-1)\)을 사용합니다. 여기서 \(n=48\)이므로 분산의 합은 48/47의 인자만큼 차이가 납니다.</p>
<p>이 데이터는 때때로 데이터의 거의 모든 변동이 더 낮은 차원의 공간에 캡처될 수 있다는 좋은 예입니다: 여기서는 3차원 데이터가 본질적으로 하나의 선으로 대체될 수 있습니다. 다음을 명심하세요: \(X<sup>tC=VSU</sup>tUS=VS^2.\) <strong>주성분</strong>은 행렬 \(C=US\)의 열들입니다. \(U\)(\(\) 함수의 출력에서 <code>USV$u</code>로 주어지는 행렬)의 \(p\)개 열들은 노름 \((s_1^2, s_2^2, …, s_p^2)\)을 갖도록 스케일이 조정됩니다. 각 열은 자신이 설명해야 할 _책임_이 있는 서로 다른 분산을 가집니다. 이들은 감소하는 숫자들이 될 것임에 주목하세요.</p>
<p>만약 첫 번째 것만 원한다면 그것은 단지 \(c_1=s_1 u_1\)입니다. \(||c_1||<sup>2=s_1</sup>tu_1 u_1^t s_1= s_1^2 u_1<sup>tu_1=s_1</sup>2=_1\)임을 주목하세요.</p>
<p>만약 행렬 \(X\)가 \(n\)개의 서로 다른 샘플이나 표본에 대한 연구로부터 나왔다면, 주성분은 그림 7.16에서처럼 이 \(n\)개 점들에 대한 새로운 좌표를 제공합니다. 이들은 때때로 PCA 함수의 결과에서 _점수(scores)_라고 불립니다.</p>
<p><a href="imgs/xkcdEigenVectors.jpg" title="그림 7.20: 또 다른 훌륭한 xkcd의 시각: 이번에는 고유벡터입니다."><img src="imgs/xkcdEigenVectors.jpg" class="img-fluid"></a></p>
<p>그림 7.20: 또 다른 훌륭한 xkcd의 시각: 이번에는 고유벡터입니다.</p>
<p>더 자세한 예제로 들어가기 전에, SVD와 PCA가 제공하는 것을 요약해 봅시다:</p>
<ul>
<li><p>각 주성분은 해당 고윳값(상응하는 특잇값의 제곱)으로 측정되는 분산을 가집니다.</p></li>
<li><p>새로운 변수들은 서로 직교하도록 만들어집니다. 이들은 또한 중앙화되어 있으므로, 이는 서로 상관관계가 없음을 의미합니다. 정규 분포 데이터의 경우, 이는 또한 서로 독립임을 의미합니다.</p></li>
<li><p>변수들이 스케일링되었을 때, 모든 변수의 분산 합은 변수의 수(\( = p\))와 같습니다. 분산의 합은 교차 곱 행렬의 대각선을 더하여 계산됩니다9.</p></li>
<li><p>주성분들은 고윳값의 크기 순서대로 정렬됩니다. 우리는 몇 개의 성분을 유지할지 결정하기 전에 항상 스크리 플롯을 확인합니다. 또한 그림 7.18에서 했던 것처럼 각 PC 축에 그것이 설명하는 분산의 비율을 주석으로 다는 것이 가장 좋은 관행입니다.</p></li>
</ul>
<p><strong>고유 분해(Eigen Decomposition):</strong> X와 그 자신과의 교차 곱은 \[X<sup>tX=VSU</sup>tUSV<sup>t=VS</sup>2V<sup>t=VV</sup>t\]를 만족하며, 여기서 \(V\)는 대칭 행렬 \(X^tX\)의 고유벡터 행렬이라 불리고 \(\)는 \(X^tX\)의 고윳값들의 대각 행렬입니다.</p>
<p>9 이 대각 원소들의 합을 행렬의 <strong>대각합(trace)</strong>이라고 부릅니다.</p>
<p>__</p>
<p>태스크</p>
<p>위키백과에서 고윳값(eigenvalue)을 찾아보세요. 공식을 사용하지 않고 이를 정의하는 문장을 찾아보세요. 왜 고유벡터가 신데렐라에서 사용될 수 있을까요(약간 억지스럽게 말이죠)? (그림 7.20의 xkcd 만화를 참조하세요.)</p>
<p><img src="imgs/book_icon.png" class="img-fluid"></p>
<p>For help with the basics of linear algebra, a motivated student pressed for time may consult <a href="https://www.khanacademy.org/math/linear-%20algebra/alternate-bases/eigen-everything/v/linear-algebra-introduction-to-%20eigenvalues-and-eigenvectors">Khan’s Academy</a>. If you have more time and would like in depth coverage, <a href="http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-%20spring-2010">Gil Strang’s MIT course</a> is a classic, and <a href="http://math.mit.edu/linearalgebra">some of the book is available online</a> (<a href="16-chap.html#ref- Strang:09">Strang 2009</a>).</p>
</section>
<section id="a-complete-analysis-the-decathlon-athletes" class="level3" data-number="9.6.2">
<h3 data-number="9.6.2" class="anchored" data-anchor-id="a-complete-analysis-the-decathlon-athletes"><span class="header-section-number">9.6.2</span> 7.7.2 A complete analysis: the decathlon athletes</h3>
<p>We started looking at these data earlier in this chapter. Here, we will follow step by step a complete multivariate analysis. First, let us have another look at the correlation matrix (rounded to 2 digits after the decimal point), which captures the bivariate associations. We already plotted it as a colored heatmap in Figure 7.3.</p>
<pre><code>cor(athletes) |&gt; round(2)__


        m100  long weight  high  m400  m110  disc  pole javel m1500
m100    1.00 -0.54  -0.21 -0.15  0.61  0.64 -0.05 -0.39 -0.06  0.26
long   -0.54  1.00   0.14  0.27 -0.52 -0.48  0.04  0.35  0.18 -0.40
weight -0.21  0.14   1.00  0.12  0.09 -0.30  0.81  0.48  0.60  0.27
high   -0.15  0.27   0.12  1.00 -0.09 -0.31  0.15  0.21  0.12 -0.11
m400    0.61 -0.52   0.09 -0.09  1.00  0.55  0.14 -0.32  0.12  0.59
m110    0.64 -0.48  -0.30 -0.31  0.55  1.00 -0.11 -0.52 -0.06  0.14
disc   -0.05  0.04   0.81  0.15  0.14 -0.11  1.00  0.34  0.44  0.40
pole   -0.39  0.35   0.48  0.21 -0.32 -0.52  0.34  1.00  0.27 -0.03
javel  -0.06  0.18   0.60  0.12  0.12 -0.06  0.44  0.27  1.00  0.10
m1500   0.26 -0.40   0.27 -0.11  0.59  0.14  0.40 -0.03  0.10  1.00</code></pre>
<p>Then we look at the screeplot, which will help us choose a rank \(k\) for representing the essence of these data.</p>
<pre><code>pca.ath = dudi.pca(athletes, scannf = FALSE)
pca.ath$eig __


 [1] 3.4182381 2.6063931 0.9432964 0.8780212 0.5566267 0.4912275 0.4305952
 [8] 0.3067981 0.2669494 0.1018542


fviz_eig(pca.ath, geom = "bar", bar_width = 0.3) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-screeplota-1.png" title="Figure 7.21: The screeplot of the athletes data indicates that most of the variation in the data can be captured in a two- dimensional plane (spanned by the first two principal components)."><img src="07-chap_files/figure-html/fig-screeplota-1.png" class="img-fluid"></a></p>
<p>Figure 7.21: The screeplot of the athletes data indicates that most of the variation in the data can be captured in a two-dimensional plane (spanned by the first two principal components).</p>
<p>The screeplot in Figure 7.21 shows a clear drop in the eigenvalues after the second one. This indicates that a good approximation will be obtained at rank 2. Let’s look at an interpretation of the first two axes by projecting the loadings of the original variables onto the two new ones, the principal components.</p>
<pre><code>fviz_pca_var(pca.ath, col.var = "blue", repel = TRUE) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-athletecorr-1.png" title="Figure 7.22: Correlation circle of the original variables."><img src="07-chap_files/figure-html/fig-athletecorr-1.png" class="img-fluid"></a></p>
<p>Figure 7.22: Correlation circle of the original variables.</p>
<p>The correlation circle Figure 7.22 displays the projection of the original variables onto the two first new principal axes. The angles between vectors are interpreted as correlations. On the right side of the plane, we have the track and field events (m110, m100, m400, m1500), and on the left, we have the throwing and jumping events. Maybe there is an opposition of skills as characterized in the correlation matrix. We did see the correlations were negative between variables from these two groups. How can we interpret this?</p>
<p>It seems that those who throw the best have lower scores in the track competitions. In fact, if we look at the original measurements, we can see what is happening. The athletes who run in short times are the stronger ones, as are the ones who throw or jump longer distances. We should probably change the scores of the track variables and redo the analysis.</p>
<p>__</p>
<p>질문 7.28</p>
<p>최고의 운동 성적이 동일한 방향으로 변하도록, 즉 대부분 양(+)의 상관관계를 갖도록 하려면 변수들을 어떻게 변환해야 할까요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>달리기 성적의 부호를 바꾸면 거의 모든 변수가 양의 상관관계를 갖게 됩니다.</p>
<pre><code>runningvars = grep("^m", colnames(athletes), value = TRUE)
runningvars __


[1] "m100"  "m400"  "m110"  "m1500"


athletes[, runningvars] = -athletes[, runningvars]
cor(athletes) |&gt; round(2)__


       m100 long weight high  m400 m110  disc pole javel m1500
m100   1.00 0.54   0.21 0.15  0.61 0.64  0.05 0.39  0.06  0.26
long   0.54 1.00   0.14 0.27  0.52 0.48  0.04 0.35  0.18  0.40
weight 0.21 0.14   1.00 0.12 -0.09 0.30  0.81 0.48  0.60 -0.27
high   0.15 0.27   0.12 1.00  0.09 0.31  0.15 0.21  0.12  0.11
m400   0.61 0.52  -0.09 0.09  1.00 0.55 -0.14 0.32 -0.12  0.59
m110   0.64 0.48   0.30 0.31  0.55 1.00  0.11 0.52  0.06  0.14
disc   0.05 0.04   0.81 0.15 -0.14 0.11  1.00 0.34  0.44 -0.40
pole   0.39 0.35   0.48 0.21  0.32 0.52  0.34 1.00  0.27  0.03
javel  0.06 0.18   0.60 0.12 -0.12 0.06  0.44 0.27  1.00 -0.10
m1500  0.26 0.40  -0.27 0.11  0.59 0.14 -0.40 0.03 -0.10  1.00


pcan.ath = dudi.pca(athletes, nf = 2, scannf = FALSE)
pcan.ath$eig __


 [1] 3.4182381 2.6063931 0.9432964 0.8780212 0.5566267 0.4912275 0.4305952
 [8] 0.3067981 0.2669494 0.1018542</code></pre>
<p>이제 모든 음의 상관관계는 상당히 작아졌습니다. 행렬의 고윳값은 위의 부호 반전에 의해 영향을 받지 않으므로 스크리 플롯은 변하지 않을 것입니다. 바뀌는 출력값은 부호를 반전시킨 변수들에 대한 주성분 로딩(loadings) 계수의 부호뿐입니다.</p>
<pre><code>fviz_pca_var(pcan.ath, col.var = "blue", repel = TRUE) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-athletecorrn-1.png" title="그림 7.23: 달리기 변수들의 부호를 바꾼 후의 상관관계 원."><img src="07-chap_files/figure-html/fig-athletecorrn-1.png" class="img-fluid"></a></p>
<p>그림 7.23: 달리기 변수들의 부호를 바꾼 후의 상관관계 원.</p>
<p>그림 7.23은 변환된 변수들의 상관관계 원을 보여줍니다. 이제 우리는 넓은 공통의 전체 축을 가지고 있음을 알 수 있습니다: 모든 화살표가 대략 같은 방향을 가리키고 있습니다.</p>
<p>이제 다음 코드를 사용하여 주평면에 투영된 운동선수들을 플롯합니다:</p>
<pre><code>fviz_pca_ind(pcan.ath, repel = TRUE) + ggtitle("") __</code></pre>
<p><a href="07-chap_files/figure- html/fig-athletepc-1.png" title="그림 7.24: 운동선수들의 투영을 보여주는 첫 번째 주평면. 숫자들의 조직 방식에서 무언가 주목할 점이 있나요?"><img src="07-chap_files/figure-html/fig-athletepc-1.png" class="img-fluid"></a></p>
<p>그림 7.24: 운동선수들의 투영을 보여주는 첫 번째 주평면. 숫자들의 조직 방식에서 무언가 주목할 점이 있나요?</p>
<p>__</p>
<p>질문 7.29</p>
<p>그림 7.24에 표시된 운동선수들 자체를 살펴보면, 약간의 순서 효과를 알 수 있습니다. 그림 7.24에서 운동선수들의 성적과 그들의 번호 매기기 사이의 관계가 보이나요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>번호 순서대로 점들을 연결해 보면, 번호가 무작위로 매겨졌을 때보다 플롯의 한쪽 면에서 더 많은 시간을 보낸다는 것을 깨닫게 될 것입니다.</p>
<p><code>olympic</code> 데이터 세트에는 보완적인 정보가 포함되어 있음이 밝혀졌습니다. <code>score</code>라고 불리는 추가 벡터 변수는 1988년 올림픽 남자 10종 경기의 최종 점수를 보고합니다.</p>
<pre><code>olympic$score __


 [1] 8488 8399 8328 8306 8286 8272 8216 8189 8180 8167 8143 8114 8093 8083 8036
[16] 8021 7869 7860 7859 7781 7753 7745 7743 7623 7579 7517 7505 7422 7310 7237
[31] 7231 7016 6907</code></pre>
<p>그러면 운동선수들의 첫 번째 주성분 좌표와 이 점수를 비교하는 산점도를 살펴봅시다. 이는 그림 7.25에 나와 있습니다. 두 변수 사이의 강한 상관관계를 볼 수 있습니다. 1번 선수(실제로 올림픽 10종 경기 금메달을 딴 선수)가 가장 높은 점수를 얻었지만, PC1에서 가장 높은 값을 가진 것은 아님을 알 수 있습니다. 왜 그렇다고 생각하시나요?</p>
<pre><code>ggplot(data = tibble(pc1 = pcan.ath$li[, 1], score = olympic$score, label = rownames(athletes)),
       mapping = aes(y = score, x = pc1)) + 
   geom_text(aes(label = label)) + stat_smooth(method = "lm", se = FALSE)__</code></pre>
<p><a href="07-chap_files/figure-html/fig-AthleteScorePCA-1.png &quot;그림 7.25: olympic$score와 첫 번째 주성분 사이의 산점도. 점들은 데이터 세트에서의 순서로 레이블이 붙어 있습니다. 강한 상관관계를 볼 수 있습니다. 왜 완벽한 선형 적합이 아닐까요?&quot;"><img src="07-chap_files/figure-html/fig- AthleteScorePCA-1.png" class="img-fluid"></a></p>
<p>그림 7.25: <code>olympic$score</code>와 첫 번째 주성분 사이의 산점도. 점들은 데이터 세트에서의 순서로 레이블이 붙어 있습니다. 강한 상관관계를 볼 수 있습니다. 왜 완벽한 선형 적합이 아닐까요?</p>
</section>
<section id="차원-수-k를-어떻게-선택할까요" class="level3" data-number="9.6.3">
<h3 data-number="9.6.3" class="anchored" data-anchor-id="차원-수-k를-어떻게-선택할까요"><span class="header-section-number">9.6.3</span> 7.7.3 차원 수 k를 어떻게 선택할까요?</h3>
<p><a href="07-chap_files/figure- html/fig-screeploteq-1.png" title="그림 7.26: '위험할 정도로' 비슷한 분산들을 보여주는 스크리 플롯. 80%의 분산을 엄격한 임계값으로 끊기로 선택한다면 불안정한 PC 플롯을 얻게 될 것입니다. 그러한 임계값이 없다면, 3개의 유사한 고윳값을 가진 3D 하위 공간에 대응하는 축들은 불안정하며 개별적으로 해석될 수 없습니다."><img src="07-chap_files/figure-html/fig-screeploteq-1.png" class="img-fluid"></a></p>
<p>그림 7.26: ‘위험할 정도로’ 비슷한 분산들을 보여주는 스크리 플롯. 80%의 분산을 엄격한 임계값으로 끊기로 선택한다면 불안정한 PC 플롯을 얻게 될 것입니다. 그러한 임계값이 없다면, 3개의 유사한 고윳값을 가진 3D 하위 공간에 대응하는 축들은 불안정하며 개별적으로 해석될 수 없습니다.</p>
<p>우리는 예제들에서 PCA의 첫 번째 단계가 새로운 변수들의 분산(<strong>고윳값</strong>과 같음)에 대한 스크리 플롯을 만드는 것임을 보았습니다. 이 플롯을 보기 전까지는 얼마나 많은 차원이 필요한지 결정할 수 없습니다. 그 이유는 주성분이 명확하게 정의되지 않는 상황이 있기 때문입니다: 그림 7.26과 같은 스크리 플롯을 주면서 두세 개의 연속된 PC가 매우 유사한 분산을 가질 때, 유사한 고윳값 그룹에 대응하는 하위 공간이 존재합니다. 이 경우 이는 \(u_2, u_3, u_4\)에 의해 생성된 3D 공간이 될 것입니다. 이 벡터들은 개별적으로는 의미가 없으며 그 로딩을 해석할 수 없습니다. 이는 하나의 관측치에서 아주 약간의 변화만 있어도 완전히 다른 세 개의 벡터 세트를 얻을 수 있기 때문입니다. 이들은 동일한 3D 공간을 생성하겠지만, 매우 다른 로딩을 가질 수 있습니다. 우리는 이러한 PC들이 불안정하다고 말합니다.</p>
</section>
</section>
<section id="탐색적-도구로서의-pca-추가-정보-사용하기" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="탐색적-도구로서의-pca-추가-정보-사용하기"><span class="header-section-number">9.7</span> 7.8 탐색적 도구로서의 PCA: 추가 정보 사용하기</h2>
<p>우리는 회귀 분석과 달리 PCA가 모든 변수를 동일하게 취급한다는 것을 보았습니다(동등한 표준 편차를 갖도록 전처리된 범위 내에서). 그러나 결과를 해석하는 데 도움을 주기 위해 다른 연속형 변수나 범주형 요인을 플롯에 매핑하는 것은 여전히 가능합니다. 종종 우리는 샘플에 대한 보완적인 정보를 가지고 있습니다. 예를 들어 당뇨병 데이터의 진단 레이블이나 T 세포 유전자 발현 데이터의 세포 유형 등이 있습니다.</p>
<p>여기서는 우리의 해석에 정보를 주기 위해 그러한 추가 변수들을 어떻게 사용할 수 있는지 살펴봅니다. 그러한 이른바 _메타데이터(metadata)_를 저장하기에 가장 좋은 장소는 데이터 객체의 적절한 슬롯(Bioconductor <em>SummarizedExperiment</em> 클래스 등)입니다. 두 번째로 좋은 장소는 수치 데이터도 포함하는 데이터 프레임의 추가 열입니다. 실제로 그러한 정보는 종종 행렬의 행 이름에 어느 정도 암호 같은 방식으로 저장됩니다. 아래에서는 후자의 시나리오에 직면해야 하며, 우리는 <code>substr</code> 기교를 사용하여 세포 유형을 추출하고 그림 7.27의 스크리 플롯과 그림 7.28의 PCA를 보여줍니다.</p>
<pre><code>pcaMsig3 = dudi.pca(Msig3transp, center = TRUE, scale = TRUE,
                    scannf = FALSE, nf = 4)
fviz_screeplot(pcaMsig3) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-tcellexpr-1.png" title="그림 7.27: T 세포 발현 PCA 스크리 플롯."><img src="07-chap_files/figure-html/fig-tcellexpr-1.png" class="img-fluid"></a></p>
<p>그림 7.27: T 세포 발현 PCA 스크리 플롯.</p>
<pre><code>ids = rownames(Msig3transp)
celltypes = factor(substr(ids, 7, 9))
status = factor(substr(ids, 1, 3))
table(celltypes)__


celltypes
EFF MEM NAI 
 10   9  11 


cbind(pcaMsig3$li, tibble(Cluster = celltypes, sample = ids)) %&gt;%
ggplot(aes(x = Axis1, y = Axis2)) +
  geom_point(aes(color = Cluster), size = 5) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_vline(xintercept = 0, linetype = 2) +
  scale_color_discrete(name = "Cluster") + coord_fixed()__</code></pre>
<p><a href="07-chap_files/figure- html/fig-tcelltypes-1-1.png" title="그림 7.28: 세 가지 별도의 T 세포 유형(effector, naïve, memory) 각각의 특이성에 관여하는 156개 유전자 하위 집합에 대한 유전자 발현 PCA. 다시 한 번, 첫 번째 축이 분산의 많은 부분을 설명하므로 플롯이 첫 번째 축을 따라 길게 뻗어 있음을 알 수 있습니다. T 세포 중 하나가 레이블이 잘못 붙은 것으로 보인다는 점에 주목하세요."><img src="07-chap_files/figure-html/fig-tcelltypes-1-1.png" class="img-fluid"></a></p>
<p>그림 7.28: 세 가지 별도의 T 세포 유형(effector, naïve, memory) 각각의 특이성에 관여하는 156개 유전자 하위 집합에 대한 유전자 발현 PCA. 다시 한 번, 첫 번째 축이 분산의 많은 부분을 설명하므로 플롯이 첫 번째 축을 따라 길게 뻗어 있음을 알 수 있습니다. T 세포 중 하나가 레이블이 잘못 붙은 것으로 보인다는 점에 주목하세요.</p>
<section id="질량-분석-데이터-분석" class="level3" data-number="9.7.1">
<h3 data-number="9.7.1" class="anchored" data-anchor-id="질량-분석-데이터-분석"><span class="header-section-number">9.7.1</span> 7.8.1 질량 분석 데이터 분석</h3>
<p>이러한 데이터는 관련 특성을 열로, 샘플을 행으로 하는 원하는 행렬을 얻기 전에 섬세한 전처리가 필요합니다. 가공되지 않은 질량 분석 측정값에서 시작하여, 단계에는 관련 특성의 피크 추출, 여러 샘플에 걸친 정렬 및 피크 높이 추정이 포함됩니다. 끔찍한 세부 사항에 대해서는 Bioconductor <strong><a href="https://bioconductor.org/packages/xcms/">xcms</a></strong> 패키지의 비네트를 참고하시기 바랍니다. 우리는 그러한 방식으로 생성된 데이터 행렬을 <code>mat1xcms.RData</code> 파일로부터 불러옵니다. 아래 코드의 출력은 그림 7.29와 7.30에 있습니다.</p>
<pre><code>load("../data/mat1xcms.RData")
dim(mat1)__


[1] 399  12


pcamat1 = dudi.pca(t(mat1), scannf = FALSE, nf = 3)
fviz_eig(pcamat1, geom = "bar", bar_width = 0.7) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-xset3scree-1.png" title="그림 7.29: 생쥐 데이터에 대한 고윳값을 보여주는 스크리 플롯."><img src="07-chap_files/figure-html/fig-xset3scree-1.png" class="img-fluid"></a></p>
<p>그림 7.29: 생쥐 데이터에 대한 고윳값을 보여주는 스크리 플롯.</p>
<pre><code>dfmat1 = cbind(pcamat1$li, tibble(
    label = rownames(pcamat1$li),
    number = substr(label, 3, 4),
    type = factor(substr(label, 1, 2))))
pcsplot = ggplot(dfmat1,
  aes(x=Axis1, y=Axis2, label=label, group=number, colour=type)) +
 geom_text(size = 4, vjust = -0.5)+ geom_point(size = 3)+ylim(c(-18,19))
pcsplot + geom_hline(yintercept = 0, linetype = 2) +
  geom_vline(xintercept = 0, linetype = 2)__</code></pre>
<p><a href="07-chap_files/figure-html/fig-Stretchedbiplot-1.png%20%22그림%207.30:%20mat1%20데이터에%20대한%20첫%20번째%20주평면.%20분산의%2059%를%20설명합니다.%22"><img src="07-chap_files/figure-html/fig- Stretchedbiplot-1.png" class="img-fluid"></a></p>
<p>그림 7.30: <code>mat1</code> 데이터에 대한 첫 번째 주평면. 분산의 59%를 설명합니다.</p>
<p>__</p>
<p>질문 7.30</p>
<p>그림 7.30을 보면, 샘플들이 평면에 무작위로 배치된 것처럼 보이나요? 레이블에 의해 설명되는 어떤 구조를 알아차릴 수 있나요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>이 플롯을 만들어 보면 답이 (더욱) 명확해집니다. 녹아웃(Knockouts)은 항상 쌍을 이루는 야생형(wildtype) 샘플 아래에 있습니다. 우리는 다음 장에서 지도 방식의 다변량 방법(supervised multivariate methods)을 살펴볼 때 이 예시를 다시 방문할 것입니다.</p>
<pre><code>pcsplot + geom_line(colour = "red")__</code></pre>
</section>
<section id="바이플롯-및-스케일링" class="level3" data-number="9.7.2">
<h3 data-number="9.7.2" class="anchored" data-anchor-id="바이플롯-및-스케일링"><span class="header-section-number">9.7.2</span> 7.8.2 바이플롯 및 스케일링</h3>
<p>이전 예제에서는 측정된 변수의 수가 너무 많아서 변수와 샘플을 유용하게 동시에 플로팅할 수 없었습니다. 이 예제에서는 범주형 <code>wine.class</code> 변수도 있는 서로 다른 와인에 대해 화학적 측정이 이루어진 간단한 데이터 세트의 PCA 바이플롯을 그립니다. 우리는 2차원…을 살펴보는 것으로 분석을 시작합니다. correlations and a heatmap of the variables.</p>
<pre><code>library("pheatmap")
load("../data/wine.RData")
load("../data/wineClass.RData")
wine[1:2, 1:7]__


  Alcohol MalicAcid  Ash AlcAsh  Mg Phenols Flav
1   14.23      1.71 2.43   15.6 127    2.80 3.06
2   13.20      1.78 2.14   11.2 100    2.65 2.76


pheatmap(1 - cor(wine), treeheight_row = 0.2)__</code></pre>
<p><a href="07-chap_files/figure- html/fig-WineHeatplot-1.png" title="Figure 7.31: The difference between 1 and the correlation can be used as a distance between variables and is used to make a heatmap of the associations between the variables."><img src="07-chap_files/figure-html/fig-WineHeatplot-1.png" class="img-fluid"></a></p>
<p>Figure 7.31: The difference between 1 and the correlation can be used as a distance between variables and is used to make a heatmap of the associations between the variables.</p>
<p>A <strong>biplot</strong> is a simultaneous representation of both the space of observations and the space of variables. In the case of a PCA biplot like Figure 7.32 the arrows represent the directions of the old variables as they project onto the plane defined by the first two new axes. Here the observations are just colored dots, the color has been chosen according to which type of wine is being plotted. We can interpret the variables’ directions with regards to the sample points, for instance the blue points are from the barbera group and show higher Malic Acid content than the other wines.</p>
<pre><code>winePCAd = dudi.pca(wine, scannf=FALSE)
table(wine.class)__


wine.class
    barolo grignolino    barbera 
        59         71         48 


fviz_pca_biplot(winePCAd, geom = "point", habillage = wine.class,
   col.var = "violet", addEllipses = TRUE, ellipse.level = 0.69) +
   ggtitle("") + coord_fixed()__</code></pre>
<p><a href="07-chap_files/figure- html/fig-WineBiplot2-1.png" title="Figure 7.32: PCA biplot including ellipses for the three types of wine: barolo, grignolino and barbera. For each ellipsis, the axis lengths are given by one standard deviation. Small angles between the vectors Phenols, Flav and Proa indicate that they are strongly correlated, whereas Hue and Alcohol are uncorrelated."><img src="07-chap_files/figure-html/fig-WineBiplot2-1.png" class="img-fluid"></a></p>
<p>Figure 7.32: PCA biplot including ellipses for the three types of wine: barolo, grignolino and barbera. For each ellipsis, the axis lengths are given by one standard deviation. Small angles between the vectors <code>Phenols</code>, <code>Flav</code> and <code>Proa</code> indicate that they are strongly correlated, whereas <code>Hue</code> and <code>Alcohol</code> are uncorrelated.</p>
<p>Interpretation of multivariate plots requires the use of as much of the available information as possible; here we have used the samples and their groups as well as the variables to understand the main differences between the wines.</p>
</section>
<section id="an-example-of-weighted-pca" class="level3" data-number="9.7.3">
<h3 data-number="9.7.3" class="anchored" data-anchor-id="an-example-of-weighted-pca"><span class="header-section-number">9.7.3</span> 7.8.3 An example of weighted PCA</h3>
<p>Sometimes we want to see variability between different groups or observations, but want to weight them. This can be the case if, e.g., the groups have very different sizes. Let’s re-examine the Hiiragi data we already saw in <a href="03-chap.html">Chapter 3</a>. In the code below, we select the wildtype (WT) samples and the top 100 features with the highest overall variance.</p>
<pre><code>data("x", package = "Hiiragi2013")
xwt = x[, x$genotype == "WT"]
sel = order(rowVars(Biobase::exprs(xwt)), decreasing = TRUE)[1:100]
xwt = xwt[sel, ]
tab = table(xwt$sampleGroup)
tab __


     E3.25 E3.5 (EPI)  E3.5 (PE) E4.5 (EPI)  E4.5 (PE) 
        36         11         11          4          4 


xwt$weight = 1 / as.numeric(tab[xwt$sampleGroup])
pcaMouse = dudi.pca(as.data.frame(t(Biobase::exprs(xwt))),
  row.w = xwt$weight,
  center = TRUE, scale = TRUE, nf = 2, scannf = FALSE)
fviz_eig(pcaMouse) + ggtitle("")__</code></pre>
<p><a href="07-chap_files/figure- html/fig-resPCADscree-1.png" title="그림 7.33: Hiiragi 데이터의 가중 PCA에서 얻은 스크리 플롯. 두 번째 고윳값 이후의 급격한 하락은 2차원 PCA가 적절함을 시사합니다."><img src="07-chap_files/figure-html/fig-resPCADscree-1.png" class="img-fluid"></a></p>
<p>그림 7.33: Hiiragi 데이터의 가중 PCA에서 얻은 스크리 플롯. 두 번째 고윳값 이후의 급격한 하락은 2차원 PCA가 적절함을 시사합니다.</p>
<pre><code>fviz_pca_ind(pcaMouse, geom = "point", col.ind = xwt$sampleGroup) +
  ggtitle("") + coord_fixed()__</code></pre>
<p>우리는 <code>tab</code>으로부터 그룹들이 다소 불균등하게 대표되어 있음을 알 수 있습니다. 이를 설명하기 위해, 우리는 각 샘플에 해당 그룹 크기의 역수로 가중치를 다시 부여합니다. <strong><a href="https://cran.r-project.org/web/packages/ade4/">ade4</a></strong> 패키지의 <code>dudi.pca</code> 함수에는 가중치를 입력할 수 있는 <code>row.w</code> 인수가 있습니다. 코드의 출력은 그림 7.33 및 7.34에 있습니다.</p>
<p><a href="07-chap_files/figure- html/fig-resPCADplot-1.png" title="그림 7.34: Hiiragi 데이터에 대한 가중 PCA 출력. 샘플들은 그룹에 따라 색상이 입혀져 있습니다."><img src="07-chap_files/figure-html/fig-resPCADplot-1.png" class="img-fluid"></a></p>
<p>그림 7.34: Hiiragi 데이터에 대한 가중 PCA 출력. 샘플들은 그룹에 따라 색상이 입혀져 있습니다.</p>
</section>
</section>
<section id="이-장의-요약" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="이-장의-요약"><span class="header-section-number">9.8</span> 7.9 이 장의 요약</h2>
<p><strong>행렬 전처리</strong> 다변량 데이터 분석은 “의식적인” 전처리를 필요로 합니다. 모든 평균, 분산 및 1차원 히스토그램을 확인한 후, 우리는 데이터를 어떻게 재스케일링하고 중앙화하는지 보았습니다.</p>
<p><strong>새로운 변수로의 투영</strong> 우리는 고차원 데이터를 너무 많은 정보를 잃지 않으면서 낮은 차원(2D 평면과 3D가 가장 자주 사용됨)으로 투영하는 방법을 보았습니다. PCA는 원래의(기존) 변수들의 선형 결합인, 새로운 “더 정보가 많은” 변수들을 찾습니다.</p>
<p><strong>행렬 분해</strong> PCA는 SVD라 불리는 행렬 \(X\)의 분해를 찾는 것에 기반합니다. 이 분해는 낮은 계수의 근사를 제공하며 \(X^tX\)의 고유 분해와 동일합니다. 특잇값의 제곱은 새로운 변수들의 고윳값 및 분산과 같습니다. 우리는 데이터의 신호를 재현하는 데 얼마나 많은 축이 필요한지 결정하기 전에 이러한 값들을 체계적으로 플롯했습니다.</p>
<p>매우 가까운 두 고윳값은 매우 불안정한 점수(scores) 또는 PC 점수를 발생시킬 수 있습니다. 고윳값의 스크리 플롯을 살펴보고 이러한 가까운 고윳값에 해당하는 축들을 분리하는 것을 피하는 것이 항상 필요합니다. 이를 위해 여러 R 패키지에서 사용 가능한 대화형 3D 또는 4D 투영을 사용해야 할 수도 있습니다.</p>
<p><strong>바이플롯(Biplot) 표현</strong> 관측치의 공간은 자연스럽게 \(p\)차원 공간입니다 (\(p\)개의 원래 변수가 좌표를 제공합니다). 변수의 공간은 \(n\)차원입니다. 우리가 공부한 두 분해(특잇값/고윳값 및 특잇값 벡터/고유벡터)는 이 두 공간 모두에 대해 새로운 좌표를 제공하며, 때때로 우리는 하나를 다른 하나의 쌍대(dual)라고 부릅니다. 우리는 동일한 고유벡터 상에 관측치와 변수 모두의 투영을 플롯할 수 있습니다. 이는 PCA 출력을 해석하는 데 유용한 바이플롯을 제공합니다.</p>
<p><strong>다른 그룹 변수의 투영</strong> PCA의 해석은 관측치에 대한 중복되거나 인접한 데이터를 통해서도 용이해질 수 있습니다.</p>
</section>
<section id="더-읽을거리" class="level2" data-number="9.9">
<h2 data-number="9.9" class="anchored" data-anchor-id="더-읽을거리"><span class="header-section-number">9.9</span> 7.10 더 읽을거리</h2>
<p>특잇값 분해에 대한 이해를 깊게 하는 가장 좋은 방법은 Strang (<a href="16-chap.html#ref-Strang:09">2009</a>)의 7장을 읽는 것입니다. 책 전체가 행렬의 계수의 의미와 행 공간과 열 공간 사이의 쌍대성(<a href="16-chap.html#ref-frenchway">Holmes 2006</a>)을 이해하는 데 필요한 선형 대수학의 기초를 다집니다.</p>
<p>PCA 및 관련 방법들에 대해 완전한 교과서들이 쓰여졌습니다. Mardia, Kent, Bibby (<a href="16-chap.html#ref-Mardia">1979</a>)는 선형 대수와 행렬을 사용하여 고전적인 방식으로 모든 다변량 방법을 다루는 표준 텍스트입니다. 데이터가 다변량 정규 분포에서 나온다는 모수적 가정을 함으로써, Mardia, Kent, Bibby (<a href="16-chap.html#ref-Mardia">1979</a>)는 성분 수에 대한 추론적 검정과 주성분에 대한 한계 속성도 제공합니다. Jolliffe (<a href="16-chap.html#ref-Jolliffe">2002</a>)는 광범위한 예제와 함께 PCA와 관련된 모든 것을 다루는 단행본입니다.</p>
<p>우리는 관측치와 변수에 대한 가중치에 보충 정보를 통합할 수 있습니다. 이는 1970년대 프랑스 데이터 과학자들에 의해 도입되었습니다. 리뷰는 Holmes (<a href="16-chap.html#ref-frenchway">2006</a>)를, 추가 예제는 <a href="09-chap.html">9장</a>을 참조하십시오.</p>
<p>PCA의 해석과 안정성에 대한 개선은 선형 결합에 나타나는 0이 아닌 계수의 수를 최소화하는 페널티를 추가함으로써 얻어질 수 있습니다. Zou, Hastie, Tibshirani (<a href="16-chap.html#ref-Zou2006">2006</a>)와 Witten, Tibshirani, Hastie (<a href="16-chap.html#ref-Witten2009">2009</a>)는 희소(sparse) 버전의 주성분 분석을 개발했으며, 그들의 패키지 <strong><a href="https://cran.r-project.org/web/packages/elasticnet/">elasticnet</a></strong> 및 <strong><a href="https://cran.r-project.org/web/packages/PMA/">PMA</a></strong>는 R에서의 구현체를 제공합니다.</p>
</section>
<section id="연습-문제" class="level2" data-number="9.10">
<h2 data-number="9.10" class="anchored" data-anchor-id="연습-문제"><span class="header-section-number">9.10</span> 7.11 연습 문제</h2>
<p>__</p>
<p>연습 문제 7.1</p>
<p><a href="http://en.wikipedia.org/wiki/Singular_value_decomposition">SVD에 관한 위키백과 문서</a>의 섹션 1, 2, 3을 읽어 svd에 관한 내용을 복습하세요. 또한 <a href="http://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">행렬의 고유 분해에 관한 위키백과 문서</a>의 섹션 1, 2, 2.1을 읽어 관련 고유 분해에 대해 읽어보는 것도 유익할 것입니다. 우리는 \(n\)행 \(p\)열의 계수 1인 행렬 \(X\)를 다음과 같이 분해할 수 있음을 알고 있습니다:</p>
<p>\[ <strong>X</strong> = ]</p>
<ol type="1">
<li><p>\(X\)에 모든 값이 0인 행이나 열이 없다면, 이 분해는 유일할까요?</p></li>
<li><p>계수가 1인 행렬을 생성해 보세요. 먼저 2부터 30까지 2씩 증가하는 길이 15의 벡터와, 3, 6, 9, 12의 값을 가진 길이 4의 벡터를 만든 다음, 이들의 외적(outer product)을 구하세요.</p></li>
</ol>
<pre><code>u = seq(2, 30, by = 2)
v = seq(3, 12, by = 3)
X1 = u %*% t(v)__</code></pre>
<p>왜 <code>t(v)</code>를 취해야 할까요?</p>
<ol start="3" type="1">
<li>이제 <code>Materr</code>라고 부르는 행렬 형태의 노이즈를 추가하여 “거의 계수가 1인” 행렬을 만듭니다.</li>
</ol>
<pre><code>Materr = matrix(rnorm(60,1),nrow=15,ncol=4)
X = X1+Materr __</code></pre>
<p><code>ggplot</code>을 사용하여 \(X\)를 시각화하세요.</p>
<ol start="4" type="1">
<li>계수가 2인 행렬에 대해서도 동일한 분석을 수행해 보세요.</li>
</ol>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p><code>X1</code>은 다음과 같이 계산될 수도 있음에 주목하세요.</p>
<pre><code>outer(u, v)__


ggplot(data=data.frame(X), aes(x=X1, y=X2, col=X3, size=X4)) + geom_point()__</code></pre>
<p>여기서 우리는 데이터가 모든 4개 차원에서 선형으로 보임을 알 수 있습니다. 이것이 계수가 1이라는 것이 의미하는 바입니다. 이제 계수가 2인 행렬을 고려해 봅시다.</p>
<pre><code>n = 100
p = 4
Y2 = outer(rnorm(n), rnorm(p)) + outer(rnorm(n), rnorm(p))
head(Y2)__


            [,1]       [,2]         [,3]        [,4]
[1,] -0.44143871  2.3213197  0.433215525 -1.35523790
[2,]  0.79620920 -1.0748037  1.217052906 -1.13096295
[3,]  0.16787281  0.2259296  0.547203332 -0.75836031
[4,]  0.87269426 -1.9208649  0.856966180 -0.38621340
[5,]  0.03751521 -0.1480678 -0.005217966  0.05864122
[6,]  0.50195482 -2.0409896 -0.108241027  0.85336630


ggplot(data=data.frame(Y2), aes(x=X1, y=X2, col=X3, size=X4)) + geom_point()__</code></pre>
<p>데이터를 처음 두 좌표(R에서 행렬을 데이터 프레임으로 변환할 때 기본적으로 <code>X1</code> 및 <code>X2</code>라고 불림)로 투영하면 데이터가 두 차원 모두에서 변하므로, 이제 분명히 적어도 두 개의 차원이 존재합니다. 따라서 다음 단계는 두 개 이상의 차원이 있는지 결정하는 것입니다. 오른쪽 상단의 점들이 여러분과 가장 가깝고(가장 큼), 플롯에서 아래쪽과 왼쪽으로 갈수록 그 점들은 더 멀어집니다. 왼쪽에는 가장 파란 점들이 있고 오른쪽으로 갈수록 선형적으로 더 어두워지는 것 같습니다. 아마 짐작하시겠지만, “고차원”이 단지 4차원을 의미할 때조차 고차원에서 저차원 공간을 시각적으로 발견하는 것은 매우 어렵습니다. 이것이 우리가 특잇값 분해에 의존하는 한 이유입니다.</p>
<pre><code>svd(Y2)$d # 0이 아닌 2개의 고윳값 __


[1] 2.637465e+01 1.266346e+01 3.144564e-15 1.023131e-15


Y = Y2 + matrix(rnorm(n*p, sd=0.01),n,p) # Y2에 노이즈 추가
svd(Y)$d # 4개의 0이 아닌 고윳값 (하지만 큰 것은 2개뿐)__


[1] 26.39673712 12.68547439  0.10735103  0.09104741</code></pre>
<p>여기서 우리는 0이 아닌 2개의 차원과 거의 0인 2개의 차원(“Y2”의 경우, 컴퓨터 허용 오차의 제곱근 내에서 0임)을 갖습니다.</p>
<p>__</p>
<p>연습 문제 7.2</p>
<ol type="1">
<li>먼저 그림 7.35에 표시된 것과 같은 상관관계가 높은 이변량 데이터 행렬을 생성하세요.<br>
힌트: <code>mvrnorm</code> 함수를 사용하세요.</li>
</ol>
<p>특잇값을 살펴보고 행렬의 계수를 확인하세요.</p>
<ol start="2" type="1">
<li>PCA를 수행하고 회전된 주성분 축을 보여주세요.</li>
</ol>
<p>__</p>
<p>해결책</p>
<p>__</p>
<ol type="1">
<li>다음을 사용하여 상관관계가 있는 이변량 정규 데이터를 생성합니다:</li>
</ol>
<pre><code>library("MASS")
mu1 = 1; mu2 = 2; s1=2.5; s2=0.8; rho=0.9;
sigma = matrix(c(s1^2, s1*s2*rho, s1*s2*rho, s2^2),2)
sim2d = data.frame(mvrnorm(50, mu = c(mu1,mu2), Sigma = sigma))
svd(scale(sim2d))$d __


[1] 9.647686 2.218592


svd(scale(sim2d))$v[,1]__


[1] 0.7071068 0.7071068</code></pre>
<ol start="2" type="1">
<li><code>prcomp</code>를 사용하여 PCA를 수행하고 점수(scores)를 통해 원하는 회전을 제공합니다.</li>
</ol>
<pre><code>respc = princomp(sim2d)
dfpc  = data.frame(pc1=respc$scores[,1], 
                   pc2=respc$scores[,2])

ggplot(data.frame(sim2d), aes(x=X1,y=X2)) + geom_point()
ggplot(dfpc, aes(x=pc1, y=pc2)) + geom_point() + coord_fixed(2)__</code></pre>
<p><a href="07-chap_files/figure- html/fig-binormalpc-1.png" title="그림 7.35 (a): \text{}"><img src="07-chap_files/figure-html/fig-binormalpc-1.png" class="img-fluid"></a></p>
<ol type="a">
<li>\(\)</li>
</ol>
<p><a href="07-chap_files/figure- html/fig-binormalpc-2.png" title="그림 7.35 (b): \text{}"><img src="07-chap_files/figure-html/fig-binormalpc-2.png" class="img-fluid"></a></p>
<ol start="2" type="a">
<li>\(\)</li>
</ol>
<p>그림 7.35: 산점도 (A)에 표시된 원래 데이터와 주성분 회전 (B)을 사용하여 얻은 플롯.</p>
<p>__</p>
<p>연습 문제 7.3</p>
<p>그림 7.35의 (a) 부분은 매우 길쭉한 플로팅 영역을 보여주는데, 그 이유는 무엇인가요?<br>
<code>coord_fixed()</code> 옵션을 사용하지 않고 정사각형 플로팅 존을 사용하면 어떤 일이 발생하나요? 왜 이것이 오해를 불러일으킬 수 있을까요?</p>
<p>__</p>
<p>연습 문제 7.4</p>
<p>Hiiragi 데이터를 다시 살펴보고 가중 및 비가중 접근 방식을 비교해 봅시다.</p>
<ol type="1">
<li><p>가중치를 부여하지 않은 Hiiragi 데이터 <code>xwt</code>에 대해 상관관계 원을 만드세요. 어떤 유전자들이 첫 번째 주평면에 가장 잘 투영(가장 좋은 근사)되나요?</p></li>
<li><p>첫 번째 평면에서 대부분의 분산을 설명하는 극단적인 유전자 변수들의 레이블을 보여주는 바이플롯을 만드세요. 샘플 포인트들도 추가하십시오.</p></li>
</ol>
<p>Abbott, Edwin A. 1884. <em>Flatland: A Romance of Many Dimensions</em>. OUP Oxford.</p>
<p>Flury, Bernard. 1997. <em>A First Course in Multivariate Statistics</em>. Springer.</p>
<p>Holmes, Susan. 2006. “Multivariate Analysis: The French way.” In <em>Probability and Statistics: Essays in Honor of David a. Freedman</em> , edited by D. Nolan and T. P. Speed. Vol. 56. IMS Lecture Notes–Monograph Series. Beachwood, OH: IMS. <a href="http://www.imstat.org/publications/lecnotes.htm" class="uri">http://www.imstat.org/publications/lecnotes.htm</a>.</p>
<p>Holmes, Susan, Michael He, Tong Xu, and Peter P Lee. 2005. “Memory t Cells Have Gene Expression Patterns Intermediate Between Naive and Effector.” <em>PNAS</em> 102 (15): 5519–23.</p>
<p>Hotelling, Harold. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” <em>Journal of Educational Psychology</em> 24 (6): 417–41.</p>
<p>Jolicoeur, Pierre, and James E Mosimann. 1960. “Size and Shape Variation in the Painted Turtle. A Principal Component Analysis.” <em>Growth</em> 24: 339–54.</p>
<p>Jolliffe, Ian. 2002. <em>Principal Component Analysis</em>. Wiley Online Library.</p>
<p>Mardia, Kanti, John T Kent, and John M Bibby. 1979. <em>Multiariate Analysis</em>. New York: Academic Press.</p>
<p>Pearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 2 (11): 559–72.</p>
<p>Strang, Gilbert. 2009. <em>Introduction to Linear Algebra</em>. Fourth. Wellesley- Cambridge Press.</p>
<p>Witten, Daniela M, Robert Tibshirani, and Trevor Hastie. 2009. “A Penalized Matrix Decomposition, with Applications to Sparse Principal Components and Canonical Correlation Analysis.” <em>Biostatistics</em> , kxp008.</p>
<p>Zou, Hui, Trevor Hastie, and Robert Tibshirani. 2006. “Sparse Principal Component Analysis.” <em>Journal of Computational and Graphical Statistics</em> 15 (2): 265–86.</p>
<p>Page built at 01:33 on 2025-09-01 using R version 4.5.1 (2025-06-13)</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./06-chap.html" class="pagination-link" aria-label="6.1 이 장의 목표">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">6.1 이 장의 목표</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./08-chap.html" class="pagination-link" aria-label="8.1 이 장의 목표">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">8.1 이 장의 목표</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>