![](imgs/StatDiagram.png)

이전 장에서 생성 모델과 매개변수 값에 대한 지식은 우리가 의사 결정을 내리는 데 사용할 수 있는 확률을 제공했습니다 – 예를 들어, 우리가 정말로 에피토프(epitope)를 찾았는지 여부와 같은 것들입니다. 많은 실제 상황에서 생성 모델이나 매개변수 중 어느 것도 알려져 있지 않으며, 우리는 수집한 데이터를 사용하여 이를 추정해야 할 것입니다. 통계 모델링은 데이터를 바탕으로 그 데이터를 그럴듯하게 설명할 수 _있을지도 모르는_ 모델을 향해 **상향식(upwards)**으로 작동합니다1. 이러한 상향 추론 단계를 통계적 **추론(inference)**이라고 합니다. 이 장에서는 추론의 구성 요소 역할을 하는 몇 가지 분포와 추정 메커니즘을 살펴볼 것입니다. 이 장의 예제들은 모두 모수적(parametric)이지만(즉, 통계 모델이 소수의 알려지지 않은 매개변수만을 가짐), 우리가 논의하는 원칙들은 일반화될 것입니다.

1 현재의 모든 데이터를 완벽하게 설명하는 모델을 찾았더라도, 현실은 항상 더 복잡할 수 있습니다. 새로운 데이터 세트는 또 다른 모델이 필요하다는 결론을 내리게 할 수 있으며, 이는 현재 모델을 특수한 사례나 근사치로 포함할 수도 있습니다.

[![통계적 환경에서, 우리는 데이터 X로부터 시작하여 이를 사용하여 매개변수들을 추정합니다. 이러한 추정치들은 \(\widehat{\theta}\)와 같이 소위 '햇(hats)'을 씌운 그리스 문자로 표시됩니다.](imgs/devil.png)](imgs/devil.png "통계적 환경에서, 우리는 데이터 X로부터 시작하여 이를 사용하여 매개변수들을 추정합니다. 이러한 추정치들은 \(\widehat{\theta}\)와 같이 소위 '햇(hats)'을 씌운 그리스 문자로 표시됩니다.")

통계적 환경에서, 우리는 데이터 \(X\)로부터 시작하여 이를 사용하여 매개변수들을 _추정_합니다. 이러한 추정치들은 \(\widehat{\theta}\)와 같이 소위 '햇(hats)'을 씌운 그리스 문자로 표시됩니다.

이 장에서 우리는 다음을 수행할 것입니다:

  * 흔히 혼동되는 두 주제인 "확률"과 "통계" 사이에 차이가 있음을 확인합니다.

  * 히스토그램과 다른 시각화 기법을 사용하여 데이터를 확률 분포에 적합시킵니다.

  * 시뮬레이션 실험을 통해 **최대 우도(maximum likelihood)**라고 알려진 추정 절차를 처음으로 접해봅니다.

  * 사전 정보가 있는 데이터로부터 추론을 수행합니다. 이를 위해 특별히 고안된 속성을 가진 새로운 분포들이 포함된 베이지안(Bayesian) 패러다임을 사용할 것입니다. 시뮬레이션을 사용하여 베이지안 추정이 단순한 최대 우도 적용과 어떻게 다른지 살펴볼 것입니다.

  * 통계 모델과 추정을 사용하여 이항 및 다항 분포에서의 의존성을 평가합니다.

  * 표로 정리된 역사적으로 흥미로운 일부 유전체 데이터를 분석합니다.

  * **종속(dependent)** 데이터에 대한 마르코프 체인 모델을 만듭니다.

  * 전체 유전체에서 모티프(motifs)를 세는 몇 가지 구체적인 응용을 수행하고 유전체 데이터 전용의 특수한 바이오컨덕터 클래스들을 조작합니다.

![](imgs/Parameters.png)

**매개변수의 예시** : 단일 매개변수 \(\lambda\)는 푸아송 분포를 정의합니다. 그리스 문자 \(\mu\)는 흔히 정규 분포의 평균을 나타내는 데 사용됩니다. 더 일반적으로, 우리는 확률 모델을 지정하는 데 필요한 매개변수들의 일반적인 튜플(tuple)을 나타내기 위해 그리스 문자 \(\theta\)를 사용합니다. 예를 들어, 이항 분포의 경우 \(\theta=(n,p)\)는 양의 정수와 0과 1 사이의 실수라는 두 개의 숫자로 구성됩니다.

#### 매개변수가 핵심입니다.

우리는 [1장](01-chap.html)에서 에피토프 예제의 모든 매개변수 값을 알고 있을 때 확률 모델을 사용하여 손에 든 데이터를 바탕으로 귀무 가설을 테스트할 수 있음을 보았습니다. 우리는 몇 가지 실제 예제와 컴퓨터 시뮬레이션을 통해 통계 모델링에 대한 서로 다른 접근 방식들을 살펴보겠지만, 우선 가용한 정보의 양에 따른 두 가지 상황을 구분하는 것부터 시작해 봅시다.

## 2.2 통계 모델과 확률 모델의 차이점

확률적 분석은 데이터의 무작위성에 대한 좋은 생성 모델을 알고 _있고_ , 그 매개변수들의 실제 값을 알고 있을 때 가능합니다.

[![](imgs/ProbaDiagram.png)](imgs/ProbaDiagram.png "그림 2.1: [1장](01-chap.html)에서 얻은 확률 모델. 데이터는 녹색 x로 표시됩니다. 만약 \(\theta\)의 참값을 안다면, \(x\)의 모든 가능한 인스턴스에 대해, 특히 우리가 관찰한 \(x\)에 대해 \(x\)를 관찰할 확률을 계산할 수 있습니다.")

그림 2.1: [1장](01-chap.html)에서 얻은 확률 모델. 데이터는 녹색 \(x\)로 표시됩니다. 만약 \(\theta\)의 참값을 안다면, \(x\)의 모든 가능한 인스턴스에 대해, 특히 우리가 관찰한 \(x\)에 대해 \(x\)를 관찰할 확률을 계산할 수 있습니다.

에피토프 예제에서, 위양성(false positives)이 위치당 Bernoulli(0.01)로 발생한다는 것과 분석된 환자 샘플의 수, 그리고 단백질의 길이를 안다는 것은 _알려지지 않은 매개변수가 없음_을 의미했습니다.

그러한 경우, 우리는 그림 2.1에 도식화된 것과 같이 사건의 확률을 계산하기 위해 수학적 **연역(deduction)**을 사용할 수 있습니다. 에피토프 예제에서 우리는 주어진 매개변수 \(\lambda=0.5\)를 사용하여 푸아송 확률을 **귀무 모델(null model)**로 사용했습니다. 우리는 수학적 연역을 통해 7 이상의 최댓값을 볼 확률이 약 \(10^{-4}\)임을 알아낼 수 있었고, 따라서 실제로 관찰된 데이터가 그 모델(또는 "귀무 가설")하에서는 발생할 가능성이 매우 낮다는 결론을 내릴 수 있었습니다.

이제 환자 수와 단백질 길이는 알고 있지만(이들은 실험 설계에 의해 주어짐), 분포 자체와 위양성률은 모른다고 가정해 봅시다. 일단 데이터를 관찰하고 나면, 확률 모델 \(F\)(푸아송, 정규, 이항)와 결과적으로 그 모델에 대해 누락된 매개변수(들)를 추정하기 위해 데이터로부터 **상향(up)**으로 나아가야 합니다. 이것이 우리가 이 장에서 설명할 통계적 **추론(inference)**의 유형입니다.

## 2.3 통계 모델링의 간단한 예제

#### 데이터로부터 시작하기

모델링 절차에는 두 가지 부분이 있습니다. 먼저 데이터 생성 과정을 모델링하기 위한 합리적인 확률 _분포_ 가 필요합니다. [1장](01-chap.html)에서 보았듯이, 이산형 카운트 데이터는 이항, 다항 또는 푸아송 분포와 같은 간단한 확률 분포로 모델링될 수 있습니다. 정규 분포, 즉 종 모양 곡선은 연속형 측정값에 대한 좋은 모델인 경우가 많습니다. 분포는 또한 이러한 기초적인 분포들의 더 복잡한 혼합물일 수도 있습니다([4장](04-chap.html)에서 더 자세히 다룹니다).

이전 장의 에피토프 예제를 다시 살펴보되, 우선 까다로운 이상치(outlier) 없이 시작해 봅시다.

    
    
    load("../data/e100.RData")
    e99 = e100[-which.max(e100)]

#### 적합도(Goodness-of-fit) : 시각적 평가

우리의 첫 번째 단계는 후보 분포들 중에서 적합한 것을 찾는 것입니다; 이를 위해 시각적 및 정량적 적합도 플롯을 참고해야 합니다. 이산형 데이터의 경우, 그림 2.2에서와 같이 빈도의 막대 그래프를 그릴 수 있습니다 (연속형 데이터의 경우에는 히스토그램을 살펴볼 것입니다).

    
    
    barplot(table(e99), space = 0.8, col = "chartreuse4")

[![](02-chap_files/figure-html/fig-twopoisson-1.png)](02-chap_files/figure-
html/fig-twopoisson-1.png "그림 2.2: 이상치를 제외한 에피토프 데이터의 관찰된 분포.")

그림 2.2: 이상치를 제외한 에피토프 데이터의 관찰된 분포.

하지만 비교 대조군 없이 어떤 이론적 분포가 데이터에 가장 잘 맞는지 결정하기는 어렵습니다. 한 가지 시각적 **적합도** 다이어그램은 **루토그램(rootogram)** ([Cleveland 1988](16-chap.html#ref-Tukey:1988))으로 알려져 있습니다; 이는 관측된 카운트가 있는 막대들을 이론적인 빨간색 점들로부터 매달아 놓습니다. 만약 카운트가 이론적 값과 정확히 일치한다면, 상자들의 바닥이 가로축과 정확히 정렬될 것입니다.

    
    
    library("vcd")
    gf1 = goodfit( e99, "poisson")
    rootogram(gf1, xlab = "", rect_gp = gpar(fill = "chartreuse4"))

[![](02-chap_files/figure-html/fig-stat-rooto-1.png)](02-chap_files/figure-
html/fig-stat-rooto-1.png "그림 2.3: 이론적 값의 제곱근을 빨간색 점으로 표시하고 관측 빈도의 제곱근을 아래로 내려온 직사각형으로 표시한 루토그램. (아래에서 goodfit 함수가 어떤 \(\lambda\)를 사용하기로 결정했는지 살펴보겠습니다.)")

그림 2.3: 이론적 값의 제곱근을 빨간색 점으로 표시하고 관측 빈도의 제곱근을 아래로 내려온 직사각형으로 표시한 루토그램. (`goodfit` 함수가 어떤 \(\lambda\)를 사용하기로 결정했는지 아래에서 좀 더 살펴보겠습니다.)



질문 2.1

알려진 푸아송 변수를 사용하여 그러한 플롯이 어떻게 보이는지 확인하기 위해, \(\lambda\) = 0.05인 `rpois`를 사용하여 100개의 푸아송 분포 숫자를 생성하고 그 루토그램을 그려보세요.



해결책



    
    
    simp = rpois(100, lambda = 0.05)
    gf2 = goodfit(simp, "poisson")
    rootogram(gf2, xlab = "")

우리는 `e99`에 대한 루토그램이 푸아송 모델에 상당히 잘 맞는 것으로 보임을 알 수 있습니다. 하지만 이를 위해 우리가 이상치를 제거했다는 점을 기억하세요. 푸아송 분포는 흔히 푸아송 평균이라 불리는 하나의 매개변수 \(\lambda\)에 의해 완전히 결정됩니다. 데이터가 푸아송 분포를 따른다고 추측할 수 있는 대부분의 경우, 우리는 데이터로부터 푸아송 매개변수를 추정해야 할 것입니다.

[![이 매개변수는 이론적 분포의 평균이기 때문에 푸아송 평균이라고 불리며, 결과적으로 표본 평균에 의해 추정됩니다. 이 단어의 중복 사용은 모든 사람에게 혼란을 줍니다.](imgs/devil.png)](imgs/devil.png "이 매개변수는 이론적 분포의 평균이기 때문에 푸아송 평균이라고 불리며, 결과적으로 표본 평균에 의해 추정됩니다. 이 단어의 중복 사용은 모든 사람에게 혼란을 줍니다.")

이 매개변수는 이론적 분포의 평균이기 때문에 푸아송 평균이라고 불리며, _결과적으로_ 표본 평균에 의해 추정됩니다. 이 단어의 중복 사용은 모든 사람에게 혼란을 줍니다.

\(\lambda\)를 추정하는 가장 일반적인 방법은 관찰된 데이터를 가장 발생 가능하게 만드는 값 \(\hat{\lambda}\)를 선택하는 것입니다. 이를 **최대 우도 추정량(maximum likelihood estimator)** ([Rice 2006, chap. 8](16-chap.html#ref-Rice:2007), 5절)이라고 하며, 흔히 **MLE**로 축약합니다. 우리는 다음 섹션에서 다소 역설적인 이 아이디어를 설명할 것입니다.

비록 우리가 확률 분포를 추측하기 전에 극단적인 관측값을 제외하긴 했지만, 나머지 분석을 위해 해당 데이터를 다시 포함시킬 것입니다. 실제로는 이상치가 존재하는지, 그리고 어떤 데이터 포인트가 이상치인지 알지 못할 것입니다. 이를 남겨두는 효과는 평균에 대한 우리 추정치를 더 높게 만드는 것입니다. 이는 결과적으로 귀무 모델하에서 7이라는 값을 관찰할 가능성을 더 높게 만들고, 그 결과 더 큰 p-값을 내놓게 됩니다. 따라서 이상치를 포함하더라도 결과 p-값이 작다면, 우리는 우리의 분석이 실재하는 무언가를 다루고 있다고 확신할 수 있습니다. 우리는 이러한 전술을 **보수적(conservative)**이라고 부릅니다: 우리는 무언가를 탐지하지 못하는 쪽으로, 즉 조심하는 쪽으로 실수를 범하는 것입니다.

#### 푸아송 분포의 매개변수 추정하기

푸아송 평균의 어떤 값이 데이터를 가장 발생 가능하게 만들까요? 첫 번째 단계로, 결과들을 집계합니다.

    
    
    table(e100)
    
    
    e100
     0  1  2  7 
    58 34  7  1 

그런 다음 푸아송 평균에 대해 여러 가지 서로 다른 값들을 시도해 보고 우리 데이터에 가장 잘 맞는 것이 무엇인지 살펴볼 것입니다. 만약 푸아송 분포의 평균 \(\lambda\)가 3이라면, 카운트는 다음과 같을 것입니다:

    
    
    table(rpois(100, 3))
    
    
     0  1  2  3  4  5  6  7 
     4 12 23 24 14 16  4  3 

이는 우리 데이터에서 보는 것보다 훨씬 더 많은 2와 3을 포함하고 있습니다. 따라서 카운트가 잘 일치하지 않으므로 \(\lambda=3\)이 우리 데이터를 생성했을 가능성은 낮다는 것을 알 수 있습니다.



질문 2.2

\(\lambda\)의 서로 다른 값들을 사용하여 이 시뮬레이션을 반복해 보세요. 단순히 시행착오를 통해 관찰된 값에 가까운 카운트를 주는 값을 찾을 수 있나요?

그래서 우리는 많은 가능한 값들을 시도해 보고 무차별 대입(brute force)으로 진행할 수 있습니다. 하지만 우리는 좀 더 우아한 작업을 수행하여, 어떤 값이 우리 데이터를 관찰할 확률을 최대화하는지 확인하기 위해 약간의 수학을 사용할 것입니다. 푸아송 매개변수의 값이 \(m\)일 때 데이터를 볼 확률을 계산해 봅시다. 데이터가 독립적인 추출로부터 유도되었다고 가정하므로, 이 확률은 단순히 개별 확률들의 곱입니다:

\[ P(58 \times 0, 34 \times 1, 7 \times 2, \text{one }7 \;|\; \text{데이터가 푸아송}(m)\text{임}) = P(0)^{58}\times P(1)^{34}\times P(2)^{7}\times P(7)^{1}. \]

\(m=3\)에 대해 이를 계산할 수 있습니다2.

2 여기서 R의 벡터화를 어떻게 사용하는지 주목하세요: `dpois` 호출은 네 가지 서로 다른 숫자에 해당하는 네 개의 값을 반환합니다. 그런 다음 `^` 연산자를 사용하여 이들을 각각 58, 34, 7, 1의 거듭제곱으로 취하며, 다시 네 개의 값을 얻습니다. 마지막으로 `prod` 함수를 사용하여 이들을 하나의 숫자인 곱으로 합칩니다.

    
    
    prod(dpois(c(0, 1, 2, 7), lambda = 3) ^ (c(58, 34, 7, 1)))
    
    
    [1] 1.392143e-110



질문 2.3

위와 같이 \(m=0, 1, 2\)에 대해 확률을 계산하세요. \(m\)은 반드시 정수여야 하나요? 예를 들어 \(m=0.4\)에 대한 확률을 계산해 보세요.



해결책



    
    
    prod(dpois(c(0, 1, 2, 7), lambda = 0.4) ^ (c(58, 34, 7, 1)))
    
    
    [1] 8.5483e-46

이 확률은 주어진 데이터에 대한 \(\lambda\)의 **우도 함수(likelihood function)**이며, 다음과 같이 씁니다.

여기서 \(L\)은 우도를 나타내고 \(f(k)=e^{-\lambda} \,\lambda^k\,/\,k!\)는 우리가 앞서 본 푸아송 확률입니다.

\[ L\left(\lambda,\,x=(k_1,k_2,k_3,...)\right)=\prod_{i=1}^{100}f(k_i) \]

백 개의 작은 숫자들을 곱하는 대신, 로그를 취하는 것이 편리합니다3. 로그 함수는 엄격하게 증가하므로, 만약 특정 구간 내에서 로그가 최댓값에 도달하는 지점이 있다면 그 지점은 확률에 대해서도 최댓값이 될 것입니다.

3 이는 대개 종이와 연필 계산뿐만 아니라 컴퓨터 계산에서도 마찬가지입니다.

4 여기서 우리는 데이터 포인트들에 대한 명시적인 루프 없이 계산을 작성할 수 있게 해주는 R의 벡터 구문을 다시 사용합니다. 위의 코드와 비교할 때, 여기서는 고유한 값들에 대해서만 `dpois`를 호출하기 위해 `table` 함수로 `data`를 집계하는 대신, 100개 데이터 포인트 각각에 대해 `dpois`를 호출합니다. 이는 결과는 동일하지만 코드를 읽기가 얼마나 쉬운지 또는 실행 시간이 얼마나 걸리는지가 다를 수 있는 대안적인 해결책들의 간단한 예시입니다.

계산적인 설명부터 시작해 봅시다. 우리는 푸아송 매개변수의 많은 서로 다른 값들에 대해 우도를 계산합니다. 이를 위해 서로 다른 값들에 대한 데이터의 확률을 계산하는 작은 함수를 작성해야 합니다4.

    
    
    loglikelihood  =  function(lambda, data = e100) {
      sum(log(dpois(data, lambda)))
    }

이제 0.05부터 0.95까지 일련의 `lambda` 값들에 대해 우도를 계산할 수 있습니다 (그림 2.4).

    
    
    lambdas = seq(0.05, 0.95, length = 100)
    loglik = vapply(lambdas, loglikelihood, numeric(1))
    plot(lambdas, loglik, type = "l", col = "red", ylab = "", lwd = 2,
         xlab = expression(lambda))
    m0 = mean(e100)
    abline(v = m0, col = "blue", lwd = 2)
    abline(h = loglikelihood(m0), col = "purple", lwd = 2)
    m0
    
    
    [1] 0.55

[![](02-chap_files/figure-html/fig-poislikel-1-1.png)](02-chap_files/figure-
html/fig-poislikel-1-1.png "그림 2.4: 빨간색 곡선은 로그 우도 함수입니다. 수직선은 m(평균) 값을 보여주고 가로선은 m의 로그 우도를 보여줍니다. m이 우도를 최대화하는 것으로 보입니다.")

그림 2.4: 빨간색 곡선은 로그 우도 함수입니다. 수직선은 `m`(평균) 값을 보여주고 가로선은 `m`의 로그 우도를 보여줍니다. `m`이 우도를 최대화하는 것으로 보입니다.



질문 2.4

위의 코드에서 `vapply` 함수는 무엇을 하나요? 힌트: 매뉴얼 페이지를 확인하세요.



해결책



`vapply`는 첫 번째 인수(이 경우 벡터 `lambdas`)를 가져와서, 각 벡터 요소에 대해 반복적으로 `loglikelihood` 함수(두 번째 인수)를 적용합니다. 결과적으로 결과값들의 벡터를 반환합니다. 이 함수는 또한 `loglikelihood`에 대한 각 개별 호출이 어떤 유형의 값을 반환할 것으로 기대되는지를 지정하는 세 번째 인수(이 경우 `numeric(1)`)를 필요로 합니다: 즉, 단일 숫자입니다. (일반적으로 함수가 때때로 문자열이나 두 개의 숫자와 같은 다른 것을 반환할 수도 있는데, 그럴 경우 전체 결과들을 일관된 하나의 벡터로 조립할 수 없으며 `vapply`가 오류를 발생시킵니다.)

사실 `goodfit`이라는 단축 함수가 있습니다.

    
    
    gf  =  goodfit(e100, "poisson")
    names(gf)
    
    
    [1] "observed" "count"    "fitted"   "type"     "method"   "df"       "par"     
    
    
    gf$par
    
    
    $lambda
    [1] 0.55

`goodfit`의 출력은 리스트(list)라 불리는 복합 객체입니다. 그 구성 요소 중 하나는 `par`라고 불리며, 연구된 분포에 대해 적합된 매개변수(들)의 값을 포함합니다. 이 경우에는 \(\lambda\)에 대한 추정치인 단 하나의 숫자뿐입니다.



질문 2.5

`goodfit` 함수의 출력에 있는 다른 구성 요소들은 무엇인가요?



태스크

`m`의 값을 이전에 \(\lambda\)로 사용했던 값인 0.5와 비교해 보세요. 0.5 대신 `m`을 사용하여 [1장](01-chap.html)에서 했던 모델링을 다시 수행해 보세요.

### 2.3.1 고전적 데이터에 대한 고전적 통계

표본 평균이 (로그) 우도를 최대화한다는 우리 계산 결과에 대한 공식적인 증명은 다음과 같습니다.

\[ \begin{align} \log L(\lambda, x) &= \sum_{i=1}^{100} - \lambda + k_i\log\lambda - \log(k_i!) \\ &= -100\lambda + \log\lambda\left(\sum_{i=1}^{100}k_i\right) + \text{const.} \end{align} \tag{2.1}\]

우리는 \(\lambda\)에 의존하지 않는 항들(비록 \(x\), 즉 \(k_i\)에는 의존할지라도)에 대해 포괄적으로 "const."를 사용합니다. 이를 최대화하는 \(\lambda\)를 찾기 위해, \(\lambda\)에 대해 미분을 수행하고 이를 0으로 둡니다.

\[ \begin{align} \frac{d}{d\lambda}\log L &= -100 + \frac{1}{\lambda} \sum_{i=1}^{100}k_i \stackrel{?}{=}0 \\ \lambda &= \frac{1}{100} \sum_{i=1}^{100}k_i = \bar{k} \end{align} \tag{2.2}\]

여러분은 방금 (데이터로부터 시작하여) 모델 매개변수(들)를 추론하기 위한 **통계적 접근 방식** 의 첫 번째 단계들을 보았습니다: 이것이 데이터로부터 매개변수를 추정하는 통계적 **추정(estimation)** 입니다. 또 다른 중요한 구성 요소는 우리 데이터를 모델링하는 데 어떤 분포군을 사용할지 선택하는 것인데, 그 부분은 **적합도(goodness of fit)**를 평가함으로써 수행됩니다. 우리는 나중에 이를 접하게 될 것입니다.

전통적인 **통계적 검정(statistical testing)** 프레임워크에서, 우리는 데이터에 대해 **귀무 모델(null model)**이라 불리는 단 하나의 모델을 고려합니다. 귀무 모델은 어떤 그룹이나 처리에 관계없이 모든 관측치가 동일한 무작위 분포로부터 온다는 것과 같은 "흥미롭지 않은" 기준선을 공식화합니다. 그런 다음 데이터가 그 모델과 호환될 확률을 계산함으로써 좀 더 흥미로운 일이 일어나고 있는지 테스트합니다. 종종 이것이 우리가 할 수 있는 최선인데, 왜냐하면 우리는 "흥미로운" 비귀무(non-null) 또는 대립 모델이 무엇인지 충분히 자세히 알지 못하기 때문입니다. 다른 상황에서는 나중에 보게 되겠지만 우리가 서로 비교할 수 있는 두 개의 경쟁 모델을 가집니다.



질문 2.6

알려진 분포를 사용하여 모델링하는 것의 가치는 무엇인가요? 예를 들어, 어떤 변수가 푸아송 분포를 가진다는 것을 아는 것이 왜 흥미로울까요?



해결책



모델은 데이터 생성 과정을 간결하면서도 표현력 있게 나타낸 것입니다. 예를 들어 푸아송 분포의 경우, 숫자 하나만 알면 우리가 앞서 보았듯이 극단적이거나 희귀한 사건의 확률을 포함하여 그 분포에 대한 모든 것을 알 수 있습니다.

또 다른 유용한 방향은 **회귀(regression)** 입니다. 우리는 카운트 기반의 반응 변수(예: 시퀀싱 리드 카운트 결과)가 연속형 공변량(예: 온도나 영양분 농도)에 어떻게 의존하는지 알고 싶을 수 있습니다. 반응 변수 \(y\)가 방정식 \(y = ax+b + e\)를 통해 공변량 \(x\)에 의존하고, (우리가 추정해야 할) 매개변수 \(a\)와 \(b\), 그리고 확률 모델이 정규 분포인 잔차 \(e\)(이의 분산 또한 대개 추정해야 함)를 사용하는 선형 회귀를 이미 접해 보셨을 것입니다. 카운트 데이터의 경우에도 동일한 유형의 회귀 모델이 가능하지만, 잔차의 확률 분포는 비정규 분포여야 합니다. 그 경우 우리는 **일반화 선형 모델(generalized linear models)** 프레임워크를 사용합니다. 우리는 [8장](08-chap.html)에서 RNA-Seq을 공부할 때, 그리고 [9장](09-chap.html)에서 또 다른 유형의 차세대 시퀀싱 데이터인 16S rRNA 데이터를 공부할 때 그 예시들을 보게 될 것입니다.

우리 확률 모델이 푸아송, 이항, 다항 분포 또는 다른 모수적 군(parametric family)을 포함한다는 것을 안다면, 모델의 매개변수에 관한 질문들에 빠르게 답할 수 있고 p-값이나 신뢰 구간과 같은 수치들을 계산할 수 있게 될 것입니다.

## 2.4 이항 분포와 최대 우도

이항 분포에는 두 가지 매개변수가 있습니다: 대개 알려져 있는 시행 횟수 \(n\)과, 각 시행에서 1이 나타날 확률 \(p\)입니다. 이 확률은 종종 알려져 있지 않습니다.

### 2.4.1 예제

\(n=120\)명의 남성 샘플을 추출하여 적록 색맹 여부를 테스트한다고 가정해 봅시다. 피험자가 색맹이 아니면 0으로, 색맹이면 1로 데이터를 코딩할 수 있습니다. 우리는 다음과 같은 표로 데이터를 요약합니다:

    
    
    table(cb)
    
    
    cb
      0   1 
    110  10 



질문 2.7

이 데이터가 주어졌을 때 가장 발생 가능성이 높은 \(p\) 값은 무엇인가요?



해결책



\(\hat{p}=\frac{1}{12}\)입니다.

    
    
    mean(cb)
    
    
    [1] 0.08333333

[![하지만 주의하세요: 때때로 최대 우도 추정치는 추측하거나 계산하기가 더 어려우며 훨씬 덜 직관적이기도 합니다 (연습 문제 2.2 참조).](imgs/devil.png)](imgs/devil.png "하지만 주의하세요: 때때로 최대 우도 추정치는 추측하거나 계산하기가 더 어려우며 훨씬 덜 직관적이기도 합니다 (연습 문제 2.2 참조).")

하지만 주의하세요: 때때로 최대 우도 추정치는 추측하거나 계산하기가 더 어려우며 훨씬 덜 직관적이기도 합니다 (연습 문제 2.2 참조).

이 특수한 사례에서는 여러분의 직관이 \(\hat{p}=\frac{1}{12}\)라는 추정치를 줄 수 있는데, 이것이 최대 우도 추정치임이 밝혀졌습니다. 우리는 이것이 (필연적으로) 기저의 실제 값이 아니라 우리가 데이터로부터 얻은 추정치임을 상기하기 위해 글자 위에 햇(hat)을 씌웠습니다.

이전의 푸아송 사례와 마찬가지로, 많은 가능한 \(p\) 값들에 대해 우도를 계산한다면 이를 플롯하고 최댓값이 어디에 떨어지는지 확인할 수 있습니다 (그림 2.5).

    
    
    probs  =  seq(0, 0.3, by = 0.005)
    likelihood = dbinom(sum(cb), prob = probs, size = length(cb))
    plot(probs, likelihood, pch = 16, xlab = "성공 확률",
           ylab = "우도", cex=0.6)
    probs[which.max(likelihood)]
    
    
    [1] 0.085

[![](02-chap_files/figure-html/fig-likely1-1-1.png)](02-chap_files/figure-
html/fig-likely1-1-1.png "그림 2.5: 확률의 함수로서의 우도 플롯. 우도는 [0, 1] 구간의 함수입니다. 여기서는 p의 더 큰 값들에 대한 우도가 사실상 0이므로 [0, 0.3] 범위를 확대해서 보았습니다.")

그림 2.5: 확률의 함수로서의 우도 플롯. 우도는 \([0, 1]\) 구간의 함수입니다. 여기서는 \(p\)의 더 큰 값들에 대한 우도가 사실상 0이므로 \([0, 0.3]\) 범위를 확대해서 보았습니다.

참고: 0.085는 우리가 예상했던 값인 (\(\frac{1}{12}\))과 정확히 일치하지 않는데, 이는 우리가 시도했던 값들의 집합(`probs`)이 \(\frac{1}{12}\simeq 0.0833\)이라는 정확한 값을 포함하지 않았기 때문에 차선책을 얻었기 때문입니다. 수치 최적화 방법을 사용하여 이를 극복할 수 있습니다.

### 2.4.2 이항 분포의 우도

[![최대 우도와는 다른 기준을 세워 다른 추정량을 도출할 수도 있습니다. 이들 역시 모두 햇(hats)을 씌웁니다. [4장](04-chap.html)에서 다른 예시들을 보게 될 것입니다.](imgs/devil.png)](imgs/devil.png "최대 우도와는 다른 기준을 세워 다른 추정량을 도출할 수도 있습니다. 이들 역시 모두 햇(hats)을 씌웁니다. [4장](04-chap.html)에서 다른 예시들을 보게 될 것입니다.")

최대 우도와는 다른 기준을 세워 다른 추정량을 도출할 수도 있습니다. 이들 역시 모두 햇(hats)을 씌웁니다. [4장](04-chap.html)에서 다른 예시들을 보게 될 것입니다.

우도(likelihood)와 확률(probability)은 동일한 수학적 함수이지만, 단지 해석하는 방식이 다를 뿐입니다 – 한 가지 경우에는 함수가 매개변수가 주어졌을 때 데이터의 특정 값 집합을 볼 확률이 얼마나 되는지를 알려줍니다; 다른 경우에는 데이터를 주어진 것으로 간주하고 그 데이터를 생성했을 법한 매개변수 값(들)을 묻습니다. \(n=300\)이라고 가정하고 \(y=40\)번의 성공을 관찰했다고 합시다. 그러면 이항 분포의 경우:

\[ f(p\,|\,n,y) = f(y\,|\,n,p)={n \choose y} \, p^y \, (1-p)^{(n-y)}. \tag{2.3}\]

다시 말하지만, 우도의 로그를 사용하는 것이 더 편리합니다.

\[ \log f(p |y) = \log {n \choose y} + y\log(p) + (n-y)\log(1-p). \tag{2.4}\]

다음은 이를 계산하는 데 사용할 수 있는 함수입니다5.

5 실제로는 `choose(n, y)`를 명시적으로 계산하는 것을 피하려고 노력할 것인데, 이는 컴퓨터의 부동 소수점 연산 한계를 시험하는 매우 큰 숫자일 수 있기 때문입니다 (`n=300` 및 `y=40`의 경우 약 9.8e+49임). 이는 최대화에 영향을 주지 않는 \(p\)와 무관한 추가적인 오프셋일 뿐이므로, 스털링 공식을 사용하여 항을 근사화하거나 실제로 무시할 수 있습니다.

    
    
    loglikelihood = function(p, n = 300, y = 40) {
      log(choose(n, y)) + y * log(p) + (n - y) * log(1 - p)
    }

0부터 1까지의 \(p\) 범위에 대해 이를 플롯해 봅니다 (그림 2.6).

    
    
    p_seq = seq(0, 1, by = 0.001)
    plot(p_seq, loglikelihood(p_seq), xlab = "p", ylab = "log f(p|y)", type = "l")

[![](02-chap_files/figure-html/fig-
loglikelihood-1-1.png)](02-chap_files/figure-html/fig-loglikelihood-1-1.png
"그림 2.6: n=300 및 y=40에 대한 로그 우도 함수 플롯.")

그림 2.6: \(n=300\) 및 \(y=40\)에 대한 로그 우도 함수 플롯.

최댓값은 40/300 = 0.1333… 지점에 위치하며 이는 직관과 일치하지만, 함수가 최댓값 주변에서 상당히 평평하여 \(p\)의 다른 값들도 거의 비슷하게 발생할 가능성이 있음을 알 수 있습니다. 우리는 이후 섹션에서 베이지안 방법을 사용하여 단일 최댓값만을 고르는 대신 \(p\)에 대한 값의 범위를 어떻게 다룰 수 있는지 살펴볼 것입니다.

## 2.5 더 많은 상자들: 다항 데이터

### 2.5.1 DNA 카운트 모델링: 염기쌍

DNA에는 아데닌(A), 시토신(C), 구아닌(G), 티민(T)의 네 가지 기본 분자가 있습니다. 뉴클레오타이드는 퓨린(A와 G)과 피리미딘(C와 T)의 두 그룹으로 분류됩니다. 이항 분포는 퓨린/피리미딘 그룹화에 대한 모델로 작동하겠지만, 만약 A, C, G, T를 사용하고 싶다면 작동하지 않을 것입니다; 이를 위해서는 [1.4절](01-chap.html#sec-generative-multinomial)의 다항 모델이 필요합니다. 이러한 빈도에서 나타나는 주목할 만한 패턴들을 살펴봅시다.

### 2.5.2 뉴클레오타이드 편향

이 섹션에서는 실제 예제에서 시뮬레이션을 통한 추정과 검정을 결합합니다. _Staphylococcus aureus_ 박테리아 유전자의 DNA 한 가닥에 대한 데이터는 _fasta_ 파일 `staphsequence.ffn.txt`에서 사용할 수 있으며, 바이오컨덕터 패키지 **[Biostrings](https://bioconductor.org/packages/Biostrings/)**의 함수를 사용하여 읽어 들일 수 있습니다.

    
    
    library("Biostrings")
    staph = readDNAStringSet("../data/staphsequence.ffn.txt", "fasta")

첫 번째 유전자를 살펴봅시다:

    
    
    staph[1]
    
    
    DNAStringSet object of length 1:
        width seq                                               names               
    [1]  1362 ATGTCGGAAAAAGAAATTTGGGA...AAAAAGAAATAAGAAATGTATAA lcl|NC_002952.2_c...
    
    
    letterFrequency(staph[[1]], letters = "ACGT", OR = 0)
    
    
      A   C   G   T 
    522 219 229 392 



질문 2.8

왜 두 번째 줄에서 이중 대괄호를 사용했나요?



해결책



이중 대괄호 `[[i]]`는 `i`번째 유전자의 서열을 단일 _DNAString_ 으로 추출하는 반면, 한 쌍의 단일 대괄호 `[i]`는 그 안에 단일 _DNAString_ 이 들어있는 _DNAStringSet_ 을 반환합니다. 만약 `staph[1]`의 길이를 보면 1인 반면, `staph[[1]]`의 길이는 1362입니다.



질문 2.9

[연습 문제 1.8](01-chap.html#imp-generative-genomefrequency)과 유사한 절차를 따라, 이 첫 번째 유전자에 대해 네 가지 뉴클레오타이드가 균등하게 분포되어 있는지 테스트해 보세요.

서로 다른 물리적 특성 때문에, 진화적 선택은 뉴클레오타이드 빈도에 작용할 수 있습니다. 따라서 우리는 이 데이터의 처음 10개 유전자가 동일한 다항 분포로부터 오는지 물을 수 있습니다. 우리는 사전 참조 정보가 없으며, 처음 10개 유전자의 뉴클레오타이드가 동일한 비율로 나타나는지만을 결정하고 싶습니다. 만약 그렇지 않다면, 이는 이 10개 유전자에 대한 선택 압력이 다양하다는 증거를 제공할 것입니다.

    
    
    letterFrq = vapply(staph, letterFrequency, FUN.VALUE = numeric(4),
             letters = "ACGT", OR = 0)
    colnames(letterFrq) = paste0("gene", seq(along = staph))
    tab10 = letterFrq[, 1:10]
    computeProportions = function(x) { x/sum(x) }
    prop10 = apply(tab10, 2, computeProportions)
    round(prop10, digits = 2)
    
    
      gene1 gene2 gene3 gene4 gene5 gene6 gene7 gene8 gene9 gene10
    A  0.38  0.36  0.35  0.37  0.35  0.33  0.33  0.34  0.38   0.27
    C  0.16  0.16  0.13  0.15  0.15  0.15  0.16  0.16  0.14   0.16
    G  0.17  0.17  0.23  0.19  0.22  0.22  0.20  0.21  0.20   0.20
    T  0.29  0.31  0.30  0.29  0.27  0.30  0.30  0.29  0.28   0.36
    
    
    p0 = rowMeans(prop10)
    p0
    
    
            A         C         G         T 
    0.3470531 0.1518313 0.2011442 0.2999714 

따라서 `p0`가 10개 유전자 전체에 대한 다항 확률의 벡터라고 가정하고, 이 가정하에서 관찰된 문자 빈도와 기대값 사이의 차이가 타당한 범위 내에 있는지 몬테카를로 시뮬레이션을 사용하여 테스트해 봅시다.

우리는 확률 벡터 p0와 10개 열 각각의 뉴클레오타이드 카운트 합계 `cs` 사이의 외적(`outer` product)을 취하여 기대되는 카운트를 계산합니다.

    
    
    cs = colSums(tab10)
    cs
    
    
     gene1  gene2  gene3  gene4  gene5  gene6  gene7  gene8  gene9 gene10 
      1362   1134    246   1113   1932   2661    831   1515   1287    696 
    
    
    expectedtab10 = outer(p0, cs, FUN = "*")
    round(expectedtab10)
    
    
      gene1 gene2 gene3 gene4 gene5 gene6 gene7 gene8 gene9 gene10
    A   473   394    85   386   671   924   288   526   447    242
    C   207   172    37   169   293   404   126   230   195    106
    G   274   228    49   224   389   535   167   305   259    140
    T   409   340    74   334   580   798   249   454   386    209

우리는 이제 `rmultinom` 함수를 사용하여 올바른 열 합계를 가진 무작위 표를 만들 수 있습니다. 이 표는 실제 비율이 `p0`에 의해 주어진다는 귀무 가설에 따라 생성됩니다.

    
    
    randomtab10 = sapply(cs, function(s) { rmultinom(1, s, p0) } )
    all(colSums(randomtab10) == cs)
    
    
    [1] TRUE

이제 이를 B = 1000번 반복합니다. 각 표에 대해 [1장](01-chap.html)의 [1.4.1절](01-chap.html#sec-generative-SimulatingForPower)(함수 `stat`)에서 정의한 검정 통계량을 계산하고 그 결과를 `simulstat` 벡터에 저장합니다. 이 값들은 모두 10개 유전자 각각에 대해 `p0`가 다항 비율 벡터라는 귀무 가설하에서 생성된 것이므로, 통칭하여 우리 귀무 분포를 구성합니다.

    
    
    stat = function(obsvd, exptd) {
       sum((obsvd - exptd)^2 / exptd)
    }
    B = 1000
    simulstat = replicate(B, {
      randomtab10 = sapply(cs, function(s) { rmultinom(1, s, p0) })
      stat(randomtab10, expectedtab10)
    })
    S1 = stat(tab10, expectedtab10)
    sum(simulstat >= S1)
    
    
    [1] 0
    
    
    hist(simulstat, col = "lavender", breaks = seq(0, 75, length.out=50))
    abline(v = S1, col = "red")
    abline(v = quantile(simulstat, probs = c(0.95, 0.99)),
           col = c("darkgreen", "blue"), lty = 2)

[![](02-chap_files/figure-html/fig-quant12-1-1.png)](02-chap_files/figure-
html/fig-quant12-1-1.png "그림 2.7: simulstat의 히스토그램. S1의 값은 수직 빨간색 선으로 표시되었으며, 0.95 및 0.99 분위수(다음 섹션 참조)는 점선으로 표시되었습니다.")

그림 2.7: `simulstat`의 히스토그램. `S1`의 값은 수직 빨간색 선으로 표시되었으며, 0.95 및 0.99 분위수(다음 섹션 참조)는 점선으로 표시되었습니다.

히스토그램은 그림 2.7에 나와 있습니다. 우리는 _귀무 모델_ 하에서 `S1`=70.1만큼 큰 값을 볼 확률이 매우 낮다는 것을 알 수 있습니다. 우리가 수행한 1000번의 시뮬레이션 중에서 `S1`만큼 큰 값이 나타난 경우는 0번이었습니다. 따라서 이 10개 유전자는 동일한 다항 모델로부터 온 것 같지 않습니다.

## 2.6 \(\chi^2\) 분포

사실, 우리는 이러한 시뮬레이션을 실행하지 않고도 통계 이론을 사용하여 동일한 결론에 도달할 수 있었습니다. `simulstat` 통계량의 이론적 분포는 매개변수가 30(\(=10\times(4-1)\))인 **\(\chi^2\)(카이제곱)** 분포6라고 불립니다. 우리는 이를 사용하여 `S1` \(=\) 70.1만큼 높은 값을 가질 확률을 계산할 수 있습니다. 위에서 보았듯이, 작은 확률은 몬테카를로 방법으로 계산하기 어렵습니다: 계산의 해상도가 \(1/B\)이기 때문에 그보다 작은 확률은 추정할 수 없으며, 실제로 추정치의 불확실성은 그보다 큽니다. 따라서 어떤 이론이라도 적용 가능하다면 유용한 경향이 있습니다. 우리는 또 다른 시각적 적합도 도구인 **분위수-분위수(quantile-quantile, QQ)** 플롯을 사용하여 우리 사례에서 이론과 시뮬레이션이 얼마나 잘 일치하는지 확인할 수 있습니다. 두 분포를 비교할 때, 그것이 서로 다른 두 표본으로부터 온 것이든 아니면 하나의 표본 대 이론적 모델이든, 단순히 히스토그램만 보는 것은 충분히 정보가 많지 않습니다. 우리는 각 분포의 분위수(quantiles)를 기반으로 한 방법을 사용합니다.

6 엄밀히 말하면, `simulstat`의 분포는 대략적으로 \(\chi^2\) 분포로 설명됩니다; 이 근사는 표의 카운트가 클 때 특히 정확합니다.

### 2.6.1 막간: 분위수와 분위수-분위수 플롯

이전 장에서 우리는 100개의 표본 값 \(x_{(1)}, x_{(2)}, ..., x_{(100)}\)을 정렬했습니다. 만약 22번째 백분위수를 원한다면, 우리는 22번째와 23번째 값 사이의 임의의 값을 취할 수 있습니다. 즉, \(x_{(22)} \leq c_{0.22} < x_{(23)}\)을 만족하는 임의의 값은 0.22 **분위수** (\(c_{0.22}\))로 수용 가능합니다. 다시 말해, \(c_{0.22}\)는 다음과 같이 정의됩니다.

\[ \frac{\# x_i \leq c_{0.22} \text{의 개수}}{n} = 0.22. \]

[3.6.7절](03-chap.html#sec-graphics-ecdf)에서 우리는 **경험적 누적 분포(empirical cumulative distribution)** 함수(**ECDF**) \(\hat{F}\)를 소개할 것이며, 우리 분위수 \(c_{0.22}\)의 정의가 \(\hat{F}_n(c_{0.22}) = 0.22\)로 쓰여질 수도 있음을 보게 될 것입니다. 그림 2.7의 `simulstat` 분포 히스토그램에는 분위수 \(c_{0.95}\)와 \(c_{0.99}\)도 표시되어 있습니다.



질문 2.10

  1. `simulstat` 값들과 무작위로 생성된 1000개의 \(\chi^2_{30}\) 난수를 각각 50개의 빈(bin)을 가진 히스토그램으로 표시하여 비교해 보세요.

  2. `simulstat` 값들의 분위수를 계산하고 이를 \(\chi_{30}^2\) 분포의 분위수와 비교해 보세요. 힌트:

    
    
    qs = ppoints(100)
    quantile(simulstat, qs)
    quantile(qchisq(qs, df = 30), qs)

[![여기서 명칭의 충돌이 발생합니다. 통계학자들은 방금 우리가 계산한 요약 통계량인 simulstat(가중 제곱 차이의 합)을 카이제곱 또는 \(\chi^2\) 통계량이라고 부릅니다. 이론적 분포 \(\chi^2_\nu\)는 자유도라고 불리는 매개변수 \(\nu\)를 가진 그 자체의 분포입니다. 카이제곱 또는 \(\chi^2\)에 대해 읽을 때, 어떤 의미가 적절한지 파악하기 위해 문맥에 주의를 기울여야 합니다.](imgs/devil.png)](imgs/devil.png "여기서 명칭의 충돌이 발생합니다. 통계학자들은 방금 우리가 계산한 요약 통계량인 simulstat(가중 제곱 차이의 합)을 카이제곱 또는 \(\chi^2\) 통계량이라고 부릅니다. 이론적 분포 \(\chi^2_\nu\)는 자유도라고 불리는 매개변수 \(\nu\)를 가진 그 자체의 분포입니다. 카이제곱 또는 \(\chi^2\)에 대해 읽을 때, 어떤 의미가 적절한지 파악하기 위해 문맥에 주의를 기울여야 합니다.")

여기서 명칭의 충돌이 발생합니다. 통계학자들은 방금 우리가 계산한 요약 통계량인 `simulstat`(가중 제곱 차이의 합)을 **카이제곱** 또는 \(\chi^2\) _통계량_ 이라고 부릅니다. 이론적 _분포_ \(\chi^2_\nu\)는 자유도라고 불리는 매개변수 \(\nu\)를 가진 그 자체의 분포입니다. 카이제곱 또는 \(\chi^2\)에 대해 읽을 때, 어떤 의미가 적절한지 파악하기 위해 문맥에 주의를 기울여야 합니다.



질문 2.11

0.5 분위수의 또 다른 이름을 알고 있나요?



해결책



중앙값(median).



질문 2.12

위의 정의에서, 우리는 분위수가 단지 0.22뿐만 아니라 일반적으로 어떻게 정의되는지에 대해 약간 모호하게 설명했습니다. \(1/n\)의 배수가 아닌 숫자를 포함하여 0과 1 사이의 임의의 숫자에 대한 분위수는 어떻게 계산되나요?



해결책



`quantile` 함수의 매뉴얼 페이지와 `type`이라는 인수를 확인해 보세요.

이제 분위수가 무엇인지 알았으므로 분위수-분위수 플롯을 그릴 수 있습니다. 귀무 가설하에서 우리가 시뮬레이션한 `simulstat` 값들의 분위수를 이론적인 귀무 분포인 \(\chi^2_{30}\)에 대해 플롯합니다 (그림 2.8).

    
    
    qqplot(qchisq(ppoints(B), df = 30), simulstat, main = "",
      xlab = expression(\chi[nu==30]^2), asp = 1, cex = 0.5, pch = 16)
    abline(a = 0, b = 1, col = "red")

[![](02-chap_files/figure-html/fig-qqplot3-1-1.png)](02-chap_files/figure-
html/fig-qqplot3-1-1.png "그림 2.8: 우리 시뮬레이션 통계량의 분포를 \(\chi_{30}^2\)와 비교한 분위수-분위수(QQ) 플롯. 가로축에는 \(\chi^2_{30}\) 분포의 이론적 분위수를, 세로축에는 샘플링된 분위수를 나타냅니다.")

그림 2.8: 우리 시뮬레이션 통계량의 분포를 \(\chi_{30}^2\)와 비교한 분위수-분위수(QQ) 플롯. 가로축에는 \(\chi^2_{30}\) 분포의 이론적 **분위수**를, 세로축에는 샘플링된 분위수를 나타냅니다.

`simulstat`가 \(\chi^2_{30}\) 분포에 의해 잘 설명된다고 확신했다면, 이를 사용하여 p-값, 즉 귀무 가설하에서 (카운트가 확률 \(p_{\text{A}} = 0.35, p_{\text{C}} = 0.15, p_{\text{G}} = 0.2, p_{\text{T}} = 0.3\)인 다항 분포를 따를 때) `S1`=70.1만큼 높은 값을 관찰할 확률을 계산할 수 있습니다.

    
    
    1 - pchisq(S1, df = 30)
    
    
    [1] 4.74342e-05

p-값이 이렇게 작으므로 귀무 가설은 일어날 법하지 않아 보입니다. 이 계산에는 1000번의 시뮬레이션이 필요하지 않았으며 훨씬 더 빨랐음을 주목하세요.

## 2.7 샤가프의 법칙 (Chargaff’s Rule)

뉴클레오타이드 빈도에서의 가장 중요한 패턴은 Chargaff에 의해 발견되었습니다 ([Elson and Chargaff 1952](16-chap.html#ref-Chargaff)).

![](imgs/ChargaffColdSpring_web.jpg)

DNA 시퀀싱이 가용해지기 훨씬 전, 분자들의 무게를 사용하여 그는 뉴클레오타이드들이 동일한 빈도로 나타나는지 물었습니다. 그는 이를 테트라뉴클레오타이드 가설(tetranucleotide hypothesis)이라고 불렀습니다. 우리는 이를 \(p_{\text{A}} = p_{\text{C}} = p_{\text{G}} = p_{\text{T}}\) 인지 묻는 것으로 해석할 것입니다.

불행하게도, Chargaff는 측정값 그 자체가 아니라 서로 다른 유기체에 존재하는 각 뉴클레오타이드 질량의 _백분율_ 만을 발표했습니다.

    
    
    load("../data/ChargaffTable.RData")
    ChargaffTable
    
    
                      A    T    C    G
    Human-Thymus   30.9 29.4 19.9 19.8
    Mycobac.Tuber  15.1 14.6 34.9 35.4
    Chicken-Eryth. 28.8 29.2 20.5 21.5
    Sheep-liver    29.3 29.3 20.5 20.7
    Sea Urchin     32.8 32.1 17.7 17.3
    Wheat          27.3 27.1 22.7 22.8
    Yeast          31.3 32.9 18.7 17.1
    E.coli         24.7 23.6 26.0 25.7

[![](02-chap_files/figure-html/fig-ChargaffBars-1.png)](02-chap_files/figure-
html/fig-ChargaffBars-1.png "그림 2.9: ChargaffTable의 서로 다른 행들에 대한 막대 그래프. 패턴을 찾을 수 있나요?")

그림 2.9: `ChargaffTable`의 서로 다른 행들에 대한 막대 그래프. 패턴을 찾을 수 있나요?



질문 2.13

  * 이 데이터가 동일한 확률을 가진 다항 범주들로부터 온 것처럼 보이나요?

  * 대안적인 패턴을 제안할 수 있나요?

  * 위의 시뮬레이션에서 영감을 얻어, 해당 패턴에 대한 정량적 분석을 수행할 수 있나요?



해결책



샤가프는 이 질문에 대한 답을 _보고_ , 유기체의 DNA에서 아데닌(A)의 양과 티민(T)의 양이 완벽하게 일치하도록 보장하는 _염기쌍(base pairing)_ 이라는 패턴을 가정했습니다. 유사하게, 구아닌(G)의 양이 얼마든 시토신(C)의 양은 그와 같을 것입니다. 이것이 현재 샤가프의 법칙이라 불리는 것입니다. 반면에, 한 유기체 내에서의 C/G 양은 A/T 양과 상당히 다를 수 있으며 유기체들 전반에 걸쳐 뚜렷한 패턴은 없습니다. 샤가프의 법칙에 기초하여, 우리는 다음과 같은 통계량을 정의할 수 있습니다.

\[ (p_{\text{C}} - p_{\text{G}})^2 + (p_{\text{A}} - p_{\text{T}})^2, \]

표의 모든 행에 대해 합산한 것입니다. 우리는 각 행에서 관찰된 확률들이 특별한 순서가 없어서 As와 Ts의 비율 또는 Cs와 Gs의 비율 사이에 특별한 관계가 없었다는 의미에서 뉴클레오타이드들이 '교환 가능'했을 경우 데이터에 어떤 일이 일어날지에 대한 비교를 살펴볼 것입니다.

    
    
    statChf = function(x){
      sum((x[, "C"] - x[, "G"])^2 + (x[, "A"] - x[, "T"])^2)
    }
    chfstat = statChf(ChargaffTable)
    permstat = replicate(100000, {
         permuted = t(apply(ChargaffTable, 1, sample))
         colnames(permuted) = colnames(ChargaffTable)
         statChf(permuted)
    })
    pChf = mean(permstat <= chfstat)
    pChf
    
    
    [1] 0.00014
    
    
    hist(permstat, breaks = 100, main = "", col = "lavender")
    abline(v = chfstat, lwd = 2, col = "red")

[![](02-chap_files/figure-html/fig-permstatChf-1-1.png)](02-chap_files/figure-
html/fig-permstatChf-1-1.png "그림 2.10: 컬럼들의 행 단위 순열을 사용한 시뮬레이션을 통해 계산된 우리 통계량 statChf의 히스토그램. 관찰된 데이터에 대해 산출된 값은 빨간색 선으로 표시되었습니다.")

그림 2.10: 컬럼들의 행 단위 순열을 사용한 시뮬레이션을 통해 계산된 우리 통계량 `statChf`의 히스토그램. 관찰된 데이터에 대해 산출된 값은 빨간색 선으로 표시되었습니다.

그림 2.10의 히스토그램은 빨간색 선이 그려진 관측값 11.1만큼 작은 값을 갖는 것이 매우 드물다는 것을 보여줍니다. 그와 같거나 더 작은 값을 관찰할 확률은 `pChf`=\(1.4 \times 10^{-4}\)입니다. 따라서 데이터는 샤가프의 통찰을 강력하게 뒷받침합니다.



질문 2.14

`pChf`를 계산할 때, 우리는 귀무 분포에서 관측된 값보다 작은 값들만을 살펴보았습니다. 왜 여기서 우리는 단측(one-sided) 방식으로 이를 수행했나요?

### 2.7.1 두 개의 범주형 변수

지금까지 우리는 샘플이 서로 다른 상자들로 분류될 수 있는 사례들을 보았습니다: 예/아니오 이진 상자에 대한 이항 분포와 A, C, G, T 또는 aa, aA, AA와 같은 다른 유전자형과 같은 범주형 변수에 대한 다항 분포입니다. 하지만 우리가 일련의 피험자에 대해 눈 색깔과 머리카락 색깔과 같은 두 개(또는 그 이상)의 범주형 변수를 측정할 수도 있습니다. 그런 다음 눈 색깔과 머리카락 색깔의 모든 조합에 대한 카운트를 교차 집계할 수 있습니다. 우리는 **분할표(contingency table)** 라 불리는 카운트 표를 얻게 됩니다. 이 개념은 많은 생물학적 데이터 유형에 매우 유용합니다.

    
    
    HairEyeColor[,, "Female"]
    
    
           Eye
    Hair    Brown Blue Hazel Green
      Black    36    9     5     2
      Brown    66   34    29    14
      Red      16    7     7     7
      Blond     4   64     5     8



질문 2.15

R에서 `HairEyeColor` 객체를 탐색해 보세요. 어떤 데이터 유형, 모양, 차원을 가지고 있나요?



해결책



이는 세 가지 차원을 가진 수치형 배열(array)입니다:

    
    
    str(HairEyeColor)
    
    
     'table' num [1:4, 1:4, 1:2] 32 53 10 3 11 50 10 30 10 25 ...
     - attr(*, "dimnames")=List of 3
      ..$ Hair: chr [1:4] "Black" "Brown" "Red" "Blond"
      ..$ Eye : chr [1:4] "Brown" "Blue" "Hazel" "Green"
      ..$ Sex : chr [1:2] "Male" "Female"
    
    
    ## ?HairEyeColor

#### 색맹과 성별

녹색맹(Deuteranopia)은 중간 파장에 민감한 원뿔 세포(녹색)가 없어서 발생하는 적록 색맹의 한 형태입니다. 녹색맹 환자는 오직 2~3가지의 서로 다른 색조만을 구별할 수 있는 반면, 정상 시력을 가진 사람은 7가지의 서로 다른 색조를 봅니다. 인간 피험자들을 대상으로 한 이 유형의 색맹 조사는 색맹 여부와 성별을 교차시킨 2원 표(two-way table)를 생성했습니다.

    
    
    load("../data/Deuteranopia.RData")
    Deuteranopia
    
    
              Men Women
    Deute      19     2
    NonDeute 1981  1998

성별과 색맹 발생 사이에 관계가 있는지 어떻게 테스트할 수 있을까요? 우리는 성별에 대한 것과 색맹에 대한 것, 두 개의 독립적인 이항 분포를 사용한 귀무 모델을 가정합니다. 이 모델하에서 우리는 모든 셀의 다항 확률을 추정할 수 있으며, 관찰된 카운트를 기대되는 카운트와 비교할 수 있습니다. 이는 R의 `chisq.test` 함수를 통해 수행됩니다.

    
    
    chisq.test(Deuteranopia)
    
    
        Pearson's Chi-squared test with Yates' continuity correction
    
    data:  Deuteranopia
    X-squared = 12.255, df = 1, p-value = 0.0004641

작은 p-값은 귀무 모델하에서 그러한 표를 볼 확률이 매우 낮다는 것을 말해줍니다 – 즉, 여성과 남성 사이에서 녹색맹 비율이 동일하다는 가설하에서 말이죠.

우리는 [10.3.2절](10-chap.html#sec-graphs-GSEA)에서 피셔의 정확 검정(Fisher’s exact test, 초기하 검정으로도 알려짐)이라 불리는 이러한 유형의 데이터를 위한 또 다른 검정을 보게 될 것입니다. 이 검정은 유의미하게 발현된 유전자 리스트에서 특정 유형의 유전자들이 과다하게 나타나는지 테스트하는 데 널리 사용됩니다.

### 2.7.2 특수한 다항 분포: 하디-와인버그 평형 (Hardy-Weinberg equilibrium)

여기서 우리는 두 대립유전자 M과 N을 결합하여 생성된 세 가지 가능한 수준을 가진 다항 분포의 사용을 강조합니다. 모집단에서 대립유전자 M의 전체 빈도가 \(p\)이고, N의 빈도가 \(q = 1-p\)라고 가정합시다. 하디-와인버그 모델은 유전자형에서 두 대립유전자의 빈도가 독립적일 때, 소위 **하디-와인버그 평형**(Hardy-Weinberg equilibrium, HWE) 상태에서 \(p\)와 \(q\) 사이의 관계를 살펴봅니다. 이는 성별 간에 대립유전자가 균등하게 분포되어 있는 대규모 집단에서 무작위 교배가 이루어지는 경우에 해당합니다. 세 가지 유전자형의 확률은 다음과 같습니다:

\[ p_{\text{MM}}=p^2,\quad p_{\text{NN}}=q^2,\quad p_{\text{MN}}=2pq \tag{2.5}\]

우리는 유전자형 MM, MN, NN에 대한 빈도 \((n_{\text{MM}},\,n_{\text{MN}},\,n_{\text{NN}})\)과 총합 \(S=n_{\text{MM}}+ n_{\text{MN}}+n_{\text{NN}}\) 만을 관찰합니다. 범주들의 확률이 식 2.5에 의해 주어질 때 관찰된 데이터의 확률인 우도를 다항 분포 공식을 사용하여 쓸 수 있습니다.

\[ P(n_{\text{MM}},\,n_{\text{MN}},\,n_{\text{NN}}\;|\;p) = {S \choose n_{\text{MM}},n_{\text{MN}},n_{\text{NN}}} (p^2)^{n_{\text{MM}}} \,\times\, (2pq)^{n_{\text{MN}}} \,\times\, (q^2)^{n_{\text{NN}}}, \]

그리고 HWE하에서의 로그 우도는 다음과 같습니다.

\[ L(p)=n_{\text{MM}}\log(p^2)+n_{\text{MN}} \log(2pq)+n_{\text{NN}}\log(q^2). \]

로그 우도를 최대화하는 \(p\)의 값은 다음과 같습니다.

\[ p = \frac{n_{\text{MM}} + n_{\text{MN}}/2}{S}. \]

증명에 대해서는 ([Rice 2006, chap. 8](16-chap.html#ref-Rice:2007), 5절)를 참조하십시오. 주어진 데이터 \((n_{\text{MM}},\,n_{\text{MN}},\,n_{\text{NN}})\)에서 로그 우도 \(L\)은 오직 하나의 매개변수 \(p\)의 함수입니다. 그림 2.11은 아래 코드에서 계산된 Mourant 데이터7의 216번째 행에 대한 \(p\)의 서로 다른 값들에 따른 로그 우도 함수를 보여줍니다.

7 이는 R 패키지 **[HardyWeinberg](https://cran.r-project.org/web/packages/HardyWeinberg/)**를 통해 제공되는 Mourant, Kopec 및 Domaniewska-Sobczak ([1976](16-chap.html#ref-Mourant1976))의 혈액형 대립유전자 유전자형 빈도 데이터입니다.

    
    
    library("HardyWeinberg")
    data("Mourant")
    Mourant[214:216,]
    
    
        Population    Country Total  MM  MN  NN
    214    Oceania Micronesia   962 228 436 298
    215    Oceania Micronesia   678  36 229 413
    216    Oceania     Tahiti   580 188 296  96
    
    
    nMM = Mourant$MM[216]
    nMN = Mourant$MN[216]
    nNN = Mourant$NN[216]
    loglik = function(p, q = 1 - p) {
      2 * nMM * log(p) + nMN * log(2*p*q) + 2 * nNN * log(q)
    }
    xv = seq(0.01, 0.99, by = 0.01)
    yv = loglik(xv)
    plot(x = xv, y = yv, type = "l", lwd = 2,
         xlab = "p",ylab = "로그 우도")
    imax = which.max(yv)
    abline(v = xv[imax], h = yv[imax], lwd = 1.5, col = "blue")
    abline(h = yv[imax], lwd = 1.5, col = "purple")

[![](02-chap_files/figure-html/fig-HardyWeinberg-1-1.png)](02-chap_files/figure-
html/fig-HardyWeinberg-1-1.png "그림 2.11: 타히티(Tahiti) 데이터에 대한 로그 우도 플롯.")

그림 2.11: 타히티(Tahiti) 데이터에 대한 로그 우도 플롯.

다항 분포에서의 확률에 대한 최대 우도 추정치는 이항 분포의 경우와 마찬가지로 관찰된 빈도를 사용하여 얻어지지만, 추정치는 세 확률 사이의 관계를 고려해야 합니다. 우리는 **[HardyWeinberg](https://cran.r-project.org/web/packages/HardyWeinberg/)** 패키지의 `af` 함수를 사용하여 \(\hat{p}_{\text{MM}}\), \(\hat{p}_{\text{MN}}\) 및 \(\hat{p}_{\text{NN}}\)을 계산할 수 있습니다.

    
    
    phat  =  af(c(nMM, nMN, nNN))
    phat
    
    
            A 
    0.5793103 
    
    
    pMM   =  phat^2
    qhat  =  1 - phat

하디-와인버그 평형 상태에서 기대되는 값은 다음과 같습니다.

    
    
    pHW = c(MM = phat^2, MN = 2*phat*qhat, NN = qhat^2)
    sum(c(nMM, nMN, nNN)) * pHW
    
    
        MM.A     MN.A     NN.A 
    194.6483 282.7034 102.6483 

이는 위에서 관찰된 값들과 비교될 수 있습니다. 우리는 이들이 관측된 값들과 꽤 가깝다는 것을 알 수 있습니다. 우리는 관측된 값들이 하디-와인버그 모델을 기각하게 하는지 여부를 시뮬레이션을 하거나 위에서와 같은 \(\chi^2\) 검정을 수행하여 추가로 테스트할 수 있습니다. 하디-와인버그 적합도에 대한 시각적 평가는 de Finetti ([Finetti 1926](16-chap.html#ref-definetti26); [Cannings and Edwards 1968](16-chap.html#ref-Cannings1968))에 의해 고안되었습니다. 이는 각 대립유전자의 비율로 주어지는 좌표를 가진 지점에 모든 샘플을 배치합니다.

#### 하디-와인버그 평형과의 시각적 비교

우리는 `HWTernaryPlot` 함수를 사용하여 데이터를 표시하고 이를 하디-와인버그 평형과 그래픽으로 비교합니다.

    
    
    pops = c(1, 69, 128, 148, 192)
    genotypeFrequencies = as.matrix(Mourant[, c("MM", "MN", "NN")])
    HWTernaryPlot(genotypeFrequencies[pops, ],
            markerlab = Mourant$Country[pops],
            alpha = 0.0001, curvecols = c("red", rep("purple", 4)),
            mcex = 0.75, vertex.cex = 1)

[![](02-chap_files/figure-html/fig-HWtern-1.png)](02-chap_files/figure-
html/fig-HWtern-1.png "그림 2.12: 이 de Finetti 플롯은 세 유전자형의 빈도를 삼각형의 각 꼭짓점에 대한 가중치로 사용하여 무게 중심으로서 점들을 보여줍니다. 하디-와인버그 모델은 빨간색 곡선이며, 채택 영역(acceptance region)은 두 보라색 선 사이에 있습니다. 우리는 미국(US)이 HW 평형 상태에서 가장 멀리 떨어져 있음을 알 수 있습니다.")

그림 2.12: 이 **de Finetti 플롯**은 세 유전자형의 빈도를 삼각형의 각 꼭짓점에 대한 가중치로 사용하여 무게 중심으로서 점들을 보여줍니다. 하디-와인버그 모델은 빨간색 곡선이며, 채택 영역(acceptance region)은 두 보라색 선 사이에 있습니다. 우리는 미국(US)이 HW 평형 상태에서 가장 멀리 떨어져 있음을 알 수 있습니다.



질문 2.16

위의 코드와 같이 삼원 플롯(ternary plot)을 만든 다음, 다른 데이터 포인트들도 추가해 보세요. 무엇을 알 수 있나요? `HWChisq` 함수를 사용하여 여러분의 논의를 뒷받침할 수 있습니다.



해결책



    
    
    HWTernaryPlot(genotypeFrequencies[-pops, ], 
                  newframe = FALSE, alpha = 0.0001, cex = 0.5)



질문 2.17

각 유전자형에 대해 동일한 비율을 유지하면서 모든 전체 빈도를 50으로 나누고 삼원 플롯을 다시 만듭니다.

  * 점들은 어떻게 되나요?

  * 신뢰 영역(confidence regions)은 어떻게 되며 그 이유는 무엇인가요?



해결책



    
    
    newgf = round(genotypeFrequencies / 50)
    HWTernaryPlot(newgf[pops, ],
                  markerlab = Mourant$Country[pops],
                  curvecols = c("red", rep("purple", 4)),
                  alpha = 0.0001, mcex = 0.75, vertex.cex = 1)

### 2.7.3 여러 다항 분포 연결하기: 서열 모티프와 로고

[Kozak 모티프](http://www.sciencegateway.org/resources/kozak.htm)는 코딩 영역의 시작 코돈인 **ATG** 근처에서 발생하는 서열입니다. 시작 코돈 자체는 항상 고정된 철자를 가지고 있지만, 그 왼쪽으로 5개 위치에는 뉴클레오타이드 패턴이 나타나며 그곳의 글자들은 동일한 확률을 갖는 것과는 거리가 멉니다.

우리는 모든 위치에서의 다항 확률을 제공하는 **위치 가중치 행렬(position weight matrix, PWM)** 또는 **위치 특이적 점수 행렬(position-specific scoring matrix, PSSM)**을 제공함으로써 이를 요약합니다. 이는 **서열 로고(sequence logo)** (그림 2.13)를 통해 그래픽으로 인코딩됩니다.

    
    
    library("seqLogo")
    load("../data/kozak.RData")
    kozak
    
    
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
    A 0.33 0.25  0.4 0.15 0.20    1    0    0 0.05
    C 0.12 0.25  0.1 0.40 0.40    0    0    0 0.05
    G 0.33 0.25  0.4 0.20 0.25    0    0    1 0.90
    T 0.22 0.25  0.1 0.25 0.15    0    1    0 0.00
    
    
    pwm = makePWM(kozak)
    seqLogo(pwm, ic.scale = FALSE)

[![](02-chap_files/figure-html/fig-seqlogo-1-1.png)](02-chap_files/figure-
html/fig-seqlogo-1-1.png "그림 2.13: Kozak 모티프를 모델링하는 데 사용되는 위치 종속 다항 분포에 대한 서열 로고라 불리는 다이어그램입니다. 이는 각 위치에서의 변동량을 로그 스케일로 인코딩합니다. 큰 글자들은 어떤 뉴클레오타이드가 나타날지에 대해 불확실성이 없는 위치를 나타냅니다.")

그림 2.13: Kozak 모티프를 모델링하는 데 사용되는 위치 종속 다항 분포에 대한 서열 로고라 불리는 다이어그램입니다. 이는 각 위치에서의 변동량을 로그 스케일로 인코딩합니다. 큰 글자들은 어떤 뉴클레오타이드가 나타날지에 대해 불확실성이 없는 위치를 나타냅니다.

지난 몇 개 섹션에서 우리는 우리가 접했던 다항 분포의 서로 다른 "상자"들이 동일한 확률을 갖는 경우가 매우 드물다는 것을 보았습니다. 다시 말해, 매개변수 \(p_1, p_2, ...\)는 모델링되는 대상에 따라 대개 다릅니다. 동일하지 않은 빈도를 가진 다항 분포의 예로는 20가지의 서로 다른 아미노산, 혈액형, 머리카락 색깔 등이 있습니다.

만약 여러 개의 범주형 변수가 있다면, 우리는 그것들이 독립적인 경우가 드물다는 것을 보았습니다(성별과 색맹, 머리카락과 눈 색깔, ...). 우리는 나중에 [9장](09-chap.html)에서 분할표의 다변량 분해를 사용하여 이러한 의존성의 패턴을 탐구할 수 있음을 보게 될 것입니다. 여기서는 범주형 변수 간의 의존성의 중요한 특수한 사례, 즉 (예를 들어 시간의 흐름이나 바이오폴리머를 따라) 범주형 변수들의 시퀀스(또는 "체인")를 따라 발생하는 의존성을 살펴볼 것입니다.

## 2.8 순차적 의존성 모델링: 마르코프 체인

내일의 날씨를 예측하고 싶을 때, 합리적으로 좋은 추측은 오늘 날씨와 대체로 같을 것이라는 점이며, 여기에 더해 다양한 종류의 가능한 변화들에 대한 확률을 서술할 수도 있을 것입니다^[동일한 추론이 역으로도 적용될 수 있습니다: 우리는 오늘로부터 어제의 날씨를 "예측"할 수도 있습니다.]. 일기 예보를 위한 이 방법은 마르코프 가정(Markov assumption)의 한 예시입니다: 내일에 대한 예측은 오늘의 상태에만 의존하며, 어제나 3주 전의 상태에는 의존하지 않습니다 (우리가 잠재적으로 사용할 수 있는 모든 정보는 이미 오늘의 날씨에 포함되어 있습니다). 날씨 예제는 또한 그러한 가정이 반드시 정확할 필요는 없지만, 충분히 좋은 가정이어야 한다는 점을 강조합니다. 이 가정을 유한하고 너무 크지 않은 수 \(k\)에 대해 이전 \(k\)일 동안의 의존성으로 확장하는 것은 꽤 간단합니다. 마르코프 가정의 정수는 프로세스가 유한한 "기억"을 가지고 있어서 예측을 위해 유한한 시간만큼만 거슬러 올라가면 된다는 점입니다.

시간적 시퀀스 대신에, 우리는 이를 생물학적 서열에 적용할 수 있습니다. DNA에서 우리는 뉴클레오타이드 쌍인 다이그램(digrams), 예를 들어 [CG, CA, CC] 및 [CT]가 동일하게 빈번하지 않도록 특정 순차적 패턴을 볼 수 있습니다. 예를 들어, 유전체의 일부 영역에서 우리는 독립성 하에서 예상되는 것보다 [CA]의 사례를 더 자주 보게 됩니다:

\[ P(\mathtt{CA}) \neq P(\mathtt{C}) \, P(\mathtt{A}). \]

우리는 서열에서의 이러한 의존성을 **마르코프 체인(Markov chain)** 으로 모델링합니다:

\[ P(\mathtt{CA}) = P(\mathtt{NCA}) = P(\mathtt{NNCA}) = P(...\mathtt{CA}) = P(\mathtt{C}) \, P(\mathtt{A|C}), \]

여기서 N은 임의의 뉴클레오타이드를 나타내고, \(P(\mathtt{A|C})\)는 "앞선 염기가 \(\mathtt{C}\)일 때 \(\mathtt{A}\)가 나타날 확률"을 나타냅니다. 그림 2.14는 그래프 상의 그러한 전이들에 대한 도식적 표현을 보여줍니다.

[![](02-chap_files/figure-html/fig-statsfourstateMC-1.png)](02-chap_files/figure-
html/fig-statsfourstateMC-1.png "그림 2.14: 4-상태 마르코프 체인의 시각화. 각 가능한 다이그램(예: CA)의 확률은 대응하는 노드 사이의 에지(edge) 가중치로 주어집니다. 따라서 예를 들어 CA의 확률은 에지 C -> A로 주어집니다. 우리는 11장(sec-images)에서 이러한 유형의 네트워크 그래프를 그리기 위해 R 패키지를 사용하는 방법을 살펴볼 것입니다.")

그림 2.14: 4-상태 마르코프 체인의 시각화. 각 가능한 다이그램(예: CA)의 확률은 대응하는 노드 사이의 에지(edge) 가중치로 주어집니다. 따라서 예를 들어 CA의 확률은 에지 C -> A로 주어집니다. 우리는 [11장](11-chap.html)에서 이러한 유형의 네트워크 그래프를 그리기 위해 R 패키지를 사용하는 방법을 살펴볼 것입니다.

## 2.9 베이지안 사고방식

[![](imgs/turtlesalltheway.png)](imgs/turtlesalltheway.png "그림 2.15: 아래쪽으로 끝없는 거북이들. 분포의 매개변수에 대한 불확실성의 베이지안 모델링은, 매개변수에 따라 분포가 달라지는 확률 변수를 사용하고 그 매개변수 자체의 불확실성은 다시 확률 변수로 모델링함으로써 수행됩니다; 이들을 계층적 모델(hierarchical models)이라고 부릅니다.")

그림 2.15: 아래쪽으로 끝없는 거북이들. 분포의 매개변수에 대한 불확실성의 베이지안 모델링은, 매개변수에 따라 분포가 달라지는 확률 변수를 사용하고 그 매개변수 자체의 불확실성은 다시 확률 변수로 모델링함으로써 수행됩니다; 이들을 계층적 모델(hierarchical models)이라고 부릅니다.

지금까지 우리는 모델의 매개변수와 그것들이 사용하는 분포, 즉 가능한 서로 다른 결과의 확률이 장기적인 빈도를 나타내는 고전적인 접근 방식을 따랐습니다. 매개변수는 –적어도 개념적으로는– 확실하고 알 수 있으며 고정된 것입니다. 우리는 그것들을 모를 수도 있으므로, 손에 든 데이터로부터 그것들을 추정합니다. 하지만 그러한 접근 방식은 우리가 이미 가지고 있을 수 있는 정보, 즉 우리가 현재의 데이터 세트를 보기 _전_ 일지라도 매개변수에 대해 알려주거나 특정 매개변수 값 또는 그 조합이 다른 것보다 더 가능성 있게 만들 수 있는 정보를 고려하지 않습니다. 이를 위해서는 확률 모델(즉, 분포)을 사용하여 매개변수에 대한 사전 지식8을 표현하고, 현재 데이터를 사용하여 그러한 지식을 _업데이트_ 하는(예를 들어 해당 분포를 이동시키거나 더 좁게 만드는 등) 다른 접근 방식이 필요합니다. 그러한 접근 방식이 바로 베이지안 패러다임(그림 2.15)에 의해 제공됩니다.

8 어떤 사람들은 "우리들의 믿음(들)"이라고 말하기를 좋아합니다.

베이지안 패러다임은 데이터를 수집하고 관찰하기 _전_ 과 _후_ 의 우리 지식을 모델링하기 위해 _사전(prior)_ 및 _사후(posterior)_ 분포를 사용하는 실용적인 접근 방식입니다. 이는 무한히 반복될 수 있습니다: 한 차례의 데이터 생성 후의 사후 분포는 다음 차례를 위한 사전 분포로 사용될 수 있습니다. 따라서 이는 서로 다른 소스로부터의 정보를 통합하거나 결합하는 데에도 특히 유용합니다.

동일한 아이디어가 가설 검정에도 적용될 수 있는데, 여기서 우리는 가설 \(H\)라고 부를 수 있는 특정 진술이 참이라고 믿는지 결정하기 위해 데이터를 사용하고 싶어 합니다. 여기서 우리의 "매개변수"는 \(H\)가 참일 확률이며, 우리는 \(P(H)\)9라고 쓰여진 **사전** 확률의 형태로 우리의 사전 지식을 공식화할 수 있습니다. 데이터를 확인한 후에는 **사후** 확률을 갖게 됩니다. 우리는 이를 \(D\)를 보았을 때 \(H\)일 확률인 \(P(H\,|\,D)\)로 씁니다. 이는 데이터 \(D\)가 무엇이었는지에 따라 \(P(H)\)보다 높거나 낮을 수 있습니다.

9 소위 빈도론자(frequentist)에게 그러한 확률은 존재하지 않습니다. 그들의 관점은 비록 진실은 알려져 있지 않지만 가설은 실제로는 참이거나 거짓이라는 것입니다; 이를 "70% 참"이라고 부르는 것은 의미가 없습니다.

### 2.9.1 예제: 일배체형 빈도

수학적 형식주의를 최소한으로 유지하기 위해, Y 염색체의 결합된 시그니처(일배체형, haplotypes)를 사용하는 법의학 예제부터 시작하겠습니다.

_일배체형_ 이란 염색체 상에서 공간적으로 인접하여 대개 함께 유전되는(재조합에 의해 분리되지 않는 경향이 있음) 대립유전자(DNA 서열 변이체)들의 집합이며, 따라서 유전적으로 연결되어 있습니다. 이 사례에서 우리는 Y 염색체 상의 연결된 변이들을 살펴보고 있습니다.

먼저 일배체형 빈도 분석의 동기를 살펴보고, 우도(likelihood)에 대한 아이디어를 다시 방문해 보겠습니다. 그 후, 알려지지 않은 매개변수들을 그 자체로 난수인 것으로 생각하고 사전 분포를 사용하여 그 불확실성을 모델링하는 방법을 설명하겠습니다. 그런 다음 관찰된 새로운 데이터를 확률 분포에 통합하고 매개변수에 대한 사후 신뢰 진술을 어떻게 계산하는지 살펴볼 것입니다.

[![](imgs/STRDefinition.png)](imgs/STRDefinition.png "그림 2.16: DNA에서의 단일 반복 서열(short tandem repeat, STR)은 두 개 이상의 뉴클레오타이드 패턴이 반복되고 그 반복된 서열들이 서로 직접 인접해 있을 때 발생합니다. STR은 미세 부수체(microsatellite)라고도 알려져 있습니다. 패턴의 길이는 2에서 13 뉴클레오타이드 범위일 수 있으며, 반복 횟수는 개인마다 매우 다양합니다. STR 숫자는 유전적 시그니처로 사용될 수 있습니다.")

그림 2.16: DNA에서의 단일 반복 서열(short tandem repeat, STR)은 두 개 이상의 뉴클레오타이드 패턴이 반복되고 그 반복된 서열들이 서로 직접 인접해 있을 때 발생합니다. STR은 미세 부수체(microsatellite)라고도 알려져 있습니다. 패턴의 길이는 2에서 13 뉴클레오타이드 범위일 수 있으며, 반복 횟수는 개인마다 매우 다양합니다. STR 숫자는 유전적 시그니처로 사용될 수 있습니다.

[![](imgs/YSTRPositions.jpg)](imgs/YSTRPositions.jpg "그림 2.17: 인간 Y 염색체 상의 단일 반복 서열(STR) 위치. 출처: https://strbase.nist.gov/ystrpos1.htm")

그림 2.17: 인간 Y 염색체 상의 단일 반복 서열(STR) 위치. 출처: <https://strbase.nist.gov/ystrpos1.htm>

[![](imgs/USY-STR.png)](imgs/USY-STR.png "그림 2.18: FBI가 사용하는 데이터베이스에서의 Y STR 일배체형 조회.")

그림 2.18: FBI가 사용하는 데이터베이스에서의 Y STR 일배체형 조회.

우리는 서로 다른 단일 반복 서열(STR) 세트로 구성된 특정 Y-일배체형들의 빈도에 관심이 있습니다. DNA 법의학에 사용되는 특정 위치에서의 STR 숫자 조합은 해당 특정 위치에서의 반복 횟수로 라벨링됩니다. 다음은 그러한 STR 일배체형 표의 짧은 발췌본입니다:

    
    
    haplo6 = read.table("../data/haplotype6.txt", header = TRUE)
    haplo6
    
    
      Individual DYS19 DXYS156Y DYS389m DYS389n DYS389p
    1         H1    14       12       4      12       3
    2         H3    15       13       4      13       3
    3         H4    15       11       5      11       3
    4         H5    17       13       4      11       3
    5         H7    13       12       5      12       3
    6         H8    16       11       5      12       3

표는 일배체형 H1이 `DYS19` 위치에서 14번의 반복을 가지고, `DXYS156Y` 위치에서 12번의 반복을 가지는 식임을 보여줍니다. 관심 모집단에서 특정 일배체형의 기저 비율 \(p\)를 알아내기 위해 \(n=300\)명의 남성을 일배체형 분석하고 싶다고 가정해 봅시다; 그리고 그중 \(y=40\)명에게서 H1을 발견했다고 합시다. 우리는 이를 모델링하기 위해 이항 분포 \(B(n,p)\)를 사용할 것이며, 여기서 \(p\)는 알려져 있지 않습니다.

이러한 Y-STR 프로필을 사용하여 생성된 일배체형은 동일한 부계 혈통의 남성들 사이에 공유됩니다. 따라서 두 명의 서로 다른 남성이 동일한 프로필을 공유하는 것이 가능합니다.

### 2.9.2 이항 분포에 대한 베이지안 패러다임의 시뮬레이션 연구

우리 매개변수 \(p\)가 단 하나의 값(예: 최대 우도 추정치인 40/300)만을 가진다고 가정하는 대신, 베이지안 접근 방식은 이를 통계적 분포로부터의 추출로 볼 수 있게 해줍니다. 그 분포는 매개변수 \(p\)의 가능한 값들에 대한 우리의 믿음을 표현합니다. 원칙적으로 우리는 \(p\)에 대해 허용되는 가능한 값들을 가진 임의의 분포를 우리가 원하는 대로 사용할 수 있습니다. 여기서는 비율이나 확률을 나타내고 0과 1 사이의 값을 가지는 매개변수를 다루고 있으므로, _베타 분포(Beta distribution)_ 를 사용하는 것이 편리합니다. 그 밀도 공식은 다음과 같이 쓰여집니다.

\[ f_{\alpha,\beta}(x) = \frac{x^{\alpha-1}\,(1-x)^{\beta-1}}{\text{B}(\alpha,\beta)}\quad\text{여기서}\quad \text{B}(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}. \tag{2.6}\]

우리는 그림 2.19에서 이 함수가 두 매개변수 \(\alpha\)와 \(\beta\)에 어떻게 의존하는지 볼 수 있으며, 이는 매우 유연한 분포군을 만듭니다(수많은 서로 다른 상황에 "적합"할 수 있음). 그리고 이는 멋진 수학적 속성을 가집니다: 만약 우리가 베타 모양의 \(p\)에 대한 사전 믿음으로 시작하여, \(n\)번의 이항 시행으로 이루어진 데이터 세트를 관찰하고, 그 후 우리의 믿음을 업데이트한다면, \(p\)에 대한 사후 분포 또한 (업데이트된 매개변수들에도 불구하고) 베타 분포를 가질 것입니다. 이것은 수학적 사실입니다. 우리는 여기서 이를 증명하지는 않겠지만, 시뮬레이션을 통해 보여줄 것입니다.

[![](02-chap_files/figure-html/fig-histobeta2-1.png)](02-chap_files/figure-
html/fig-histobeta2-1.png "그림 2.19: \(\alpha=10, 20, 50\) 및 \(\beta=30, 60, 150\)인 베타 분포. 우리는 이들을 이항 실험에서의 성공 확률에 대한 사전 분포로 사용할 수 있습니다. 이 세 분포는 동일한 평균 \(\frac{\alpha}{\alpha +\beta}\)을 가지지만, 평균 주변의 집중도는 다릅니다.")

그림 2.19: \(\alpha=10, 20, 50\) 및 \(\beta=30, 60, 150\)인 베타 분포. 우리는 이들을 이항 실험에서의 성공 확률에 대한 **사전 분포**로 사용할 수 있습니다. 이 세 분포는 동일한 평균 (\(\frac{\alpha}{\alpha +\beta}\))을 가지지만, 평균 주변의 집중도는 다릅니다.

### 2.9.3 \(Y\)의 분포

주어진 \(p\)의 선택에 대해, 우리는 식 2.3에 의해 \(Y\)의 분포가 무엇인지 압니다. 하지만 만약 \(p\) 자체 또한 어떤 분포에 따라 변한다면 \(Y\)의 분포는 무엇일까요? 우리는 이를 \(Y\)의 **주변 분포(marginal distribution)**라고 부릅니다. 이를 시뮬레이션해 봅시다. 먼저 100,000개의 \(p\)에 대한 무작위 샘플 `rp`를 생성합니다. 그런 다음 각각에 대해 \(Y\)의 무작위 샘플을 생성하여 그림 2.20에 나타냅니다. 아래 코드에서는 시연을 위해 사전 분포의 매개변수로 50과 350을 사용합니다. 그러한 사전 분포는 이미 상당히 많은 정보를 담고 있으며("뾰족함"), 예를 들어 이전 연구들에 기초한 우리의 믿음을 반영할 수 있습니다. 질문 2.20에서는 "더 부드러운"(정보가 적은) 사전 분포를 시도해 볼 기회가 있을 것입니다. 우리는 다시 `vapply`를 사용하여 익명의 `x` 함수를 `rp`의 모든 요소에 적용하여 결과적으로 동일한 길이의 또 다른 벡터 `y`를 얻습니다.

    
    
    rp = rbeta(100000, 50, 350)
    y = vapply(rp, 
               function(x) rbinom(1, prob = x, size = 300), 
               integer(1))
    hist(y, breaks = 50, col = "orange", main = "", xlab = "")

[![](02-chap_files/figure-html/fig-
histmarginal-1-1.png)](02-chap_files/figure-html/fig-histmarginal-1-1.png
"그림 2.20: Y의 주변 분포.")

그림 2.20: \(Y\)의 주변 분포.



질문 2.18

R의 벡터화 기능을 사용하고 `rbinom(length(rp), rp, size = 300)`이라고 씀으로써 위의 코드 청크에서와 동일한 결과를 얻을 수 있는지 확인해 보세요.



해결책



    
    
    set.seed(0xbebe)
    y1 = vapply(rp, 
                function(x) rbinom(1, prob = x, size = 300), 
                integer(1))
    set.seed(0xbebe)
    y2 = rbinom(length(rp), rp, size = 300)
    stopifnot(identical(y1, y2))

### 2.9.4 \(Y=40\)을 만족하는 모든 \(p\)의 히스토그램: 사후 분포

이제 \(Y\)가 40인 결과들을 조건부로 하여 \(p\)의 사후 분포를 계산해 봅시다. 이를 이론적인 사후 분포인 `densPostTheory`와 비교해 볼 것인데, 이에 대해서는 아래에서 더 자세히 다룹니다. 결과는 그림 2.21에 나와 있습니다.

    
    
    pPostEmp = rp[ y == 40 ]
    hist(pPostEmp, breaks = 40, col = "chartreuse4", main = "",
      probability = TRUE, xlab = "사후 p")
    
    p_seq = seq(0, 1, by = 0.001)
    densPostTheory = dbeta(p_seq, 50 + 40, 350 + 260)
    lines(p_seq, densPostTheory, type = "l", lwd = 3)

[![](02-chap_files/figure-html/fig-
densityposterior-1-1.png)](02-chap_files/figure-
html/fig-densityposterior-1-1.png "그림 2.21: Y=40인 분포의 값들만을 선택하면 p의 사후 분포를 얻을 수 있습니다. 히스토그램(초록색)은 사후 분포에 대한 시뮬레이션된 값들을 보여주고, 선은 이론적 매개변수를 사용한 베타 분포의 밀도를 나타냅니다.")

그림 2.21: \(Y=40\)인 분포의 값들만을 선택하면 \(p\)의 사후 분포를 얻을 수 있습니다. 히스토그램(초록색)은 사후 분포에 대한 시뮬레이션된 값들을 보여주고, 선은 이론적 매개변수를 사용한 베타 분포의 밀도를 나타냅니다.

우리는 또한 위에서 계산된 두 분포의 평균을 확인하여 유효 숫자 4자리까지 가까움을 볼 수 있습니다.

    
    
    mean(pPostEmp)
    
    
    [1] 0.128726
    
    
    dp = p_seq[2] - p_seq[1]
    sum(p_seq * densPostTheory * dp)
    
    
    [1] 0.1285714

이론적 밀도 `densPostTheory`의 평균을 근사하기 위해, 우리는 위에서 문자 그대로 적분인

\[ \int_0^1 p \, f(p) \, dp \]

을 수치 적분, 즉 적분에 대한 `sum`을 사용하여 계산했습니다. 이는 특히 모델이 단일 스칼라 매개변수 \(p\)만을 포함하지 않고 많은 매개변수를 가져서 고차원 매개변수 벡터와 고차원 적분을 다루어야 할 때 항상 편리(하거나 실용적)하지는 않습니다. 만약 적분을 분석적으로 계산할 수 없다면, 우리는 **몬테카를로 적분(Monte Carlo integration)** 을 사용할 수 있습니다. 여러분은 위의 코드에서 몬테카를로 적분의 아주 간단한 사례를 이미 보셨는데, 거기서 우리는 `pPostEmp`로 사후 분포를 샘플링하고 R의 `mean` 함수를 호출하여 사후 평균을 계산하기 위해 통합을 수행했습니다. 이 경우, 대안적인 몬테카를로 알고리즘은 올바른 매개변수와 함께 `rbeta` 함수를 직접 사용하여 사후 샘플을 생성하는 것입니다.

    
    
    pPostMC = rbeta(n = 100000, 90, 610)
    mean(pPostMC)
    
    
    [1] 0.1285718

우리는 약간 다른 방식으로 생성된 몬테카를로 샘플 `pPostMC`와 `pPostEmp` 사이의 일치도를 **분위수-분위수 플롯(quantile-quantile plot, QQ-plot** , 그림 2.22)을 사용하여 확인할 수 있습니다.

    
    
    qqplot(pPostMC, pPostEmp, type = "l", asp = 1)
    abline(a = 0, b = 1, col = "blue")

[![](02-chap_files/figure-html/fig-qqplotbeta-1-1.png)](02-chap_files/figure-
html/fig-qqplotbeta-1-1.png "그림 2.22: 이론적 분포로부터 얻은 우리 몬테카를로 샘플 pPostMC와 우리 시뮬레이션 샘플 pPostEmp의 분위수-분위수(QQ) 플롯. 또한 이 두 분포 중 하나를 이론적 분포 함수 pbeta(., 90, 610)와 유사하게 비교할 수도 있습니다. 곡선이 y=x 선 위에 있다면 이는 좋은 일치를 나타냅니다. 꼬리 부분에는 약간의 무작위 차이가 있습니다.")

그림 2.22: 이론적 분포로부터 얻은 우리 몬테카를로 샘플 `pPostMC`와 우리 시뮬레이션 샘플 `pPostEmp`의 QQ(Quantile-Quantile) 플롯. 또한 이 두 분포 중 하나를 이론적 분포 함수 `pbeta(., 90, 610)`와 유사하게 비교할 수도 있습니다. 곡선이 \(y=x\) 선 위에 있다면 이는 좋은 일치를 나타냅니다. 꼬리 부분에는 약간의 무작위 차이가 있습니다.



질문 2.19

`pPostEmp`로 이어지는 시뮬레이션과 `pPostMC`로 이어지는 몬테카를로 시뮬레이션의 차이는 무엇인가요?

### 2.9.5 사후 분포 또한 베타 분포입니다.

이제 우리는 사후 분포 또한 베타임을 확인했습니다. 우리 사례에서 그 매개변수 \(\alpha=90\)과 \(\beta=610\)은 사전 매개변수 \(\alpha=50, \beta=350\)에 관측된 성공 횟수 \(y=40\)과 관측된 실패 횟수 \(n-y=260\)를 각각 더함으로써 얻어졌습니다.

\[ \text{Beta}(90,\, 610)=\text{Beta}(\alpha+y,\beta+(n-y)). \]

우리는 사후 분포에 의해 주어지는 불확실성과 함께 \(p\)에 대해 우리가 할 수 있는 최선의10 추정치를 제공하기 위해 이를 사용할 수 있습니다.

10 사후 분포를 최대화하는 값을 최선의 추정치로 취할 수 있으며, 이를 **MAP** 추정치라고 합니다. 이 경우에는 \(\frac{\alpha-1}{\alpha+\beta-2}=\frac{89}{698}\doteq 0.1275\)가 될 것입니다.

### 2.9.6 두 번째 데이터 시리즈가 있다고 가정해 봅시다.

이전 데이터를 본 후, 우리는 이제 새로운 사전 분포인 \(\text{Beta}(90, 610)\)을 가집니다. 우리가 \(n=150\)번의 관측을 하여 \(y=25\)번의 성공, 즉 125번의 실패를 얻은 새로운 데이터 세트를 수집한다고 가정해 봅시다. 이제 \(p\)에 대한 우리의 최선의 추측은 무엇이 될까요?

이전과 동일한 추론을 사용하면, 새로운 사후 분포는 \(\text{Beta}(90+25=115,\, 610+125=735)\)가 될 것입니다. 이 분포의 평균은 \(\frac{115}{115+735}=\frac{115}{850}\simeq 0.135\)이므로, \(p\)의 한 추정치는 0.135가 될 것입니다. **최대 사후(maximum a posteriori, MAP)** 추정치는 \(\text{Beta}(115, 735)\)의 모드(mode), 즉 \(\frac{114}{848}\simeq 0.134\)입니다. 이를 수치적으로 확인해 봅시다.

    
    
    densPost2 = dbeta(p_seq, 115, 735)
    mcPost2   = rbeta(1e6, 115, 735)
    sum(p_seq * densPost2 * dp)   # 수치 적분에 의한 평균
    
    
    [1] 0.1352941
    
    
    mean(mcPost2)                 # MC에 의한 평균
    
    
    [1] 0.1352655
    
    
    p_seq[which.max(densPost2)]   # MAP 추정치
    
    
    [1] 0.134



질문 2.20

우리의 원래 사전 분포를 덜 뾰족한(softer) 사전 분포로 대체하여 모든 계산을 다시 수행해 보세요. 즉, 사전 정보를 덜 사용한다는 의미입니다. 예를 들어, 균등 분포인 Beta(1,1)을 시도해 보세요. 이것이 최종 결과를 얼마나 변화시키나요?

일반적인 규칙으로서, 사전 분포는 그것이 매우 뾰족하지 않은 한 사후 분포를 실질적으로 변화시키는 경우가 드뭅니다. 처음에 우리가 무엇을 기대할지 이미 상당히 확신하고 있었다면 그런 경우가 될 것입니다. 사전 분포가 영향을 미치는 또 다른 경우는 데이터가 매우 적을 때입니다.

최선의 상황은 사전 분포를 압도할 만큼 충분한 데이터를 확보하여 사전 분포의 선택이 최종 결과에 큰 영향을 미치지 않도록 하는 것입니다.

### 2.9.7 비율 매개변수에 대한 신뢰 진술

이제 데이터가 주어졌을 때 비율 \(p\)가 실제로 무엇인지에 대해 결론을 내릴 차례입니다. 한 가지 요약 수치는 신뢰 구간(confidence interval)의 베이지안 대응물인 사후 신용 구간(posterior credibility interval)입니다. 우리는 사후 분포의 2.5% 및 97.5% 백분위수를 취할 수 있습니다: \(P(q_{2.5\%} \leq p \leq q_{97.5\%})=0.95\).

    
    
    quantile(mcPost2, c(0.025, 0.975))
    
    
         2.5%     97.5% 
    0.1131080 0.1590221 

[![](imgs/DESeq2-Prediction-Interval.png)](imgs/DESeq2-Prediction-Interval.png
"그림 2.23: Love 등(2014)의 예시는 초록색과 보라색 유전자에 대한 우도(실선, 1로 적분되도록 스케일 조정됨), 사후 분포(점선), 그리고 사전 분포(검은색 실선)의 플롯을 보여줍니다: 보라색 유전자의 더 높은 분산으로 인해 그 우도는 더 넓고 덜 뾰족하며(정보가 적음을 나타냄), 사전 분포가 초록색 유전자의 경우보다 그 사후 분포에 더 많은 영향을 미칩니다. 최댓값 지점에서의 초록색 사후 분포의 더 강한 곡률은 MAP 로그 폴드 변화(logarithmic fold change, LFC) 추정치(가로 오차 막대)에 대해 보고된 표준 오차가 더 작음을 의미합니다.")

그림 2.23: Love, Huber, Anders ([2014](16-chap.html#ref-LoveDESeq2))의 예시는 초록색과 보라색 유전자에 대한 우도(실선, 1로 적분되도록 스케일 조정됨), 사후 분포(점선), 그리고 사전 분포(검은색 실선)의 플롯을 보여줍니다: 보라색 유전자의 더 높은 분산으로 인해 그 우도는 더 넓고 덜 뾰족하며(정보가 적음을 나타냄), 사전 분포가 초록색 유전자의 경우보다 그 사후 분포에 더 많은 영향을 미칩니다. 최댓값 지점에서의 초록색 사후 분포의 더 강한 곡률은 MAP 로그 폴드 변화(logarithmic fold change, LFC) 추정치(가로 오차 막대)에 대해 보고된 표준 오차가 더 작음을 의미합니다.

## 2.10 예제: 유전체에서의 뉴클레오타이드 패턴 발생

지금까지 우리가 본 예제들은 이산형 카운트와 범주형 데이터의 분포에 집중되어 있었습니다. 이제 준연속형(quasi-continuous)인 거리 분포의 예제를 살펴봅시다. 유전체 서열에서의 특정 모티프 인스턴스 간 거리 분포에 대한 이 사례 연구는 우리가 바이오컨덕터에서의 구체적인 유전체 서열 조작을 탐색할 수 있게 해줄 것입니다.

**[Biostrings](https://bioconductor.org/packages/Biostrings/)** 패키지는 서열 데이터 작업을 위한 도구들을 제공합니다. 필수적인 데이터 구조, 즉 R의 _클래스(classes)_ 들은 _DNAString_ 과 _DNAStringSet_ 입니다. 이들은 우리가 하나 또는 여러 개의 DNA 서열을 효율적으로 다룰 수 있게 해줍니다.

**[Biostrings](https://bioconductor.org/packages/Biostrings/)** 패키지는 또한 아미노산 서열과 더 일반적인 생물학 영감 서열들을 표현하기 위한 추가적인 클래스들을 포함하고 있습니다.

    
    
    library("Biostrings")



질문 2.21

튜토리얼 비네트(vignette)를 탐색하여 Biostrings 패키지에서 제공되는 유용한 데이터와 함수들을 일부 살펴보세요.



해결책



첫 번째 줄은 유전 코드 정보를 출력하고, 두 번째 줄은 IUPAC 뉴클레오타이드 모호성 코드를 반환합니다. 세 번째 줄은 **[Biostrings](https://bioconductor.org/packages/Biostrings/)** 패키지에서 가용한 모든 비네트를 나열하며, 네 번째 줄은 특정 비네트 하나를 표시합니다.

    
    
    GENETIC_CODE
    IUPAC_CODE_MAP
    vignette(package = "Biostrings")
    vignette("BiostringsQuickOverview", package = "Biostrings")

이 마지막 명령은 브라우저 창에서 설명서에 접근할 수 있는 목록을 열어줄 것입니다11. **[BSgenome](https://bioconductor.org/packages/BSgenome/)** 패키지는 많은 유전체에 대한 접근을 제공하며, 다음과 같이 입력하여 전체 유전체 서열을 포함하는 데이터 패키지들의 이름을 확인할 수 있습니다.

11 비네트(Vignettes)는 예제와 사례 연구가 포함된 패키지 매뉴얼입니다.

    
    
    library("BSgenome")
    ag = available.genomes()
    length(ag)
    
    
    [1] 113
    
    
    ag[1:2]
    
    
    [1] "BSgenome.Alyrata.JGI.v1"              
    [2] "BSgenome.Amellifera.BeeBase.assembly4"

우리는 대장균(E.coli) 유전체에서의 `AGGAGGT` 모티프12 발생을 조사해 볼 것입니다. 우리는 특정 균주인 **Escherichia coli** str. K12 substr.DH10B13의 유전체 서열을 사용하며, 그 NCBI 기탁 번호는 NC_010473입니다.

12 이것은 박테리아에서 단백질 합성을 개시하는 데 도움을 주는 [Shine-Dalgarno](https://en.wikipedia.org/wiki/Shine-Dalgarno_sequence) 모티프입니다.

13 실험실의 "일꾼"으로 알려져 있으며 실험에 자주 사용됩니다.

    
    
    library("BSgenome.Ecoli.NCBI.20080805")
    Ecoli
    shineDalgarno = "AGGAGGT"
    ecoli = Ecoli$NC_010473

우리는 `countPattern` 함수를 사용하여 너비 50,000의 윈도우에서 패턴의 발생 횟수를 셀 수 있습니다.

    
    
    window = 50000
    starts = seq(1, length(ecoli) - window, by = window)
    ends   = starts + window - 1
    numMatches = vapply(seq_along(starts), function(i) {
      countPattern(shineDalgarno, ecoli[starts[i]:ends[i]],
                   max.mismatch = 0)
      }, numeric(1))
    table(numMatches)
    
    
    numMatches
     0  1  2  3  4 
    48 32  8  3  2 



질문 2.22

이 표는 어떤 분포에 잘 맞을까요?



해결책



이러한 데이터에 대한 정량적 및 그래픽 평가(그림 2.24 참조)가 보여주듯이, 푸아송 분포가 좋은 후보입니다.

    
    
    library("vcd")
    gf = goodfit(numMatches, "poisson")
    summary(gf)
    
    
        Goodness-of-fit test for poisson distribution
    
                          X^2 df  P(> X^2)
    Likelihood Ratio 4.134932  3 0.2472577
    
    
    distplot(numMatches, type = "poisson")

[![](02-chap_files/figure-html/fig-poissonness-1.png)](02-chap_files/figure-
html/fig-poissonness-1.png "그림 2.24: Ecoli$NC_010473 서열을 따른 모티프 카운트에 대한 푸아송 모델 평가.")

그림 2.24: `Ecoli$NC_010473` 서열을 따른 모티프 카운트에 대한 푸아송 모델 평가.

우리는 `matchPattern` 함수를 사용하여 일치하는 것들을 조사할 수 있습니다.

    
    
    sdMatches = matchPattern(shineDalgarno, ecoli, max.mismatch = 0)

R 커맨드 라인에 `sdMatches`를 입력하여 이 객체에 대한 요약을 얻을 수 있습니다. 여기에는 원래 서열 상에서의 이른바 _뷰(views)_ 들의 집합으로 표현된 모든 65개의 패턴 일치 위치들이 포함되어 있습니다. 이제 그들 사이의 거리는 얼마일까요?

    
    
    betweenmotifs = gaps(sdMatches)

따라서 이들은 사실 66개의 보충적인 영역들입니다. 이제 모티프들 사이의 간격(gap) 크기 분포에 대한 모델을 찾아봅시다. 만약 모티프들이 무작위 위치에서 발생한다면, 우리는 간격 길이가 지수 분포(exponential distribution)를 따를 것으로 기대합니다14. 아래 코드(그 출력은 그림 2.25에 나타남)는 이 가정을 평가합니다. 만약 지수 분포가 잘 맞는다면, 점들은 대략 직선 위에 놓여야 합니다. 지수 분포는 비율(rate)이라는 하나의 매개변수를 가지며, 데이터로부터 얻은 추정치에 해당하는 기울기를 가진 선 또한 표시되었습니다.

14 여기서 왜 지수 분포가 적합한지 어떻게 추측할 수 있을까요? 서열을 따라 독립적이고 무작위적인 베르누이 발생이 있을 때마다, 간격 길이는 지수 분포를 따릅니다. 여러분은 방사성 붕괴에 익숙하실 텐데, 거기서 방출 사이의 대기 시간 또한 지수 분포를 따릅니다. 이 분포가 생소하시다면 [위키백과](http://en.wikipedia.org/wiki/Exponential_distribution)에서 더 자세한 내용을 찾아보시기를 추천합니다.

    
    
    library("Renext")
    expplot(width(betweenmotifs), rate = 1/mean(width(betweenmotifs)),
            labels = "fit")

[![](02-chap_files/figure-html/fig-expplotdata-1-1.png)](02-chap_files/figure-
html/fig-expplotdata-1-1.png "그림 2.25: 모티프 간 간격들의 지수 분포(검은색 실선) 적합도 평가.")

그림 2.25: 모티프 간 간격들의 지수 분포(검은색 실선) 적합도 평가.



질문 2.23

그림 2.25의 적합된 선에서 분포의 오른쪽 꼬리, 즉 가장 큰 값들 부근에서 약간의 이탈이 있는 것으로 보입니다. 그 이유가 무엇일 수 있을까요?

### 2.10.1 의존성이 있는 경우의 모델링

2.8절에서 보았듯이, 뉴클레오타이드 서열은 종종 의존성을 갖습니다: 특정 위치에서 어떤 뉴클레오타이드를 보게 될 확률은 주변 서열에 의존하는 경향이 있습니다. 여기서 우리는 **마르코프 체인(Markov chain)** 을 사용하여 의존성 모델링을 실습해 볼 것입니다. 우리는 인간 유전체의 8번 염색체 영역들을 살펴보고, CpG15 섬(islands)이라 불리는 영역들과 나머지 영역들 사이의 차이점을 발견해 보려 합니다.

15 CpG는 5'-C-phosphate-G-3'을 의미합니다; 즉, C가 가닥을 따라 인산염을 통해 G와 연결되어 있음을 뜻합니다 (이는 2.7절의 C-G 염기쌍과는 무관합니다). CpG 디뉴클레오타이드의 사이토신은 메틸화될 수 있으며, 이는 유전자 발현 수준을 변화시킵니다. 이러한 유형의 유전자 조절은 **후생유전학(epigenetics)** 의 일부입니다. 위키백과에서 더 많은 정보를 찾을 수 있습니다: [CpG 사이트(CpG site)](https://en.wikipedia.org/wiki/CpG_site) 및 [후생유전학(epigenetics)](https://en.wikipedia.org/wiki/Epigenetics).

우리는 유전체에서 섬들의 시작점과 끝점이 어디인지 알려주는 (Irizarry, Wu, Anders ([2009](16-chap.html#ref-Irizarry2009))에 의해 생성된) 데이터를 사용하여, 뉴클레오타이드들과 ‘CG’, ‘CT’, ‘CA’, ‘CC’와 같은 다이그램들의 빈도를 살펴볼 것입니다. 따라서 우리는 뉴클레오타이드 발생 사이에 의존성이 있는지, 그리고 있다면 이를 어떻게 모델링할지 물을 수 있습니다.

    
    
    library("BSgenome.Hsapiens.UCSC.hg19")
    chr8  =  Hsapiens$chr8
    CpGtab = read.table("../data/model-based-cpg-islands-hg19.txt",
                        header = TRUE)
    nrow(CpGtab)
    
    
    [1] 65699
    
    
    head(CpGtab)
    
    
        chr  start    end length CpGcount GCcontent pctGC obsExp
    1 chr10  93098  93818    721       32       403 0.559  0.572
    2 chr10  94002  94165    164       12        97 0.591  0.841
    3 chr10  94527  95302    776       65       538 0.693  0.702
    4 chr10 119652 120193    542       53       369 0.681  0.866
    5 chr10 122133 122621    489       51       339 0.693  0.880
    6 chr10 180265 180720    456       32       256 0.561  0.893
    
    
    irCpG = with(dplyr::filter(CpGtab, chr == "chr8"),
             IRanges(start = start, end = end))

[![우리는 dplyr 패키지로부터 명시적으로 filter 함수를 호출하기 위해 :: 연산자를 사용합니다 – 동일한 이름의 함수를 정의하고 있는 다른 패키지들이 로드되어 있을 수도 있기 때문입니다. 특히 filter 함수의 경우 이 명칭이 꽤 많은 다른 패키지들에서 사용되므로 이러한 예방 조치가 특히 권장됩니다. R 함수를 (:: 없이) 호출하는 일반적인 방식은 사람들을 이름으로 부르는 것과 유사하다고 생각할 수 있습니다; 반면 ::를 사용한 완전 수식 버전은 누군가를 성과 이름을 포함한 전체 이름으로 부르는 것에 해당합니다. 최소한 CRAN 및 바이오컨덕터 저장소 내에서는 이러한 완전 수식 이름들은 고유함이 보장됩니다.](imgs/devil.png)](imgs/devil.png "우리는 dplyr 패키지로부터 명시적으로 filter 함수를 호출하기 위해 :: 연산자를 사용합니다 – 동일한 이름의 함수를 정의하고 있는 다른 패키지들이 로드되어 있을 수도 있기 때문입니다. 특히 filter 함수의 경우 이 명칭이 꽤 많은 다른 패키지들에서 사용되므로 이러한 예방 조치가 특히 권장됩니다. R 함수를 (:: 없이) 호출하는 일반적인 방식은 사람들을 이름으로 부르는 것과 유사하다고 생각할 수 있습니다; 반면 ::를 사용한 완전 수식 버전은 누군가를 성과 이름을 포함한 전체 이름으로 부르는 것에 해당합니다. 최소한 CRAN 및 바이오컨덕터 저장소 내에서는 이러한 완전 수식 이름들은 고유함이 보장됩니다.")

우리는 `dplyr` 패키지로부터 명시적으로 `filter` 함수를 호출하기 위해 `::` 연산자를 사용합니다 – 동일한 이름의 함수를 정의하고 있는 다른 패키지들이 로드되어 있을 수도 있기 때문입니다. 특히 `filter` 함수의 경우 이 명칭이 꽤 많은 다른 패키지들에서 사용되므로 이러한 예방 조치가 특히 권장됩니다. R 함수를 (`::` 없이) 호출하는 일반적인 방식은 사람들을 이름으로 부르는 것과 유사하다고 생각할 수 있습니다; 반면 `::`를 사용한 완전 수식 버전은 누군가를 성과 이름을 포함한 전체 이름으로 부르는 것에 해당합니다. 최소한 CRAN 및 바이오컨덕터 저장소 내에서는 이러한 완전 수식 이름들은 고유함이 보장됩니다.

위의 줄에서, 우리는 데이터 프레임 `CpGtab`을 8번 염색체로만 하위 집합화(`filter`)한 다음, 데이터 프레임의 동일한 이름의 열들에 의해 시작 및 종료 위치가 정의되는 _IRanges_ 객체를 만듭니다. (인수들로부터 객체를 생성하는) `IRanges` 함수 호출에서, 첫 번째 `start`는 함수의 인수 이름이고, 두 번째 `start`는 `filter`의 출력으로 얻은 데이터 프레임의 열을 나타냅니다; `end`에 대해서도 마찬가지입니다. _IRanges_ 는 수학적 구간들을 위한 일반적인 컨테이너입니다. 우리는 다음 줄로 생물학적 맥락을 만듭니다16.

16 _IRanges_ 에서의 "I"는 "구간(interval)"을 의미합니다; _GRanges_ 에서의 "G"는 "유전체(genomic)"를 의미합니다.

    
    
    grCpG = GRanges(ranges = irCpG, seqnames = "chr8", strand = "+")
    genome(grCpG) = "hg19"

이제 시각화해 봅시다; 그림 2.26의 출력을 보세요.

    
    
    library("Gviz")
    ideo = IdeogramTrack(genome = "hg19", chromosome = "chr8")
    plotTracks(
      list(GenomeAxisTrack(),
        AnnotationTrack(grCpG, name = "CpG"), ideo),
        from = 2200000, to = 5800000,
        shape = "box", fill = "#006400", stacking = "dense")

[![](02-chap_files/figure-html/fig-freqandbayes-
ideo-1.png)](02-chap_files/figure-html/fig-freqandbayes-ideo-1.png
"그림 2.26: 8번 염색체의 선택된 영역에 있는 CpG 위치들의 Gviz 플롯.")

그림 2.26: **[Gviz](https://bioconductor.org/packages/Gviz/)**를 이용한 8번 염색체의 선택된 영역에 있는 CpG 위치들의 플롯.

우리는 이제 CpG 섬인 `irCpG`와 그 사이의 영역들(`gaps(irCpG)`)에 해당하는 염색체 서열 상의 소위 뷰(views)들을 정의합니다. 결과로 나오는 객체 `CGIview`와 `NonCGIview`는 오직 좌표들만을 포함하며 서열 그 자체는 포함하지 않으므로 (이들은 큰 객체인 `Hsapiens$chr8`에 머뭅니다), 저장 공간 측면에서 상당히 가볍습니다.

    
    
    CGIview    = Views(unmasked(Hsapiens$chr8), irCpG)
    NonCGIview = Views(unmasked(Hsapiens$chr8), gaps(irCpG))

우리는 데이터를 사용하여 CpG 섬과 비섬에서의 전이(transition) 횟수를 계산합니다.

    
    
    seqCGI      = as(CGIview, "DNAStringSet")
    seqNonCGI   = as(NonCGIview, "DNAStringSet")
    dinucCpG    = sapply(seqCGI, dinucleotideFrequency)
    dinucNonCpG = sapply(seqNonCGI, dinucleotideFrequency)
    dinucNonCpG[, 1]
    
    
     AA  AC  AG  AT  CA  CC  CG  CT  GA  GC  GG  GT  TA  TC  TG  TT 
    389 351 400 436 498 560 112 603 359 336 403 336 330 527 519 485 
    
    
    NonICounts = rowSums(dinucNonCpG)
    IslCounts  = rowSums(dinucCpG)

우리가 가진 4-상태 마르코프 체인의 경우, 행이 'from' 상태이고 열이 'to' 상태인 전이 행렬을 정의합니다.

    
    
    TI  = matrix( IslCounts, ncol = 4, byrow = TRUE)
    TnI = matrix(NonICounts, ncol = 4, byrow = TRUE)
    dimnames(TI) = dimnames(TnI) =
      list(c("A", "C", "G", "T"), c("A", "C", "G", "T"))

우리는 각 유형의 전이 횟수 카운트를 사용하여 빈도를 계산하고 이를 두 행렬에 담습니다.

[![전이 확률은 확률이므로 행의 합이 1이어야 합니다.](imgs/devil.png)](imgs/devil.png "전이 확률은 확률이므로 행의 합이 1이어야 합니다.")

전이 확률은 확률이므로 행의 합이 1이어야 합니다.

    
    
    MI = TI /rowSums(TI)
    MI
    
    
               A         C         G         T 
    A 0.20457773 0.2652333 0.3897678 0.1404212 
    C 0.20128250 0.3442381 0.2371595 0.2173200 
    G 0.18657245 0.3145299 0.3450223 0.1538754 
    T 0.09802105 0.3352314 0.3598984 0.2068492 
    
    
    MN = TnI / rowSums(TnI)
    MN
    
    
              A         C          G         T 
    A 0.3351380 0.1680007 0.23080886 0.2660524 
    C 0.3641054 0.2464366 0.04177094 0.3476871 
    G 0.2976696 0.2029017 0.24655406 0.2528746 
    T 0.2265813 0.1972407 0.24117528 0.3350027



질문 2.24

서로 다른 행들에서 전이들이 다른가요? 이는 예를 들어 \(P(\mathtt{A}\,|\,\mathtt{C}) \neq P(\mathtt{A}\,|\,\mathtt{T})\)인 상황을 의미합니다.



해결책



전이들이 다릅니다. 예를 들어, 섬(island) 내부의 전이 행렬(MI)에서 C에서 A로의 전이와 T에서 A로의 전이는 매우 다르게 보입니다 (0.201 대 0.098).



질문 2.25

CpG 섬에서의 서로 다른 뉴클레오타이드들의 상대적 빈도가 다른 곳과 비교했을 때 다른가요?



해결책



    
    
    freqIsl = alphabetFrequency(seqCGI, baseOnly = TRUE, collapse = TRUE)[1:4]
    freqIsl / sum(freqIsl)
    
    
            A         C         G         T 
    0.1781693 0.3201109 0.3206298 0.1810901 
    
    
    freqNon = alphabetFrequency(seqNonCGI, baseOnly = TRUE, collapse = TRUE)[1:4]
    freqNon / sum(freqNon)
    
    
            A         C         G         T 
    0.3008292 0.1993832 0.1993737 0.3004139 

이는 반대되는 패턴을 보여줍니다: CpG 섬에서는 C와 G가 약 0.32의 빈도를 가지는 반면, 비-CpG 섬에서는 A와 T가 약 0.30의 빈도를 가집니다.



질문 2.26

이러한 차이점들을 사용하여 주어진 서열이 CpG 섬으로부터 오는지 여부를 어떻게 결정할 수 있을까요?



해결책



관찰된 빈도와 `freqIsl` 및 `freqNon` 빈도 사이를 비교하기 위해 \(\chi^2\) 통계량을 사용합니다. 더 짧은 서열의 경우, 이는 충분히 민감하지 않을 수 있으며 아래에 더 민감한 접근 방식이 제시됩니다.

어떤 서열이 CpG 섬 내부에 있는지 아닌지 모르는 상태로 주어졌을 때, 우리는 그 서열이 다른 곳과 비교했을 때 CpG 섬에 속할 확률이 얼마나 되는지 물을 수 있습니다. 우리는 오즈 비(odds ratio)에 기반하여 점수를 계산합니다. 예제를 하나 들어봅시다: 우리 서열 \(x\)가 `ACGTTATACTACG`이고, 이것이 CpG 섬으로부터 오는지 여부를 결정하고 싶다고 가정해 봅시다.

서열을 1차 마르코프 체인으로 모델링한다면, 그 서열이 CpG 섬으로부터 온다고 가정할 때 다음과 같이 쓸 수 있습니다:

\[ \begin{align} P_{\text{i}}(x = \mathtt{ACGTTATACTACG}) = \; &P_{\text{i}}(\mathtt{A}) \, P_{\text{i}}(\mathtt{AC})\, P_{\text{i}}(\mathtt{CG})\, P_{\text{i}}(\mathtt{GT})\, P_{\text{i}}(\mathtt{TT}) \times \\ &P_{\text{i}}(\mathtt{TA})\, P_{\text{i}}(\mathtt{AT})\, P_{\text{i}}(\mathtt{TA})\, P_{\text{i}}(\mathtt{AC})\, P_{\text{i}}(\mathtt{CG}). \end{align} \]

우리는 이 확률을 섬이 아닌 곳에 대한 확률과 비교할 것입니다. 위에서 보았듯이, 이러한 확률들은 상당히 다른 경향이 있습니다. 우리는 그들의 비율을 취해서 그것이 1보다 큰지 작은지 볼 것입니다. 이 확률들은 많은 작은 항들의 곱이 될 것이며 매우 작아질 것입니다. 우리는 로그를 취함으로써 이 문제를 해결할 수 있습니다.

\[ \begin{align} \log&\frac{P(x\,|\, \text{섬})}{P(x\,|\,\text{비섬})}=\\\\log&\left( \frac{P_{\text{i}}(\mathtt{A})\, P_{\text{i}}(\mathtt{A}\rightarrow \mathtt{C})\, P_{\text{i}}(\mathtt{C}\rightarrow \mathtt{G})\, P_{\text{i}}(\mathtt{G}\rightarrow \mathtt{T})\, P_{\text{i}}(\mathtt{T}\rightarrow \mathtt{T})\, P_{\text{i}}(\mathtt{T}\rightarrow \mathtt{A})} {P_{\text{n}}(\mathtt{A})\, P_{\text{n}}(\mathtt{A}\rightarrow \mathtt{C})\, P_{\text{n}}(\mathtt{C}\rightarrow \mathtt{G})\, P_{\text{n}}(\mathtt{G}\rightarrow \mathtt{T})\, P_{\text{n}}( \mathtt{T}\rightarrow \mathtt{T})\, P_{\text{n}}( \mathtt{T}\rightarrow \mathtt{A})} \right. \times\\ &\left.\mathtt{A}\rightarrow \mathtt{T})\, P_{\text{i}}(\mathtt{T}\rightarrow \mathtt{A})\, P_{\text{i}}(\mathtt{A}\rightarrow \mathtt{C})\, P_{\text{i}}(\mathtt{C}\rightarrow \mathtt{G})} {P_{\text{n}}(\mathtt{A}\rightarrow \mathtt{T})\, P_{\text{n}}(\mathtt{T}\rightarrow \mathtt{A})\, P_{\text{n}}(\mathtt{A}\rightarrow \mathtt{C})\, P_{\text{n}}(\mathtt{C}\rightarrow \mathtt{G})} \right) \end{align} \tag{2.7}\]

이것이 **로그 우도 비(log-likelihood ratio)** 점수입니다. 계산 속도를 높이기 위해, 우리는 로그 비율들인 \(\log(P_{\text{i}}(\mathtt{A})/P_{\text{n}}(\mathtt{A})),..., \log(P_{\text{i}}(\mathtt{T}\rightarrow \mathtt{A})/P_{\text{n}}(\mathtt{T}\rightarrow \mathtt{A}))\)을 한 번에 계산한 다음, 관련 있는 것들을 모두 더하여 우리 점수를 얻습니다.

[![연구된 예제들과 많은 유용한 세부 사항들을 Durbin 등(1998)에서 찾아볼 수 있습니다.](imgs/book_icon.png)](imgs/book_icon.png "연구된 예제들과 많은 유용한 세부 사항들을 @DEKM에서 찾아볼 수 있습니다.")

연구된 예제들과 많은 유용한 세부 사항들을 Durbin 등 ([1998](16-chap.html#ref-DEKM))에서 찾아볼 수 있습니다.

    
    
    alpha = log((freqIsl/sum(freqIsl)) / (freqNon/sum(freqNon)))
    beta  = log(MI / MN)

    
    
    x = "ACGTTATACTACG"
    scorefun = function(x) {
      s = unlist(strsplit(x, ""))
      score = alpha[s[1]]
      if (length(s) >= 2)
        for (j in 2:length(s))
          score = score + beta[s[j-1], s[j]]
      score
    }
    scorefun(x)
    
    
             A 
    -0.2824623 

아래 코드에서, 우리는 `seqCGI` 객체의 2855개 서열 중 100 길이(`len = 100`)의 서열들을 뽑고, 그 다음 `seqNonCGI` 객체의 2854개 서열 중에서도 마찬가지로 뽑습니다 (각각은 _DNAStringSet_ 입니다). `generateRandomScores` 함수의 처음 세 줄에서, 우리는 A, C, T, G 이외의 글자(예: 정의되지 않은 뉴클레오타이드에 사용되는 글자인 ".")를 포함하는 서열들을 버립니다. 남은 서열들 중에서 서열 길이에 `len`을 뺀 값에 비례하는 확률로 샘플링한 다음, 그중에서 100 길이의 하위 서열을 뽑습니다. 하위 서열의 시작점들은 하위 서열이 전체 서열 내에 들어와야 한다는 제약 조건을 두고 균등하게 샘플링됩니다.

    
    
    generateRandomScores = function(s, len = 100, B = 1000) {
      alphFreq = alphabetFrequency(s)
      isGoodSeq = rowSums(alphFreq[, 5:ncol(alphFreq)]) == 0
      s = s[isGoodSeq]
      slen = sapply(s, length)
      prob = pmax(slen - len, 0)
      prob = prob / sum(prob)
      idx  = sample(length(s), B, replace = TRUE, prob = prob)
      ssmp = s[idx]
      start = sapply(ssmp, function(x) sample(length(x) - len, 1))
      scores = sapply(seq_len(B), function(i)
        scorefun(as.character(ssmp[[i]][start[i]+(1:len)]))
      )
      scores / len
    }
    scoresCGI    = generateRandomScores(seqCGI)
    scoresNonCGI = generateRandomScores(seqNonCGI)

    
    
    rgs = range(c(scoresCGI, scoresNonCGI))
    br = seq(rgs[1], rgs[2], length.out = 50)
    h1 = hist(scoresCGI,    breaks = br, plot = FALSE)
    h2 = hist(scoresNonCGI, breaks = br, plot = FALSE)
    plot(h1, col = rgb(0, 0, 1, 1/4), xlim = c(-0.5, 0.5), ylim=c(0,120))
    plot(h2, col = rgb(1, 0, 0, 1/4), add = TRUE)

[![](02-chap_files/figure-html/fig-ScoreMixture-1-1.png)](02-chap_files/figure-
html/fig-ScoreMixture-1-1.png "그림 2.27: generateRandomScores 함수에 의해 생성된 섬 및 비섬 점수. 이는 우리가 접하게 되는 혼합물(mixture)의 첫 번째 사례입니다. 우리는 sec-mixtures에서 이들을 다시 방문할 것입니다.")

그림 2.27: `generateRandomScores` 함수에 의해 생성된 섬 및 비섬 점수. 이는 우리가 접하게 되는 첫 번째 **혼합물(mixture)** 사례입니다. 우리는 [4장](04-chap.html)에서 이들을 다시 방문할 것입니다.

우리는 이들을 우리의 **훈련 데이터(training data)** 로 간주할 수 있습니다: 유형을 알고 있는 데이터로부터, 우리는 우리 점수가 분류(discrimination)에 유용한지 확인할 수 있습니다 – 그림 2.27을 보세요.

## 2.11 이 장의 요약

이 장에서 우리는 통계학의 기본적인 훈련(yoga)을 경험했습니다: 어떻게 데이터로부터 가능한 생성 분포로 거슬러 올라가는지, 그리고 이러한 분포를 정의하는 매개변수들을 어떻게 추정하는지를 보았습니다.

**통계 모델** 우리는 범주형 결과(이항 및 다항) 실험을 위한 몇 가지 구체적인 통계 모델들을 보여주었습니다.

**적합도** 우리는 다양한 시각화 기법을 사용하고 시뮬레이션 실험을 실행하여 우리 데이터가 공정한 4-박스 다항 모델에 적합될 수 있는지 테스트하는 방법을 보았습니다. 우리는 카이제곱 통계량을 접했고 QQ-플롯을 사용하여 시뮬레이션과 이론을 비교하는 법을 살펴보았습니다.

**추정** 최대 우도와 베이지안 추정 절차에 대해 설명했습니다. 이러한 접근 방식들은 뉴클레오타이드 패턴 발견과 일배체형 추정을 포함하는 예제들을 통해 예시되었습니다.

**사전 및 사후 분포** 일배체형과 같이 이전에 연구된 적이 있는 유형의 데이터를 평가할 때, 데이터의 사후 분포를 계산하는 것이 유익할 수 있습니다. 이는 간단한 계산을 통해 의사 결정 과정에 불확실성을 통합할 수 있게 해줍니다. 충분한 데이터가 있는 한 사전 분포의 선택은 결과에 거의 영향을 미치지 않습니다.

**CpG 섬과 마르코프 체인** 우리는 DNA 서열을 따른 의존성이 마르코프 체인 전이에 의해 어떻게 모델링될 수 있는지 보았습니다. 우리는 이를 사용하여 긴 DNA 서열이 CpG 섬으로부터 오는지 여부를 결정할 수 있게 해주는 우도 비에 기반한 점수를 구축했습니다. 우리가 점수들의 히스토그램을 만들었을 때, 그림 2.27에서 주목할 만한 특징을 보았습니다: 그것은 두 개의 조각으로 만들어진 것처럼 보였습니다. 이 **이봉성(bimodality)** 은 혼합물과의 첫 번째 만남이었으며, 이들은 [4장](04-chap.html)의 주제입니다.

이것은 일부 훈련 데이터 상에서 모델을 구축하는 첫 번째 사례입니다: 우리가 CpG 섬 내부에 있다는 것을 알고 있는 서열들은 나중에 새로운 데이터를 분류하는 데 사용될 수 있습니다. 우리는 [12장](12-chap.html)에서 이를 수행하는 훨씬 더 완전한 방법을 개발할 것입니다.

## 2.12 더 읽을거리

가장 훌륭한 기초 통계학 서적 중 하나는 Freedman, Pisani, Purves ([1997](16-chap.html#ref-Freedman:1997))입니다. 이 책은 중요한 개념들을 설명하기 위해 상자 모델을 사용합니다. 통계학 수업을 들어본 적이 없거나 복습이 필요하다고 느낀다면, 이 책을 강력히 추천합니다. 많은 기초 통계학 수업들은 이산형 데이터에 대한 통계를 심도 있게 다루지 않습니다. 이 주제는 생물학적 응용 분야에 필요한 중요한 부분입니다. 이러한 유형의 분석들에 대한 한 권으로 된 입문서는 ([Agresti 2007](16-chap.html#ref-Agresti:2007))에서 찾아볼 수 있습니다.

여기서 우리는 간단하고 구조화되지 않은 다항 분포의 예제들을 들었습니다. 하지만 때때로 다항 분포의 범주들(또는 상자들)은 특정한 구조를 가집니다. 예를 들어, 64개의 가능한 코돈은 20개의 아미노산과 종결 코돈(61+3)을 코딩합니다. 그래서 우리는 아미노산 자체를 20 자유도의 다항 분포로 볼 수 있습니다. 각 아미노산 내에는 서로 다른 수의 범주를 가진 다항 분포들이 존재합니다 (프롤린은 `CCA, CCG, CCC, CCT` 네 가지를 가집니다, 연습 문제 2.3 참조). 일부 다변량 방법들은 서로 다르게 풍부한 아미노산들 내에서의 코돈 사용 간의 가변성을 분해하기 위해 특별히 고안되었으며 ([Grantham et al. 1981](16-chap.html#ref-Grantham1981); [Perrière and Thiouluse 2002](16-chap.html#ref-Perriere2002)), 이는 수평적 유전자 전달과 번역 선택의 발견을 가능하게 합니다. 우리는 [9장](09-chap.html)에서 범주형 데이터의 다변량 탐색을 깊이 파고들 때 해당 논문들에서 사용된 구체적인 방법들을 다룰 것입니다.

불확실성을 정량화하기 위해 베이지안 패러다임을 성공적으로 사용한 많은 예시들이 있습니다. 최근 몇 년 동안 사후 분포의 계산은 마르코프 체인이나 무작위 보행(random walk), 또는 해밀턴 동역학(Hamiltonian dynamics)을 사용하는 특수한 유형의 몬테카를로 방법에 의해 혁신을 일으켰습니다. 이러한 방법들은 수차례의 반복 후에 올바른 사후 분포로 수렴하는 근사치를 제공합니다. 예제들과 더 많은 내용은 ([Robert and Casella 2009](16-chap.html#ref-Casella2009); [Marin and Robert 2007](16-chap.html#ref-Marin2007); [McElreath 2015](16-chap.html#ref-McElreath2015))를 참조하십시오.

## 2.13 연습 문제



연습 문제 2.1

1,000개의 글자 길이를 가진 유전자 서열을 따라 발생하는 돌연변이를 모델링하는 1,000개의 무작위 0/1 변수들을 생성하세요. 이들은 각각 \(10^{-4}\)의 비율로 독립적으로 발생합니다. 그런 다음 1,000개 위치의 합을 구하여 1,000 길이의 서열에 얼마나 많은 돌연변이가 있는지 계산하세요.

적합도 검정을 사용하여 이러한 돌연변이 합계에 대한 올바른 분포를 찾고 적합도의 품질을 시각화하는 플롯을 만드세요.



연습 문제 2.2

\(0\)과 \(7\) 사이에서 \(n\)개의 무작위 균등 분포 숫자를 생성하고 그중 최댓값을 반환하는 함수를 만드세요. \(n=25\)에 대해 함수를 실행하세요. 이 절차를 \(B=100\)번 반복하세요. 이러한 최댓값들의 분포를 플롯하세요.  
크기 25인 표본의 최대 우도 추정치(이를 \(\hat{\theta}\)라고 부릅시다)는 무엇인가요?  
이론적인 정당성과 실제 최댓값 \(\theta\)를 찾아낼 수 있나요?



연습 문제 2.3

유전자의 코딩 영역에서 가져온 세 개의 뉴클레오타이드 시퀀스(**코돈**)는 20가지의 가능한 아미노산 중 하나로 전사될 수 있습니다. \(4^3=64\)가지의 가능한 코돈 서열이 있지만, 아미노산은 20가지뿐입니다. 우리는 **유전 코드** 가 중복(redundant)된다고 말합니다: 각 아미노산을 _철자하는_ 방법은 여러 가지가 있습니다.

다중성(동일한 아미노산을 코딩하는 코돈의 수)은 2에서 6까지 다양합니다. 각 아미노산의 서로 다른 코돈 철자들은 동일한 확률로 발생하지 않습니다. 표준 실험실 균주인 결핵균(H37Rv)에 대한 데이터를 살펴봅시다:

    
    
    mtb = read.table("../data/M_tuberculosis.txt", header = TRUE)
    head(mtb, n = 4)
    
    
      AmAcid Codon Number PerThous
    1    Gly   GGG  25874    19.25
    2    Gly   GGA  13306     9.90
    3    Gly   GGT  25320    18.84
    4    Gly   GGC  68310    50.82

아미노산 프롤린(proline)에 대한 코돈들은 \(CC*\) 형태이며, 결핵균(Mycobacterium tuberculosis)에서 다음과 같은 빈도로 발생합니다:

    
    
    pro  =  mtb[ mtb$AmAcid == "Pro", "Number"]
    pro/sum(pro)
    
    
    [1] 0.54302025 0.10532985 0.05859765 0.29305225

  1. `table`을 사용하여 `AmAcid`와 `Codon` 변수를 집계하여 데이터 `mtb`를 탐색하세요.

  2. `PerThous` 변수는 어떻게 만들어졌나요?

  3. 가능한 철자들 사이의 균등 분포로부터의 이탈이 가장 큰, 즉 가장 강한 **코돈 편향(codon bias)** 을 보이는 아미노산이 무엇인지 찾기 위해 여러분이 표에 적용할 수 있는 R 함수를 작성하세요.

\(*\)은 정규 표현식의 컴퓨터 표기법을 사용하여 임의의 4개 글자 중 하나를 나타냅니다.



연습 문제 2.4

황색포도상구균(_Staphylococcus Aureus_) 서열을 따라 움직이는 윈도우에서 GC 함량을 표시하세요. 파일로부터 _fasta_ 파일 서열을 읽어 들입니다.

    
    
    staph = readDNAStringSet("../data/staphsequence.ffn.txt", "fasta")

  1. 전체 `staph` 객체를 살펴본 다음 세트의 처음 세 서열을 표시하세요.

  2. 너비 100의 슬라이딩 윈도우를 따라 GC 함량을 찾으세요.

  3. b)의 결과를 표시하세요.

  4. 서열을 따른 이러한 비율의 전반적인 추세를 어떻게 시각화할 수 있을까요?



해결책



  1. 데이터는 다음과 같이 표시됩니다:

    
    
    staph[1:3, ]
    
    
    DNAStringSet object of length 3:
        width seq                                               names               
    [1]  1362 ATGTCGGAAAAAGAAATTTGGGA...AAAAAGAAATAAGAAATGTATAA lcl|NC_002952.2_c...
    [2]  1134 ATGATGGAATTCACTATTAAAAG...TTTTACCAATCAGAACTTACTAA lcl|NC_002952.2_c...
    [3]   246 GTGATTATTTTGGTTCAAGAAGT...TCATTCATCAAGGTGAACAATGA lcl|NC_002952.2_c...
    
    
    staph
    
    
    DNAStringSet object of length 2650:
           width seq                                            names               
       [1]  1362 ATGTCGGAAAAAGAAATTTGGG...AAAGAAATAAGAAATGTATAA lcl|NC_002952.2_c...
       [2]  1134 ATGATGGAATTCACTATTAAAA...TTACCAATCAGAACTTACTAA lcl|NC_002952.2_c...
       [3]   246 GTGATTATTTTGGTTCAAGAAG...ATTCATCAAGGTGAACAATGA lcl|NC_002952.2_c...
       [4]  1113 ATGAAGTTAAATACACTCCAAT...CAAGGTGAAATTATAAAGTAA lcl|NC_002952.2_c...
       [5]  1932 GTGACTGCATTGTCAGATGTAA...TATGCAAACTTAGACTTCTAA lcl|NC_002952.2_c...
       ...   ... ...
    [2646]   720 ATGACTGTAGAATGGTTAGCAG...ACTCCTTTACTTGAAAAATAA lcl|NC_002952.2_c...
    [2647]  1878 GTGGTTCAAGAATATGATGTAA...CTCCAAAGGGTGAGTGACTAA lcl|NC_002952.2_c...
    [2648]  1380 ATGGATTTAGATACAATTACGA...CAATTCTGCTTAGGTAAATAG lcl|NC_002952.2_c...
    [2649]   348 TTGGAAAAAGCTTACCGAATTA...TTTAATAAAAAGATTAAGTAA lcl|NC_002952.2_c...
    [2650]   138 ATGGTAAAACGTACTTATCAAC...CGTAAAGTTTTATCTGCATAA lcl|NC_002952.2_c...

  2. `letterFrequency` 함수를 사용하여 빈도를 계산할 수 있습니다.

    
    
    letterFrequency(staph[[1]], letters = "ACGT", OR = 0)
    
    
      A   C   G   T 
    522 219 229 392 
    
    
    GCstaph = data.frame(
      ID = names(staph),
      GC = rowSums(alphabetFrequency(staph)[, 2:3] / width(staph)) * 100
    )

  3. 플로팅은 다음과 같이 수행될 수 있으며, 여기서는 예시로 364번 서열을 사용합니다 (그림 2.28):

    
    
    window = 100
    gc = rowSums( letterFrequencyInSlidingView(staph[[364]], window,
          c("G","C")))/window
    plot(x = seq(along = gc), y = gc, type = "l")

[![](02-chap_files/figure-html/fig-SlidingGC-1-1.png)](02-chap_files/figure-
html/fig-SlidingGC-1-1.png "그림 2.28: 황색포도상구균 유전체의 364번 서열을 따른 GC 함량.")

그림 2.28: 황색포도상구균 유전체의 364번 서열을 따른 GC 함량.

  4. 윈도우를 따라 `lowess` 함수를 사용하여 데이터를 평활화함으로써 전반적인 추세를 살펴볼 수 있습니다.

    
    
    plot(x = seq(along = gc), y = gc, type = "l")
    lines(lowess(x = seq(along = gc), y = gc, f = 0.2), col = 2)

[![](02-chap_files/figure-html/fig-
SmoothSlidingGC-1-1.png)](02-chap_files/figure-html/fig-SmoothSlidingGC-1-1.png "그림 2.29: 평활화가 적용된 그림 2.28과 유사한 플롯.")

그림 2.29: 평활화가 적용된 그림 2.28과 유사한 플롯.

우리는 나중에 서열을 따라 이동함에 따라 우리가 항상 여러 가능한 **상태(states)** 중 하나에 있다는 아이디어를 사용하여, 해당 윈도우가 비정상적으로 높은 GC 함량을 가지고 있는지 결정하는 적절한 방법을 보게 될 것입니다. 하지만 우리는 그 상태를 직접 관찰하지 못하고 오직 서열만을 관찰합니다. 그러한 모델들을 **은닉 (상태) 마르코프 모델(hidden (state) Markov models)** , 줄여서 HMM이라고 부릅니다 ([위키백과](http://en.wikipedia.org/wiki/Hidden_Markov_model) 참조). 이러한 모델 명칭에서의 _마르코프_ 는 이웃한 위치들 사이의 의존성을 모델링하는 방식을 뜻하며, _은닉_ 부분은 상태가 직접 관찰되지 않고 숨겨져 있음을 나타냅니다.



연습 문제 2.5

그림 2.19와 유사한 그림을 다시 그리되, 두 가지 다른 분포를 포함시키세요: 균등 분포(Beta(1,1)임)와 Beta(\\(1/2, 1/2\\))입니다. 무엇을 발견했나요?



해결책



    
    
    dfbetas = data.frame(
      p = rep(p_seq, 5),
      dbeta = c(dbeta(p_seq, 0.5, 0.5), 
                dbeta(p_seq,   1,   1), 
                dbeta(p_seq,  10,  30),
                dbeta(p_seq,  20,  60), 
                dbeta(p_seq,  50, 150)),
      pars = rep(c("Beta(0.5,0.5)", "U(0,1)=Beta(1,1)", 
                   "Beta(10,30)", "Beta(20,60)", 
                   "Beta(50,150)"), each = length(p_seq)))
    ggplot(dfbetas) +
      geom_line(aes(x = p, y = dbeta, colour = pars)) +
      theme(legend.title = element_blank()) +
      geom_vline(aes(xintercept = 0.25), colour = "#990000", linetype = "dashed")

[![](02-chap_files/figure-html/fig-histobeta4-1-1.png)](02-chap_files/figure-
html/fig-histobeta4-1-1.png "그림 2.30: 서로 다른 매개변수 선택에 대한 베타 밀도 함수.")

그림 2.30: 서로 다른 매개변수 선택에 대한 베타 밀도 함수.

매개변수가 1보다 큰 베타 분포들이 단봉형(unimodal)인 반면, Beta(0.5, 0.5) 분포는 이봉형(bimodal)이고 Beta(1, 1)은 평평하며 모드가 없습니다.



연습 문제 2.6

베타 분포의 매개변수들에 대해 여러분만의 사전 분포를 선택해 보세요. <https://jhubiostatistics.shinyapps.io/drawyourprior> 에서 직접 그려볼 수 있습니다. 사전 분포를 설정했다면, \(n=300\)번의 시행 중 \(Y=40\)번의 성공을 보았던 2.9.1절의 데이터를 다시 분석하세요. 여러분의 사후 분포를 QQ-플롯을 사용하여 해당 섹션에서 우리가 얻었던 것과 비교해 보세요.

Agresti, Alan. 2007. _An Introduction to Categorical Data Analysis_. John
Wiley.

Cannings, Chris, and Anthony WF Edwards. 1968. “Natural Selection and the de
Finetti Diagram.” _Annals of Human Genetics_ 31 (4): 421–28.

Cleveland, William S. 1988. _The Collected Works of John w. Tukey: Graphics
1965-1985_. Vol. 5. CRC Press.

Durbin, Richard, Sean Eddy, Anders Krogh, and Graeme Mitchison. 1998.
_Biological Sequence Analysis_. Cambridge University Press.

Elson, D, and E Chargaff. 1952. “On the Desoxyribonucleic Acid Content of Sea
Urchin Gametes.” _Experientia_ 8 (4): 143–45.

Finetti, Bruno de. 1926. “Considerazioni Matematiche Sull’ereditarieta
Mendeliana.” _Metron_ 6: 3–41.

Freedman, David, Robert Pisani, and Roger Purves. 1997. _Statistics_. New
York, NY: WW Norton.

Grantham, Richard, Christian Gautier, Manolo Gouy, M Jacobzone, and R Mercier.
1981. “Codon Catalog Usage Is a Genome Strategy Modulated for Gene
Expressivity.” _Nucleic Acids Research_ 9 (1): 213–13.

Irizarry, Rafael A, Hao Wu, and Andrew P Feinberg. 2009. “A Species-
Generalized Probabilistic Model-Based Definition of CpG Islands.” _Mammalian
Genome_ 20 (9-10): 674–80.

Love, Michael I, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation
of Fold Change and Dispersion for RNA-seq Data with DESeq2.” _Gnome Biology_
15 (12): 1–21.

Marin, Jean-Michel, and Christian Robert. 2007. _Bayesian Core: A Practical
Approach to Computational Bayesian Statistics_. Springer Science & Business
Media.

McElreath, Richard. 2015. _Statistical Rethinking: A Bayesian Course with
Examples in R and Stan_. Chapman; Hall/CRC.

Mourant, AE, Ada Kopec, and K Domaniewska-Sobczak. 1976. “The Distribution of
the Human Blood Groups 2nd Edition.” Oxford University Press London.

Perrière, Guy, and Jean Thiouluse. 2002. “Use and Misuse of Correspondence
Analysis in Codon Usage Studies.” _Nucleic Acids Research_ 30 (20): 4548–55.

Rice, John. 2006. _Mathematical Statistics and Data Analysis_. Cengage
Learning.

Robert, Christian, and George Casella. 2009. _Introducing Monte Carlo Methods
with R_. Springer Science & Business Media.

페이지는 R 버전 4.5.1 (2025-06-13)을 사용하여 2025-09-01 01:33에 빌드되었습니다.
## 2.9 요약

이 장에서는 데이터로부터 모델 파라미터를 추정하는 두 가지 주요 접근 방식인 **최대 우도 추정(Maximum Likelihood Estimation, MLE)**과 **베이지안(Bayesian) 추론**을 소개했습니다.

*   **MLE**: 관측된 데이터를 얻을 가능성(우도)을 최대화하는 파라미터 값을 찾습니다.
*   **베이지안 추론**: 파라미터에 대한 사전 지식(사전 분포)을 데이터(우도)와 결합하여 사후 분포를 업데이트합니다.

또한 통계적 모델링에서 **이항 분포**, **푸아송 분포** 등 다양한 확률 분포가 어떻게 사용되는지 살펴보았습니다. 이러한 기초 지식은 이후 장에서 다룰 더 복잡한 생물학적 데이터 분석의 토대가 됩니다.
