# 실험 설계 (Design of Experiments)

![](imgs/RAFisherSmoking.png)

![](imgs/dailies_icon.png)

영화 감독이 촬영된 장면이 너무 많아지기 전에 조명이나 촬영 문제를 수정하기 위해 매일 촬영분(daily takes)을 확인하는 것과 마찬가지로, 실험의 모든 실행이 완료될 때까지 기다리지 않고 데이터를 살펴보는 것이 좋습니다. 중간 데이터 분석과 시각화는 예상치 못한 변동 원인을 추적하고 프로토콜을 조정할 수 있게 해줍니다. 실험의 순차적 설계([Mead 1990](16-chap.html#ref-mead1990design))에 대해 많은 것이 알려져 있지만, 좀 더 실용적인 환경에서도 변동 원인이 발생할 때 이를 인지하고 조정하는 것이 중요합니다.

우리는 이제 많은 다양한 생물학적 데이터 세트와 데이터 유형, 그리고 이를 분석하는 방법들을 보았습니다. 이 책을 마무리하며 우리가 배운 몇 가지 일반적인 교훈을 요약해 보겠습니다. 세 가지 훌륭한 조언은 다음과 같습니다:

  * **어떻게 분석할 것인가?** 실험 설계의 아버지 중 한 명인 R.A. Fisher([Fisher 1935](16-chap.html#ref-fisher1935design))는 다음과 같이 말한 것으로 인용됩니다: _실험이 끝난 후에 통계학자를 찾는 것은 종종 그에게 사후 검사를 요청하는 것에 불과하다. 그는 아마 실험이 왜 죽었는지만 말해줄 수 있을 것이다_ 1. 따라서 분석을 염두에 두고 실험을 설계하는 것이 중요합니다. 데이터를 다 얻은 후에야 어떻게 분석할지 생각하기 시작해서는 안 됩니다.

  * **언제?** 데일리(Dailies): 첫 데이터를 얻는 즉시 분석을 시작하세요. 모든 것이 수집되어 문제를 해결하기에 너무 늦을 때까지 기다리지 마세요.

  * **무엇을?** 데이터를 분석하는 동안 논문을 쓰기 시작하세요. 글을 쓰고 결과와 결론을 제시하려고 시도할 때야 비로소 그것들을 제대로 뒷받침하기 위해 무엇을 했어야 했는지 깨닫게 됩니다.

1 1938년 제1회 인도 통계 회의 대통령 연설. Sankhya 4, 14-17.

## 13.1 이 장의 목표

이 장에서는 다음을 수행합니다:

  * 실험의 유형과 각 유형에 대해 우리가 가질 수 있는 통제 수준에 대한 간단한 분류를 개발합니다.

  * 가변성의 서로 다른 유형인 오차(error), 노이즈(noise), 편향(bias)을 구별하는 방법을 요약합니다.

  * 우리가 걱정해야 할 것들인 혼동(confounding), 의존성(dependencies), 배치 효과(batch effects)에 대해 논의합니다. 유명한 질문인 _반복 실험은 몇 번이나 필요한가?_ 에 대해 답해 봅니다.

  * 평균-분산 관계(mean-variance relationships)와 이것이 데이터 변환 여부 및 방법에 대해 어떤 정보를 주는지 핵심 아이디어를 요약합니다.

  * 계산 기법과 도구는 작업을 완료하는 데 필수적입니다. 효율적인 워크플로우 설계, 데이터 표현 및 계산에 대해 논의합니다.

  * 분석 워크플로우에서의 데이터 요약 단계와 통계적 충분성(sufficiency) 문제를 인식하려고 노력합니다. 그래야 "상류(upstream)"의 어떤 단계에서 중요한 정보를 버려 하류에서 문제를 겪는 일을 방지할 수 있습니다.

## 13.2 실험의 유형

#### "충분히 좋은" 것의 예술.

우리의 자원은 유한하고, 장비는 완벽하지 않으며, 현실 세계는 복잡하다는 사실을 다루기 위해 실험 설계가 필요합니다. 우리는 그럼에도 불구하고 가능한 최선의 결과를 얻고 싶어 합니다. 이는 필연적으로 어려운 결정과 상충 관계(trade-off)를 초래합니다. **실험 설계(Experimental design)**는 이러한 결정을 합리화하는 것을 목표로 합니다. 우리의 실험적 개입과 측정 장비는 정밀도와 정확도가 제한적입니다. 종종 우리는 처음에 이러한 한계를 알지 못하며, 이를 추정하기 위해 **예비 데이터(preliminary data)**를 수집해야 합니다. 우리는 관심 있는 현상을 직접 관찰하기보다 간접적으로만 관찰할 수 있을지도 모릅니다. 우리의 처리 조건은 피하기 어렵고 바람직하지 않은 부작용을 가질 수 있으며, 우리의 측정값에는 방해 신호나 "배경 노이즈"가 섞여 있을 수 있습니다. 표본 크기는 실무적이고 경제적인 이유로 제한됩니다. 비현실적인 이상향을 처방하는 것은 의미가 없습니다. 우리는 실용적이고 실행 가능한 선택을 해야 합니다. ([Bacher and Kendziorski 2016](16-chap.html#ref-Bacher:GB:2016))의 인용구는 이를 명확하게 설명합니다: "일반적으로 말해서, 잘 설계된 실험이란 충분한 검정력(power)을 가지고 있으며, 측정값에 체계적으로 영향을 미칠 수 있는 기술적 아티팩트와 생물학적 특징들이 균형을 이루거나 무작위화되거나 다른 방식으로 제어되어 연구 중인 효과에 대한 여러 가지 설명 가능성을 최소화하는 것입니다."

우선, 실험의 주요 유형들에 대해 논의해 봅시다. 각 유형은 서로 다른 접근 방식을 필요로 하기 때문입니다.

**통제된 실험(controlled experiment)**에서 우리는 모든 관련 변수에 대해 통제권을 가집니다: 연구 중인 (모델) 시스템, 환경 조건, 실험적 리드아웃 등입니다. 예를 들어, 정의된 배지, 온도 및 대기 상태의 실험실 조건에서 자라는 잘 특성화된 세포주를 가지고 정밀한 양의 약물을 투여한 후, 72시간 후에 특정 경로 리포터의 활성을 측정할 수 있습니다.

**연구(study)**에서 우리는 통제권이 적습니다: 측정된 결과에 영향을 줄 수 있는 중요한 조건들이 연구자의 통제 하에 있지 않으며, 대개 윤리적 우려나 물류상의 제약 때문입니다. 예를 들어, 생태학적 현장 연구에서 이는 날씨, 영양 자원의 가용성 또는 포식자의 활동일 수 있습니다. **관찰 연구(observational study)**에서는 심지어 관심 변수조차 연구자에 의해 통제되지 않습니다. 예를 들어, 임상 시험에서 이는 개별 피험자의 그룹 할당일 수 있습니다. 혼동(13.4.1절)의 가능성이 많기 때문에 관찰 연구의 해석은 어려울 수 있습니다. 여기서 "상관관계는 인과관계가 아니다"라는 오래된 격언이 적용됩니다.

**무작위 통제 시험(randomized controlled trial)**에서 우리는 여전히 결과에 영향을 미치는 많은 요인들에 대한 통제권 결여 문제를 다루어야 하지만, 관심 변수의 할당(예: 임상 시험에서의 치료 유형)을 통제하므로, 표본 크기가 충분히 크다면 모든 성가신 효과들이 상쇄되고 관찰된 효과가 진정으로 개입에 인과적으로 할당될 수 있을 것으로 기대할 수 있습니다. 이러한 시험은 대개 **전향적(prospective)** 2입니다. 즉, 피험자를 그룹에 할당할 당시에는 결과를 알지 못합니다.

2 반의어는 후향적(retrospective)입니다. 관찰 연구는 전향적일 수도 있고 후향적일 수도 있습니다.

**메타 분석(meta-analysis)**은 여러 이전 실험이나 연구에 대한 관찰 연구입니다. 메타 분석의 한 가지 동기는 유효 표본 크기를 늘려 검정력을 높이는 것입니다. 또 다른 동기는 연구자의 편향이나 다른 편향으로 고통받거나, 검정력이 부족하거나, 혹은 다른 방식으로 결함이 있거나 무작위적일 수 있는 개별 실험이나 연구의 한계를 극복하는 것입니다. 여러 연구의 결과를 합침으로써 이러한 "연구 수준"의 문제들이 상쇄되기를 기대하는 것입니다.

## 13.3 오차 분할: 편향과 노이즈

[![통계학자들은 측정값이 참값에서 벗어난 모든 편차를 오차(error)라는 용어로 부릅니다. 이는 일상적인 단어 사용과는 다릅니다. 통계학에서 오차는 피할 수 없는 삶의 한 측면입니다. 그것은 "나쁜" 것이 아니라 소중히 여기고, 계산하고, 길들이고, 통제해야 하는 것입니다.](imgs/devil.png)](imgs/devil.png "통계학자들은 측정값이 참값에서 벗어난 모든 편차를 오차(error)라는 용어로 부릅니다. 이는 일상적인 단어 사용과는 다릅니다. 통계학에서 오차는 피할 수 없는 삶의 한 측면입니다. 그것은 \"나쁜\" 것이 아니라 소중히 여기고, 계산하고, 길들이고, 통제해야 하는 것입니다.")

통계학자들은 측정값이 참값에서 벗어난 모든 편차를 **오차(error)**라는 용어로 부릅니다. 이는 일상적인 단어 사용과는 다릅니다. 통계학에서 오차는 피할 수 없는 삶의 한 측면입니다. 그것은 "나쁜" 것이 아니라 소중히 여기고, 계산하고, 길들이고, 통제해야 하는 것입니다.

우리는 크게 두 가지 유형의 오차를 구분합니다. 첫 번째는 우리가 **노이즈(noise)**라고 부르는 것으로, 충분한 반복 실험을 수행하기만 하면 "상쇄"됩니다. 두 번째는 **편향(bias)**이라고 부르는 것으로, 그대로 남아 있으며 반복 실험이 많아질수록 오히려 더 분명해집니다. [그림 12.18](12-chap.html#fig-supervised-bullseye)의 과녁을 떠올려 보세요: 아래쪽 패널에는 노이즈는 많지만 편향은 없으며, 점 구름의 중심은 정확한 위치에 있습니다. 위쪽 패널에는 노이즈는 훨씬 적지만 편향이 있습니다. 아무리 많은 반복 실험을 해도 점들의 중심이 잘못된 위치에 있다는 사실을 해결할 수는 없습니다.

편향은 노이즈보다 다루기 더 어렵습니다. 노이즈는 반복 실험을 살펴보는 것만으로도 쉽게 인식되고 더 많은 반복 실험을 분석함에 따라 상쇄됩니다. 편향의 경우, 그것이 있다는 것을 인식하는 것조차 어려울 수 있으며, 대개 어떤 정량적 모델을 사용하여 그것을 측정하고 조정할 방법을 찾아야 합니다.



질문 13.1

고처리량 데이터에서 편향을 모델링했던 이전 장의 예시 두 가지를 드세요.



해결책



예를 들어, [8장](08-chap.html)에서 우리는 감마-포아송 분포로 샘플링 노이즈를 모델링했고, 라이브러리 크기 인자로 시퀀싱 깊이 편향을 추정하여 차등 발현 검정 시 이를 고려했습니다. 또한 우리는 일반화 선형 모델에 차단 요인(blocking factor)을 도입하여 두 가지 서로 다른 프로토콜(단일말단, 쌍말단)에 의해 발생한 샘플링 편향을 모델링했습니다.

### 13.3.1 오차 모델: 노이즈는 보는 사람의 관점에 달려 있다

DNA 폴리머가 관여하는 대부분의 생화학적 또는 물리적 프로세스의 효율성은 그들의 서열 내용에 의존합니다. 예를 들어, 긴 호모폴리머(homopolymer) 구간, 팔린드롬(palindromes), 전체적 또는 국소적 GC 함량의 발생은 PCR의 효율이나 나노포어를 통해 폴리머가 당겨지는 역학을 변화시킬 수 있습니다. 이러한 효과의 크기와 특성을 모델링하는 것은 어렵습니다. 이들은 농도, 온도, 사용된 효소 등과 같은 요인들에 미묘하게 의존합니다. 그렇다면, RNA-Seq 데이터를 볼 때 GC 함량을 노이즈로 취급해야 할까요, 아니면 편향으로 취급해야 할까요?



질문 13.2

**[DESeq2](https://bioconductor.org/packages/DESeq2/)** 방법은 이 문제를 어떻게 다루나요?



해결책



**[DESeq2](https://bioconductor.org/packages/DESeq2/)**는 두 가지 옵션을 모두 제공합니다. 샘플별 샘플링 편향을 모델링하기 위해 크기 인자가 사용된다면, 이러한 효과는 명시적으로 모델링되지 않습니다.

_참고:_ 이 경우 각 유전자에 대해 그러한 편향이 모든 샘플에서 동일하게 작용하여 차등 발현 분석 목적상 상쇄될 것이라는 가정이 깔려 있습니다. 그러한 효과가 샘플별로 다른 한, 그것은 노이즈로 취급됩니다. 그러나 비네트에 설명된 대로, **[DESeq2](https://bioconductor.org/packages/DESeq2/)**는 행렬에 대해 샘플 _및_ 유전자 의존적인 정규화 인자를 지정할 수 있게 해주며, 이는 그러한 편향들에 대한 명시적인 추정치를 포함하기 위한 용도입니다.

여기서 명사 _샘플(sample)_은 관례상 카운트 행렬의 한 열, 예를 들어 한 생물학적 조건의 한 반복 실험에 해당하는 하나의 시퀀싱 라이브러리를 의미함을 기억하세요. 동일한 용어(여기서는 동사 형태인 _샘플링(sampling)_)는 "분포로부터 얻은 데이터 표본"과 같이 좀 더 일반적인 통계적 의미로도 사용됩니다. 이러한 모호함을 피할 쉬운 방법은 없으므로, 우리는 단지 이를 인지하고 있어야 합니다.

공식적인 오차 모델은 가변성을 노이즈와 편향으로 분해하는 데 도움을 줄 수 있습니다. 여러분이 접해 보았을 표준적인 분해는 ANOVA(분산 분석)라고 불립니다. 이러한 유형의 모델에서 가변성은 제곱합으로 측정되고 그 기원에 따라 할당됩니다. 예를 들어, [12장](12-chap.html)에서 선형 판별 분석(LDA)으로 지도 분류를 수행할 때, 우리는 전체 제곱합 \(C\)를 다음과 같이 계산했습니다.

\[ C_{\text{전체}} = C_{\text{그룹 내}} + C_{\text{그룹 간}}. \tag{13.1}\]

하지만 대개 그러한 분해를 하는 방법은 여러 가지가 있습니다: 한 단계에서 그룹 내 변동(노이즈)으로 간주되었던 효과가 올바른 (하위)그룹이 할당되면 그룹 간 효과로 간주될 수 있습니다.

[![아마도 이것은 "정밀 의료"의 비전과 유사할 것입니다: 치료 실패나 불필요한 치료를 포함하는 그룹 내 변동을, 모든 그룹이 정확히 필요한 것을 얻는 그룹 간 변동으로 변환하는 더 나은 환자 계층화 말이죠.](imgs/devil.png)](imgs/devil.png "아마도 이것은 \"정밀 의료\"의 비전과 유사할 것입니다: 치료 실패나 불필요한 치료를 포함하는 그룹 내 변동을, 모든 그룹이 정확히 필요한 것을 얻는 그룹 간 변동으로 변환하는 더 나은 환자 계층화 말이죠.")

아마도 이것은 "정밀 의료"의 비전과 유사할 것입니다: 치료 실패나 불필요한 치료를 포함하는 그룹 내 변동을, 모든 그룹이 정확히 필요한 것을 얻는 그룹 간 변동으로 변환하는 더 나은 환자 계층화 말이죠.

#### 결정론 대 우연.

[![](imgs/cointosser3_web.jpg)](imgs/cointosser3_web.jpg "그림 13.1: 세심하게 제작된 동전 던지기 기계는 결정론적인 동전 던지기 결과를 제공하도록 만들어질 수 있습니다.")

그림 13.1: 세심하게 제작된 동전 던지기 기계는 결정론적인 동전 던지기 결과를 제공하도록 만들어질 수 있습니다.

모두가 동전 던지기의 결과를 무작위라고 생각하며, 따라서 노이즈의 완벽한 예라고 봅니다. 하지만 우리가 동전 던지기의 초기 조건을 꼼꼼하게 기록하고 역학 방정식을 푼다면, 어느 쪽이 나올 확률이 더 높은지 예측할 수 있습니다 ([Diaconis, Holmes, and Montgomery 2007](16-chap.html#ref-Diaconis-Montgomery-Holmes-2007)).

따라서 어떤 효과나 프로세스가 무작위인지 결정론적인지 묻기보다는, _우리가_ 그것을 결정론적으로(편향으로) 모델링하고 싶은지, 아니면 세부 사항을 무시하고 확률적으로 처리하여 확률 모델링(노이즈)을 사용할 것인지 말하는 것이 더 유익합니다. 이런 의미에서 확률 모델은 우리의 무지를 정량화하고 불확실성을 길들이는 방법입니다.

#### 잠재 요인.

때때로 우리는 편향을 일으키는 요인들을 명시적으로 알고 있습니다. 예를 들어 실험의 서로 다른 단계에서 서로 다른 시약 배치가 사용된 경우입니다. 우리는 이를 **배치 효과(batch effects)**라고 부릅니다 ([Jeffrey T. Leek et al. 2010](16-chap.html#ref-Leek:2010:batch)). 다른 때에는 그러한 요인들이 작용할 것으로 예상하지만 그것들에 대한 명시적인 기록이 없을 수 있습니다. 우리는 이를 **잠재 요인(latent factors)**이라고 부릅니다. 우리는 그것들을 노이즈에 추가되는 것으로 취급할 수 있으며, [4장](04-chap.html)에서 혼합 모델을 사용하여 그렇게 하는 방법을 보았습니다. 하지만 이것만으로는 충분하지 않을 수 있습니다: 고차원 데이터에서 잠재 요인에 의해 발생하는 노이즈는 상관관계를 갖는 경향이 있으며, 이는 잘못된 추론으로 이어질 수 있습니다 ([Jeffrey T. Leek et al. 2010](16-chap.html#ref-Leek:2010:batch)). 좋은 소식은 이러한 동일한 상관관계가 데이터로부터 잠재 요인을 추정하고, 이를 편향으로 모델링하여 노이즈를 줄이는 데 활용될 수 있다는 것입니다 ([Jeffrey T. Leek and Storey 2007](16-chap.html#ref-LeekStorey:2007); [Stegle et al. 2010](16-chap.html#ref-Stegle:2010)).

### 13.3.2 생물학적 반복 대 기술적 반복



질문 13.3

체중 감량 약물이 효과가 있는지 테스트하고 싶다고 가정해 봅시다. 다음 중 어떤 연구 설계를 사용하시겠습니까?

  * 한 사람의 체중을 밀리그램 단위의 정밀 저울로 20번 반복해서 잽니다. 그는 다이어트를 따르고, 4주 후에 다시 20번 반복해서 잽니다.

  * 10명의 사람이 각자 자신의 집 저울로 한 번씩 재고 그 숫자를 보고합니다. 4주 후에 다시 재서 보고합니다.

첫 번째 옵션이 오래된 장비를 사용하는 단 10명보다 정밀한 장비로 20번의 반복을 하므로 반드시 더 나을까요?



해결책



우리가 여기서 가진 것은 **기술적 반복(technical replicates)** 대 **생물학적 반복(biological replicates)**의 차이에 대한 (노골적인) 예시입니다. 반복 실험의 횟수보다 어떤 유형의 변동이 그것들에 영향을 미치도록 허용되었는지가 더 중요합니다. 첫 번째 설계의 20번의 반복은 우리가 이미 충분히 정밀하게 알고 있는 것을 다시 측정하는 데 낭비되고 있습니다. 반면 훨씬 더 중요한 질문인 –그 효과가 다른 사람들에게 어떻게 일반화되는가– 는 비록 실제로는 더 많은 사람이 필요하겠지만 두 번째 설계에서 다루어지기 시작합니다.

_참고:_ 추론이나 일반화는 우리가 해당 모집단의 대표적이고 무작위화된 표본을 우리 연구에 가지고 있을 때만 그 모집단에 대해 이루어질 수 있습니다. 첫 번째 사례에서 체중 감량이 일어난다면, 오직 그 당시의 그 사람에 대해서만 추론할 수 있을 것입니다.

생물학적 실험에서도 유사한 질문들이 발생합니다. 예를 들어, 동일한 세포주에서 5번의 반복 실험을 하시겠습니까, 아니면 3개의 서로 다른 세포주에서 각각 한 번씩 하시겠습니까?



질문 13.4

1000 Genomes 프로젝트에서 사용된 시퀀싱 기술로 신뢰할 수 있는 변이 호출(variant calling)을 하려면 게놈당 약 \(30\times\)의 커버리지가 필요합니다. 하지만 생성된 데이터의 평균 깊이는 1,092명에 대해 5.1이었습니다 ([1000 Genomes Project Consortium 2012](16-chap.html#ref-1000Genomes)). 왜 그러한 연구 설계가 선택되었을까요?



해결책



프로젝트의 목표는 흔한 유전 변이를 찾는 것, 즉 모집단에서 유병률이 예를 들어 1% 이상인 변이를 찾는 것이었습니다. 개별 사람들의 고신뢰도 유전자형을 판독하는 것이 목표가 아니었습니다. 따라서 적은 수의 개인을 고커버리지로 샘플링하는 것보다(예: 182명을 30x로), 많은 개인을 저커버리지로 샘플링하는 것이(예: 1092명을 5x로) 더 비용 효율적이었습니다. 이런 방식으로 흔한 변이들은 1000명 중 여러 명에게 존재할 것이므로 여전히 \(>=30\)의 커버리지로 발견될 것이며(\(1092 \times 1\% \times 5 = 55\)), 더 많은 변이들이 발견되고 모집단 빈도에 대한 더 정확한 추정치를 얻을 수 있었습니다.

기술적 대 생물학적 반복이라는 용어는 어느 정도 가치가 있지만, 종종 너무 거칠습니다. 관찰된 효과는 실험실, 한 실험실 내의 다른 작업자, 기술, 동일 기술의 다른 기계, 프로토콜의 다른 변체, 계통, 새끼(litters), 성별, 개별 동물 등 여러 수준에서 일반화될 수도 있고 그렇지 않을 수도 있습니다. 복제 수준의 이름을 더 명시적으로 부르는 것이 좋습니다.

### 13.3.3 단위 대 폴드 변화

물리학에서의 측정값은 대개 미터, 킬로그램, 초와 같은 SI3 단위의 배수로 보고됩니다. 호주의 한 실험실에서 한 기구로 측정한 미터 단위의 길이는 일년 후 캐나다의 한 실험실에서 다른 기구로 측정한 길이나, 먼 은하계의 외계인 과학자가 측정한 길과 직접적으로 비교 가능합니다. 생물학에서 이만큼 표준화된 측정을 하는 것은 드물거나 실용적이지 않습니다. 여기서의 상황은 사람의 신체 부위(피트, 인치 등)가 길이 측정에 사용되고, 이러한 신체 부위의 크기가 마을이나 나라마다, 하물며 은하계마다 다른 상황과 더 비슷합니다.

3 국제 단위계 (프랑스어: Système International d’Unités)

생물학자들은 종종 측정값을 어떤 국소적이고 다소 임의적인 참조값의 배수(즉, 그것에 대한 폴드 변화)로 보고합니다. 이것의 문제는 폴드 변화와 비율이 분수라는 것입니다. 분모가 무작위 변수이므로(실험실마다, 아마도 실험마다 변하기 때문에), 이는 높은 불안정성과 실험 간의 매우 불균등한 분산을 초래할 수 있습니다. 이 장의 뒷부분에 나오는 변환과 충분성에 관한 섹션을 참조하십시오. 겉보기에 절대적인 수치가 존재하는 경우에도(예: RNA-Seq 실험의 TPKM 값), 실험 특이적인 샘플링 편향 때문에 이들은 보편적인 단위로 변환되지 않으며, 종종 정밀도에 대한 지표가 부족합니다.

### 13.3.4 규칙적인 노이즈와 치명적인 노이즈

규칙적인 노이즈는 독립적인 정규 분포, 포아송, 또는 감마-포아송이나 라플라스와 같은 혼합물과 같은 단순한 확률 모델로 모델링될 수 있습니다. 우리는 그러한 노이즈를 데이터 분석 시 고려하고 이례적으로 크거나 작은 값의 확률을 계산하기 위해 상대적으로 직관적인 방법들을 사용할 수 있습니다. 현실 세계에서는 이것이 이야기의 일부일 뿐입니다: 측정값이 범위를 완전히 벗어날 수도 있고(샘플 뒤바뀜, 오염 또는 소프트웨어 버그), 모든 것이 한꺼번에 잘못될 수도 있습니다(마이크로타이터 플레이트 전체가 잘못되어 그로부터 측정된 모든 데이터에 영향을 주는 경우). 그러한 사건들은 모델링하거나 보정하기 어렵습니다 – 그것들에 대처할 수 있는 최선의 기회는 데이터 품질 평가, 이상치 탐지 및 기록된 제거입니다.

## 13.4 실험 설계의 기본 원칙

### 13.4.1 혼동 (Confounding)

[![](13-chap_files/figure-html/fig-confounding-1-1.png)](13-chap_files/figure-
html/fig-confounding-1-1.png "그림 13.2: 질병 상태와 건강 상태 샘플 간의 (가상의) 바이오마커 비교. 왼쪽 패널에 표시된 정보만 주어진다면, 우리는 이 바이오마커가 질병을 탐지하는 데 좋은 성능을 보인다고 결론 내릴 수 있습니다. 만약 추가로 오른쪽 패널에 표시된 것과 같이 데이터가 두 개의 별도 배치(예: 다른 실험실, 다른 기계, 다른 시점)에서 획득되었다는 정보를 듣게 된다면 결론은 달라질 것입니다.")

그림 13.2: 질병 상태와 건강 상태 샘플 간의 (가상의) 바이오마커 비교. 왼쪽 패널에 표시된 정보만 주어진다면, 우리는 이 바이오마커가 질병을 탐지하는 데 좋은 성능을 보인다고 결론 내릴 수 있습니다. 만약 추가로 오른쪽 패널에 표시된 것과 같이 데이터가 두 개의 별도 배치(예: 다른 실험실, 다른 기계, 다른 시점)에서 획득되었다는 정보를 듣게 된다면 결론은 달라질 것입니다.



질문 13.5

그림 13.2에 표시된 데이터를 고려해 보세요. 바이오마커 수준에서 관찰된 차이가 질병 대 건강 때문인지, 아니면 배치 때문인지 어떻게 결정할 수 있을까요?



해결책



이 데이터로부터는 아는 것이 불가능합니다: 두 변수가 혼동되어 있기 때문입니다.

**혼동(Confounding)**은 생물학적 변수와 기술적 변수 사이에서만 일어나는 것이 아니며, 더 미묘할 수도 있습니다. 예를 들어, 바이오마커가 질병과 직접적인 관련이 없을 수도 있습니다 – 그것은 단지 질병을 유발하는(동시에 다른 것도 유발하는) 생활 방식의 마커이거나, 질병에 의해(동시에 다른 많은 것들에 의해서도) 유발되는 염증의 마커일 뿐일 수도 있습니다.

### 13.4.2 효과 크기와 반복 실험

[![](imgs/Avicenna.png)](imgs/Avicenna.png "그림 13.3: 혼동은 서기 1020년경 페르시아의 의사-과학자 아부 알리 알 후세인 이븐 시나(아비센나)가 나열한 실험 설계의 일곱 가지 규칙 중 하나가 "한 번에 질병의 한 가지 가능한 원인만을 연구하는 것"이었던 이유입니다 [@Stigler:sevenpillars].")

그림 13.3: 혼동은 서기 1020년경 페르시아의 의사-과학자 [아부 알리 알 후세인 이븐 시나(아비센나)](https://en.wikipedia.org/wiki/Avicenna)가 나열한 실험 설계의 일곱 가지 규칙 중 하나가 "한 번에 질병의 한 가지 가능한 원인만을 연구하는 것"이었던 이유입니다 ([Stigler 2016](16-chap.html#ref-Stigler:sevenpillars)).

효과 크기(Effect size)는 그림 13.4에서 빨간색 화살표로 표시된 것과 같이 그룹 중심 사이의 차이입니다. 각 그룹의 표본 크기가 클수록 각 그룹의 위치와 효과 크기를 알 수 있는 정밀도가 높아지며, 따라서 차이를 감지할 수 있는 검정력이 높아집니다 (그림 13.5). 반면에, 건강 상태와 질병 상태 사이의 개별 샘플을 구별하기 위한 진단으로서의 바이오마커의 성능은 그룹 내 분포(및 두 상태의 상대적 유병률)에 달려 있으며, 반복 실험에 의해 개선되지 않습니다.

[![](13-chap_files/figure-html/fig-effectsize-1.png)](13-chap_files/figure-
html/fig-effectsize-1.png "그림 13.4: 빨간색 화살표는 두 그룹의 중심 사이의 차이로 측정된 효과 크기를 보여줍니다. 여기서는 중앙값으로 중심을 위치시켰으며, 때때로 평균이 사용되기도 합니다.")

그림 13.4: 빨간색 화살표는 두 그룹의 중심 사이의 차이로 측정된 효과 크기를 보여줍니다. 여기서는 중앙값으로 중심을 위치시켰으며, 때때로 평균이 사용되기도 합니다.

[![](13-chap_files/figure-html/fig-
comparesamplesize-1.png)](13-chap_files/figure-
html/fig-
comparesamplesize-1.png "그림 13.5: 왼쪽의 박스플롯은 크기 6인 표본으로 생성되었습니다. 오른쪽의 표본 크기는 60입니다. 측정값은 두 경우 모두 동일한 기저 오차 분포를 가집니다.")

그림 13.5: 왼쪽의 박스플롯은 크기 6인 표본으로 생성되었습니다. 오른쪽의 표본 크기는 60입니다. 측정값은 두 경우 모두 동일한 기저 오차 분포를 가집니다.

### 13.4.3 영리한 조합: Hotelling의 가중치 예시

가용 자원으로부터 최선의 데이터를 얻으려면 상쇄와 대칭을 활용하는 것이 중요한 측면입니다. 여기에 Hotelling이 어떻게 개선된 계량 체계를 고안했는지에 대한 유명한 예시가 있습니다. 8개의 알 수 없는 무게 \(\theta = (\theta_1, ...,\theta_8)\) 세트가 주어졌다고 가정해 봅시다. 다음 코드에서는 R의 난수 생성기를 사용하여 그러한 실제 무게 세트를 시뮬레이션합니다.

    
    
    theta = round((2 * sample(8, 8) + rnorm(8)), 1)
    theta
    
    
    [1] 10.7 13.4 16.4  3.9  8.5 16.0  1.2  4.4

**방법 1** : 8번의 계량을 사용하는 나이브한 방법. 약사의 저울(그림 13.6)을 사용하여 각 무게 \(\theta_i\)를 개별적으로 재고, 오차가 표준 편차 0.1인 정규 분포를 따른다고 가정해 봅시다. 우리는 다음과 같이 오차 벡터 `errors1`과 그 제곱합을 계산합니다:

    
    
    X = theta + rnorm(length(theta), 0, 0.1)
    X
    
    
    [1] 10.513279 13.268145 16.507673  3.881881  8.395974 16.073952  1.131341
    [8]  4.289040
    
    
    errors1 = X - theta
    errors1
    
    
    [1] -0.18672051 -0.13185519  0.10767279 -0.01811869 -0.10402607  0.07395242
    [7] -0.06865871 -0.11095993
    
    
    sum(errors1^2)
    
    
    [1] 0.09748857

**방법 2** : 역시 8번의 계량을 사용하는 Hotelling의 방법. 이 방법은 아다마르(Hadamard) 행렬에 기초하며, 여기서 계산합니다.

    
    
    library("survey")
    h8 = hadamard(6)
    coef8 = 2*h8 - 1
    coef8
    
    
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
    [1,]    1    1    1    1    1    1    1    1
    [2,]    1   -1    1   -1    1   -1    1   -1
    [3,]    1    1   -1   -1    1    1   -1   -1
    [4,]    1   -1   -1    1    1   -1   -1    1
    [5,]    1    1    1    1   -1   -1   -1   -1
    [6,]    1   -1    1   -1   -1    1   -1    1
    [7,]    1    1   -1   -1   -1   -1    1    1
    [8,]    1   -1   -1    1   -1    1    1   -1

우리는 `coef8`을 새로운 계량 체계의 계수로 사용합니다: 행렬의 첫 번째 열은 모든 무게를 저울의 한쪽에 올려놓고 재라고 말해줍니다. 결과값을 `Y[1]`이라고 부릅시다. 두 번째 열은 무게 1, 3, 5, 7을 저울의 한쪽에 놓고 무게 2, 4, 6, 8을 다른 쪽에 놓으라고 말해줍니다. 그런 다음 차이를 측정하고 그 결과를 `Y[2]`라고 부릅니다. `coef8`의 모든 8개 열에 대해 이와 같이 수행합니다. 우리는 필요한 계산을 아래와 같이 행렬 곱셈 형태로 표현할 수 있습니다.

    
    
    Y = theta  %*% coef8 + rnorm(length(theta), 0, 0.1)

첫 번째 방법에서와 마찬가지로, 8개의 무게 측정값 각각은 표준 편차 0.1인 정규 오차를 가집니다.



질문 13.6

  1. `coef8`이 –전체적인 인자를 제외하고– 직교 행렬(\(C^t C = \lambda\mathbb{1}\) 어떤 \(\lambda\in\mathbb{R}\)에 대해)임을 확인하세요.

  2. 만약 우리가 `theta`에 `coef8`과 `coef8`의 전치 행렬을 곱하고 8로 나누면, 다시 `theta`를 얻게 됨을 확인하세요.



해결책



    
    
    coef8 %*% t(coef8)
    
    
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
    [1,]    8    0    0    0    0    0    0    0
    [2,]    0    8    0    0    0    0    0    0
    [3,]    0    0    8    0    0    0    0    0
    [4,]    0    0    0    8    0    0    0    0
    [5,]    0    0    0    0    8    0    0    0
    [6,]    0    0    0    0    0    8    0    0
    [7,]    0    0    0    0    0    0    8    0
    [8,]    0    0    0    0    0    0    0    8
    
    
    theta %*% coef8 %*% t(coef8) / ncol(coef8)
    
    
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
    [1,] 10.7 13.4 16.4  3.9  8.5   16  1.2  4.4

우리는 `coef8`의 직교성을 사용하여 이 결과들을 결합해 `theta`를 추정합니다.

    
    
    thetahat = Y %*% t(coef8) / ncol(coef8)

우리는 실제 \(\theta\)를 알고 있으므로 오차와 그 제곱합을 계산할 수 있습니다.

    
    
    errors2 = as.vector(thetahat) - theta
    errors2
    
    
    [1] -0.005213746  0.025216488  0.003201562  0.033880188 -0.029459127
    [6] -0.043173774  0.083202870 -0.025818188
    
    
    sum(errors2^2)
    
    
    [1] 0.01214228

우리는 여기서의 제곱합이 첫 번째 절차의 그것보다 상당히 작다는 것을 알 수 있습니다. 단지 운이 좋았던 것일까요?



질문 13.7

  1. 위 실험을 B = 10000번 반복하되, 매번 다른 `theta`를 사용하고 두 체계의 오차 제곱합의 표집 분포를 살펴보세요.

  2. 두 분산 사이의 관계가 무엇이라고 생각하시나요?



해결책



    
    
    B  = 10000
    tc = t(coef8) / ncol(coef8)
    sse = replicate(B, {
      theta = round((2 * sample(8, 8)) + rnorm(8), 1)
      X = theta + rnorm(length(theta), 0, 0.1)
      err1 = sum((X - theta)^2)
      Y = coef8 %*% theta + rnorm(length(theta), 0, 0.1)
      thetahat = tc %*% Y
      err2 = sum((thetahat - theta)^2)
      c(err1, err2)
    })
    rowMeans(sse)
    
    
    [1] 0.079591221 0.009954419
    
    
    ggplot(tibble(lr = log2(sse[1, ] / sse[2, ])), aes(x = lr)) +
      geom_histogram(bins = 50) +
      geom_vline(xintercept = log2(8), col = "orange") +
      xlab("log2 ratio of SSE, Method 1 vs 2")

[![](13-chap_files/figure-html/fig-logsseratios-1.png)](13-chap_files/figure-
html/fig-logsseratios-1.png "그림 13.7: 두 방법의 오차 제곱합 비율의 로그(밑 2). 수직 주황색 선은 8에 해당합니다.")

그림 13.7: 두 방법의 오차 제곱합 비율의 로그(밑 2). 수직 주황색 선은 8에 해당합니다.

두 번째 체계는 첫 번째보다 8배 더 **효율적(efficient)**인데, 측정에 의해 생성된 오차의 제곱합이 8배 더 낮기 때문입니다 (그림 13.7).

이 예제는 여러 수량을 확정해야 할 때, 한 실험에서 측정값들을 결합하고 유사한 그룹들 사이를 비교함으로써 정확도를 높이고 비용을 줄일 수 있는 기회가 있음을 보여줍니다.

최적의 설계는 한 번에 하나의 요인만을 변화시킬 수 있다는 이븐 시나의 규칙은 20세기에 R.A. Fisher에 의해 대체되었습니다. 그는 대비(contrasts)가 세심하게 설계되기만 한다면, 요인들을 조합하여 수정하더라도 여전히 결론에 도달할 수 있으며 –때때로 계량 예시에서처럼 훨씬 더 나은 결론을 얻을 수 있다는 것을 깨달았습니다.

[![](13-chap_files/figure-html/fig-blockbox-1.png)](13-chap_files/figure-
html/fig-blockbox-1.png "그림 13.8: 왼쪽은 각각 크기 6인 두 표본이 비교되고 있습니다. 오른쪽은 동일한 데이터가 표시되어 있지만, 데이터 수집 시간에 따라 색상이 입혀져 있습니다. 우리는 데이터가 이러한 시간에 따라 블록으로 나뉘는 경향이 있음을 주목합니다. 이 때문에 그룹 간의 비교가 희석됩니다. 이러한 효과는 시간 내에서 비교함으로써, 즉 세 개의 그룹으로 블록화함으로써 완화될 수 있습니다. 질문 13.8—13.10에서 시연된 쌍체 분석(Paired analysis)은 블록화의 특수한 사례입니다.")

그림 13.8: 왼쪽은 각각 크기 6인 두 표본이 비교되고 있습니다. 오른쪽은 동일한 데이터가 표시되어 있지만, 데이터 수집 시간에 따라 색상이 입혀져 있습니다. 우리는 데이터가 이러한 시간에 따라 블록으로 나뉘는 경향이 있음을 주목합니다. 이 때문에 그룹 간의 비교가 희석됩니다. 이러한 효과는 시간 내에서 비교함으로써, 즉 세 개의 그룹으로 블록화함으로써 완화될 수 있습니다. 질문 13.8—13.10에서 시연된 쌍체 분석(Paired analysis)은 블록화의 특수한 사례입니다.

### 13.4.4 블록화와 쌍체(Pairing)

다윈은 옥수수의 성장이 토양의 구성과 화분 내의 습도에 영향을 받는다고 의심했습니다. 이러한 이유로, 그가 타가 수분된 씨앗에서 자란 식물과 자가 수분된 씨앗에서 자란 식물을 비교하고 싶었을 때, 그는 15개의 화분 각각에 각 유형의 묘목을 하나씩 심었습니다. 다윈의 _Zea Mays_ 실험에서 각 화분은 하나의 블록이며, 각 블록 내에서 관심 요인(수분 방법), 즉 **처리(treatment)**만이 다릅니다 (그림 13.9).

[![](imgs/maizeDarwin.png)](imgs/maizeDarwin.png "그림 13.9: 쌍체 실험은 블록화의 가장 단순한 사례입니다.")

그림 13.9: 쌍체 실험은 블록화의 가장 단순한 사례입니다.

사실 R.A. Fisher는 다윈의 실험을 비판했는데, 다윈이 타가 수분된 식물들을 화분의 한쪽 면에만 체계적으로 배치했기 때문입니다. 이는 예를 들어 화분의 한쪽 면이 햇빛을 더 많이 받는 경우 "측면" 효과와 교배 효과의 혼동을 일으킬 수 있었습니다. 예를 들어 동전을 던져서 화분의 측면을 무작위화하는 것이 더 좋았을 것입니다.

_블록화할 수 있는 것은 블록화하고, 할 수 없는 것은 무작위화하라._  
(George Box, 1978)

#### 쌍체 설계와 비쌍체 설계의 비교

여러 가능한 설계를 비교할 때, 우리는 [1장](01-chap.html)에서 보았던 것과 유사한 **검정력 시뮬레이션(power simulations)**을 수행합니다. 각 그룹의 표본 크기가 15이고 **효과 크기**가 0.2라고 가정해 봅시다. 또한 측정값의 표준 편차에 대한 가정도 필요한데, 여기서는 두 그룹 모두 동일하게 sd=0.25라고 가정하고 데이터를 시뮬레이션합니다:

    
    
    n = 15
    effect = 0.2
    pots   = rnorm(n, 0, 1)
    noiseh = rnorm(n, 0, 0.25)
    noisea = rnorm(n, 0, 0.25)
    hybrid = pots + effect + noiseh
    autoz  = pots + noisea



질문 13.8

단순 \(t\)-검정과 쌍체 \(t\)-검정을 모두 수행하세요. 이 경우 어느 것이 더 강력한가요?



해결책



    
    
    t.test(hybrid, autoz, paired = FALSE)
    
    
        Welch Two Sample t-test
    
    data:  hybrid and autoz
    t = 0.77183, df = 26.012, p-value = 0.4472
    alternative hypothesis: true difference in means is not equal to 0
    95 percent confidence interval:
     -0.3145706  0.6928591
    sample estimates:
    mean of x mean of y 
    0.5073519 0.3182076 
    
    
    t.test(hybrid, autoz, paired = TRUE)
    
    
        Paired t-test
    
    data:  hybrid and autoz
    t = 1.8783, df = 14, p-value = 0.08133
    alternative hypothesis: true mean difference is not equal to 0
    95 percent confidence interval:
     -0.02683705  0.40512561
    sample estimates:
    mean difference 
          0.1891443 

아마 여기서 시뮬레이션된 데이터로만 운이 좋았던 걸까요?



질문 13.9

일반적으로 어느 방법이 더 강력한지 확인하세요. 위 계산을 \(1000\)번 반복하고, 위양성률 \(\alpha=0.05\)를 사용하여 이 1000번의 시험에 대한 평균 기각 확률을 계산하세요.



해결책



    
    
    B     = 1000
    alpha = 0.05
    what  = c(FALSE, TRUE)
    pvs = replicate(B, {
      pots   = rnorm(n, 0, 1)
      noiseh = rnorm(n, 0, 0.25)
      noisea = rnorm(n, 0, 0.25)
      hybrid = pots + effect + noiseh
      autoz  = pots + noisea
      vapply(what,
        function(paired)
          t.test(hybrid, autoz, paired = paired)$p.value,
        double(1)) |> setNames(paste(what))
    })
    rowMeans(pvs <= alpha)
    
    
    FALSE  TRUE 
    0.000 0.532 

우리는 두 방법을 사용하여 얻은 p-값들을 비교할 수 있습니다 (그림 13.10).

    
    
    tidyr::pivot_longer(as.data.frame(t(pvs)), cols = everything(), names_to = "paired") |>
      ggplot(aes(x = value, fill = paired)) +
      geom_histogram(binwidth = 0.01, boundary = 0, alpha = 1/3)

[![](13-chap_files/figure-html/fig-
pvaluescompare-1-1.png)](13-chap_files/figure-
html/fig-pvaluescompare-1-1.png "그림 13.10: 일반적인 비쌍체 t-검정과 쌍체 t-검정의 p-값 분포를 비교한 검정력 계산 결과.")

그림 13.10: 일반적인 비쌍체 \(t\)-검정과 쌍체 \(t\)-검정의 p-값 분포를 비교한 검정력 계산 결과.



질문 13.10

  * 효과 크기, 표본 크기, 화분 효과의 크기(표준 편차로 측정됨), 노이즈 표준 편차 및 표본 크기의 서로 다른 값에 대해 두 유형의 검정력을 비교하는 함수를 작성하세요.

  * 여러분의 함수를 사용하여 \(n=15\)일 때 어느 표준 편차(화분 또는 노이즈)가 쌍체에 의한 개선에 가장 큰 영향을 미치는지 찾아보세요.

  * 두 표준 편차가 모두 0.5일 때 80%의 검정력을 달성하려면 \(n\)이 얼마나 커야 할까요?



해결책



    
    
    powercomparison = function(effect = 0.2, n = 15, alpha = 0.05,
                    sdnoise, sdpots, B = 1000) {
      what = c(FALSE, TRUE)
      pvs = replicate(B, {
        pots   = rnorm(n, 0, sdpots)
        noiseh = rnorm(n, 0, sdnoise)
        noisea = rnorm(n, 0, sdnoise)
        hybrid = pots + effect + noiseh
        autoz  = pots + noisea
        vapply(what,
          function(paired)
            t.test(hybrid, autoz, paired = paired)$p.value,
          double(1)) |> setNames(paste(what))
      })
      rowMeans(pvs <= alpha)
    }

화분 효과가 노이즈 표준 편차에 비해 작을 때는 쌍체화가 거의 차이를 만들지 못함을 보여주는 몇 가지 시뮬레이션입니다. 만약 화분 효과가 크다면, 쌍체화는 큰 차이를 만듭니다.

    
    
    powercomparison(sdpots = 0.5,  sdnoise = 0.25)
    
    
    FALSE  TRUE 
    0.034 0.533 
    
    
    powercomparison(sdpots = 0.25, sdnoise = 0.25)
    
    
    FALSE  TRUE 
    0.242 0.524 
    
    
    powercomparison(sdpots = 0.1,  sdnoise = 0.25)
    
    
    FALSE  TRUE 
    0.510 0.534 

각 유형의 식물 100개와 두 표준 편차 모두 0.5일 때, 쌍체 검정의 검정력은 약 80%입니다.

    
    
    powercomparison(sdpots = 0.5, sdnoise = 0.5, n = 100)
    
    
    FALSE  TRUE 
    0.513 0.796 



질문 13.11

**쌍체 설계(Paired designs)**는 관측치의 자연스러운 쌍체 관계를 고려합니다 – 예를 들어 쌍둥이 연구, 또는 치료 전후의 환자 연구 등이 있습니다. 쌍체 관계가 없을 때는 무엇을 할 수 있을까요?



해결책



**매칭 설계(Matched designs)**는 나이, 성별, 배경 건강 상태 등을 일치시킴으로써 피험자들 사이의 유사성을 최대한으로 확보한 쌍을 만들려고 시도합니다. 하나는 치료를 받고, 다른 하나는 대조군 역할을 합니다.

**균형 설계(balanced design)**는 모든 서로 다른 요인 조합이 동일한 수의 관측 반복을 가지는 실험 설계입니다. 각 요인의 효과를 식별할 수 있습니다. 만약 성가신 요인(nuisance factors)이 있다면, 이들이 관심 요인들과 균형을 이루도록 하는 것이 좋습니다. 때때로 이것은 물류상이나 경제적인 이유로 불편하거나 비실용적일 수 있지만 – 그러한 경우 분석가는 살얼음판 위를 걷는 것과 같으므로 주의해서 진행해야 합니다.

#### 무작위화 (Randomization)

종종 우리는 어떤 성가신 요인이 중요할지 알지 못하거나, 미리 계획할 수 없습니다. 그러한 경우 무작위화는 실용적인 전략입니다: 적어도 표본 크기가 충분히 큰 한계에서는 모든 성가신 요인의 효과가 상쇄될 것으로 기대할 수 있습니다.

무작위화는 무의식적인 편향을 줄이는 데에도 도움을 줄 수 있습니다. 예를 들어, 한 그룹의 샘플을 얻기가 극도로 어렵다면, 우리는 다른 그룹의 샘플을 다룰 때보다 그 샘플들을 다룰 때 더욱 세심하게 주의를 기울이고 싶은 유혹을 느낄 수 있습니다. 불행히도 이는 측정 결과에 편향을 일으켜 비교를 무효화할 수 있습니다. 단순한 무작위화를 개선하려고 할 때 발생하는 몇 가지 함정에 대한 광범위한 논의는 Senn ([2004](16-chap.html#ref-senn2004randomization))을 참조하십시오.

### 13.4.5 반복 실험은 몇 번이나 필요한가?

[![저전력의 "나도(me-too)" 연구를 주의하세요.](imgs/devil.png)](imgs/devil.png "저전력의 \"나도(me-too)\" 연구를 주의하세요.")

저전력의 "나도(me-too)" 연구를 주의하세요.

[1.4.1절](01-chap.html#sec-generative-SimulatingForPower)에서 우리는 대안 가설을 알고 있을 때 80%의 진양성률을 달성하기 위해 얼마나 많은 뉴클레오타이드가 필요한지 계산하는 시뮬레이션 실험을 보여주었습니다. 이제 13.2절의 실험 대 연구에 관한 논의를 떠올려 봅시다. 세포주 실험의 경우, 우리는 단 한 번의 반복 실험만으로도 이미 올바른 결과를 얻을 수도 있습니다. 대개 확신을 위해 두세 번을 할 것입니다. 반면에 환자들에 대한 두 가지 대안 약물의 효과를 비교하는 연구의 경우, 우리의 직관은 결과에 대해 확신을 가질 수 있을 때까지 수십 명(혹은 그 이상)의 환자가 필요할 것임을 알려줍니다. 필요한 반복 실험의 횟수는 문맥에 따라 크게 달라집니다. 그것은 통제되지 않은 가변성의 양과 **효과 크기**에 달려 있습니다. 실용적인 접근 방식은 이전에 성공했던(또는 실패했던) 유사한 실험이나 연구를 확인하고 시뮬레이션, 서브샘플링 또는 붓스트랩을 사용하여 계획된 연구의 검정력을 추정하는 것입니다.

#### 검정력은 표본 크기, 효과 크기 및 가변성에 달려 있습니다.

[![](imgs/African_Bush_Elephant.jpg)](imgs/African_Bush_Elephant.jpg "그림 13.11: 검정력 계산에서 보이지 않는 큰 문제(elephant in the room)는 효과 크기입니다. 특히 옴익스(’omics) 연구에서 수천 개의 유전자(또는 다른 특징)에서 차이를 스크리닝할 때, 어떤 효과 크기를 기대해야 할지 정확히 알기는 어렵습니다. 하지만 그럼에도 불구하고, 검정력 계산은 자릿수 계산이나 이 섹션에서 쌍체 대 비쌍체 검정에 대해 보여준 것과 같은 정성적 비교에 유용합니다. 출처: Wikimedia CH.")

그림 13.11: 검정력 계산에서 보이지 않는 큰 문제(elephant in the room)는 효과 크기입니다. 특히 옴익스(’omics) 연구에서 수천 개의 유전자(또는 다른 특징)에서 차이를 스크리닝할 때, 어떤 효과 크기를 기대해야 할지 정확히 알기는 어렵습니다. 하지만 그럼에도 불구하고, 검정력 계산은 자릿수 계산이나 이 섹션에서 쌍체 대 비쌍체 검정에 대해 보여준 것과 같은 정성적 비교에 유용합니다. [출처: Wikimedia CH](https://en.wikipedia.org/wiki/Elephant).

**[pwr](https://cran.r-project.org/web/packages/pwr/)** 패키지는 표준 **검정력 계산(power calculations)**을 수행하는 함수들을 제공합니다. 이러한 계산에는 항상 표본 크기, 효과 크기, 유의 수준(위양성률) 및 검정력 자체(가설을 기각해야 할 때 기각할 확률, 즉 진양성률)의 네 가지 수치가 관여합니다. `pwr.2p.test`, `pwr.chisq.test`, `pwr.f2.test` 함수는 각각 두 비율의 검정, 카이제곱 검정 및 일반 선형 검정에 대한 계산을 제공합니다.

여기에 \(n=15\)일 때의 2표본 \(t\)-검정에 대한 검정력 계산 예시가 있습니다. 이 함수는 여러 인수를 필요로 합니다:

    
    
    library("pwr")
    str(pwr.t.test)
    
    
    function (n = NULL, d = NULL, sig.level = 0.05, power = NULL, type = c("two.sample", 
        "one.sample", "paired"), alternative = c("two.sided", "less", "greater"))  

만약 검정력과 효과 크기 값을 넣어 함수를 호출하면 필요한 표본 크기를 반환하고, 표본 크기와 효과 크기를 지정하면 검정력을 반환합니다.

    
    
    pwr.t.test(n = 15, d = 0.4, sig.level = 0.05, type = "two.sample")
    
    
         Two-sample t test power calculation 
    
                  n = 15
                  d = 0.4
          sig.level = 0.05
              power = 0.1848496
        alternative = two.sided
    
    NOTE: n is number in *each* group
    
    
    pwr.t.test(n = 15, d = 0.4, sig.level = 0.05, type = "paired")
    
    
         Paired t test power calculation 
    
                  n = 15
                  d = 0.4
          sig.level = 0.05
              power = 0.3031649
        alternative = two.sided
    
    NOTE: n is number of *pairs*

주어진 효과 크기를 감지하기 위해 어떤 표본 크기가 필요할지 알고 싶다면:

    
    
    pwr.t.test(d = 0.4, sig.level = 0.05, type = "two.sample", power=0.8)
    
    
         Two-sample t test power calculation 
    
                  n = 99.08032
                  d = 0.4
          sig.level = 0.05
              power = 0.8
        alternative = two.sided
    
    NOTE: n is number in *each* group
    
    
    pwr.t.test(d = 0.4, sig.level = 0.05, type = "paired", power=0.8)
    
    
         Paired t test power calculation 
    
                  n = 51.00945
                  d = 0.4
          sig.level = 0.05
              power = 0.8
        alternative = two.sided
    
    NOTE: n is number of *pairs*

우리는 쌍체 검정을 사용하지 않을 때 동일한 검정력을 얻기 위해 약 두 배 더 많은 관측치가 필요함을 알 수 있습니다.

#### 유효 표본 크기

독립적인 관측치들의 표본은 같은 수의 종속적인 관측치들보다 더 많은 정보를 줍니다. 여러분이 집마다 문을 두드려 질문을 함으로써 여론 조사를 하고 싶다고 가정해 봅시다. 첫 번째 시나리오에서는 전국적으로 무작위인 \(n\)개 장소에서 \(n\)명의 사람을 뽑습니다. 두 번째 시나리오에서는 여행 시간을 절약하기 위해 무작위인 \(n/3\)개 장소를 고르고 각 장소에서 옆집에 사는 세 사람씩 인터뷰합니다. 두 경우 모두 설문에 응한 사람 수는 \(n\)명이지만, 같은 동네에 사는 사람들은 같은 의견을 가질 가능성이 더 높다고 가정한다면, 두 번째 시나리오의 데이터는 (양(+)의) 상관관계를 갖습니다. 이를 탐구하기 위해 시뮬레이션을 해봅시다.

    
    
    doPoll = function(n = 100, numPeoplePolled = 12) {
      opinion = sort(rnorm(n))
      i1 = sample(n, numPeoplePolled)
      i2 = sample(seq(3, n, by = 3), numPeoplePolled / 3)
      i2 = c(i2, i2 - 1, i2 - 2)
      c(independent = mean(opinion[i1]), correlated = mean(opinion[i2]))
    }
    responses = replicate(5000, doPoll())
    
    tidyr::pivot_longer(as.data.frame(t(responses)), 
            cols = everything(), names_to = "design") |>
    ggplot(aes(x = value, col = design)) + geom_density() +
      geom_vline(xintercept = 0) + xlab("여론 조사 결과")

[![](13-chap_files/figure-html/fig-effective-sample-size-
sim-1-1.png)](13-chap_files/figure-
html/fig-effective-sample-size-
sim-1-1.png "그림 13.12: 두 가지 샘플링 방법을 사용한 여론 조사 결과의 밀도 추정치. 상관관계가 있는 방법이 더 큰 퍼짐을 가집니다. 참값은 수직선으로 표시됩니다.")

그림 13.12: 두 가지 샘플링 방법을 사용한 여론 조사 결과의 밀도 추정치. 상관관계가 있는 방법이 더 큰 퍼짐을 가집니다. 참값은 수직선으로 표시됩니다.

그 나라에는 100명의 사람이 있고, 첫 번째 접근 방식(`i1`)에서는 그중 12명을 무작위로 샘플링합니다. 두 번째 접근 방식에서는 4명의 사람과 각자의 이웃 두 명씩을 샘플링합니다(`i2`). 우리의 "의견"은 이 경우 실수이며, 모집단에서 평균 0, 표준 편차 1인 정규 분포를 따릅니다. 우리는 `doPoll` 함수의 첫 번째 줄에서 집들을 가장 부정적인 의견부터 가장 긍정적인 의견 순으로 정렬함으로써 나라의 공간-사회적 구조를 모델링합니다. 출력 결과는 그림 13.12에 나와 있습니다.

## 13.5 평균-분산 관계와 분산 안정화 변환

[4장](04-chap.html)과 [8장](08-chap.html)에서 우리는 정량적 측정값의 공간을 압축하거나 늘려서 측정값의 분산이 전반적으로 더 비슷해지도록 만드는 데이터 변환의 예시들을 보았습니다. 따라서 반복 측정값 사이의 분산은 더 이상 평균값에 크게 의존하지 않게 됩니다.

변환 _전_ 우리 데이터의 평균-분산 관계는 원칙적으로 어떤 함수든 될 수 있지만, 많은 경우 다음과 같은 원형적인 관계들이 적어도 대략적으로 발견됩니다:

  1. 상수(constant): 분산이 평균과 독립적임, \(v(m)=c\).

  2. 포아송(Poisson): 분산이 평균에 비례함, \(v(m)=am\).

  3. 이차(quadratic): 표준 편차가 평균에 비례함, 따라서 분산은 이차적으로 증가함, \(v(m)=bm^2\).

여기서 \(v(m)\)은 평균 \(m\)의 함수로서 분산 \(v\)의 추세를 설명하는 함수입니다. 실수 \(a, b, c\ge0\)는 평균 외에 분산에 영향을 미치는 요인들을 매개변수화합니다.



질문 13.12

이러한 유형의 평균-분산 관계를 보여주는 생물학적 어세이나 측정 기술의 예시를 드세요.

실제 데이터는 이들의 조합에 의해 영향을 받을 수도 있습니다. 예를 들어, DNA 마이크로어레이의 경우 형광 강도는 신호와 거의 독립적인 배경 노이즈와, 표준 편차가 신호에 비례하는 곱셈 노이즈(multiplicative noise)의 조합에 영향을 받습니다 ([Rocke and Durbin 2001](16-chap.html#ref-RockeDurbin:2001)). 따라서 평균-분산 관계는 \(v(m)=bm^2+c\)입니다. 밝은 점(큰 \(m\))의 경우 곱셈 노이즈(\(bm^2\))가 지배적인 반면, 희미한 점의 경우 배경 노이즈 \(c\)가 지배적입니다.



질문 13.13

분산 안정화 변환을 적용하는 요점이 무엇인가요?



해결책



변환된 스케일에서 데이터를 분석하면 다음과 같은 경향이 있습니다:

  * 시각화가 개선됩니다. 플롯의 물리적 공간이 데이터 범위 전체에서 더 "공평하게" 사용되기 때문입니다. 히트맵의 경우 색상 공간에도 유사한 논리가 적용됩니다.

  * PCA와 같은 서열화 방법이나 상관관계 기반의 군집화 결과가 개선됩니다. 결과가 소수의 매우 높게 발현된 유전자의 신호에 의해 좌우되지 않고, 동적 범위 전체의 많은 유전자로부터 더 균일하게 영향을 받기 때문입니다.

  * 동일하게 분포된(따라서 등분산적인) 노이즈를 가정하는 통계 모델로부터의 추정 및 추론이 개선됩니다.

## 13.6 데이터 품질 평가 및 품질 관리

우리는 데이터 품질 평가(Quality Assessment, QA) –품질을 측정하고 모니터링하기 위해 취해진 단계들– 와 품질 관리(Quality Control, QC) –나쁜 데이터를 제거하는 것– 을 구분합니다. 이러한 활동들은 가공되지 않은 데이터를 조립하는 것부터 변환, 요약, 모델 적합, 가설 검정 또는 "히트" 스크리닝, 해석에 이르기까지 분석의 모든 단계에 스며들어 있습니다. QA 관련 질문들은 다음과 같습니다:

  * 변수들의 주변 분포(marginal distributions)가 어떻게 보이나요 (히스토그램, ECDF 플롯)?

  * 그들의 결합 분포(joint distributions)가 어떻게 보이나요 (산점도, 페어즈 플롯)?

  * 반복 실험들이 얼마나 잘 일치하나요 (서로 다른 생물학적 조건과 비교했을 때)? 여러 조건들 사이의 차이의 크기가 타당한가요?

  * 배치 효과의 증거가 있나요? 이들은 단계적(categorical)이거나 점진적(continuous)인 성격일 수 있습니다. 예: 실험 시약, 프로토콜 또는 환경 요인의 변화 때문. 그러한 효과와 관련된 요인들은 명시적으로 알려져 있을 수도 있고, 알려지지 않은 잠재적인 것일 수도 있으며, 종종 그 중간 어디쯤일 수도 있습니다 (예: 측정 장치가 시간이 지남에 따라 천천히 성능이 저하되고, 우리는 시간을 기록했지만 정확히 어느 시점에 얼마나 나빠졌는지는 모르는 경우).

마지막 두 가지 질문 세트에 대해서는 히트맵, 주성분 분석 플롯 및 다른 서열화 플롯([7장](07-chap.html)과 [9장](09-chap.html)에서 보았던 것들)이 유용합니다.

[![](imgs/1896_Ford_Quadricycle.jpeg)](imgs/1896_Ford_Quadricycle.jpeg "그림 13.13: 헨리 포드의 (아마도 가짜일 수 있는) 인용구: "내가 사람들에게 무엇을 원하는지 물었다면, 그들은 더 빠른 말이라고 대답했을 것이다."는 사양 준수(adherence to specifications)가 아닌, 목적 적합성(fitness for purpose)으로서의 품질에 대한 관점을 표현합니다. (출처: Ford)")

그림 13.13: 헨리 포드의 (아마도 가짜일 수 있는) 인용구: "내가 사람들에게 무엇을 원하는지 물었다면, 그들은 더 빠른 말이라고 대답했을 것이다."는 사양 준수(adherence to specifications)가 아닌, **목적 적합성(fitness for purpose)**으로서의 품질에 대한 관점을 표현합니다. ([출처: Ford](https://corporate.ford.com/history.html))

**품질(Quality)**을 정의하는 것은 쉽지 않으며, 이 단어는 많은 의미로 사용됩니다. 우리에게 가장 적절한 것은 **목적 적합성(fitness for purpose)** 4이며, 이는 규범적 사양에 기초한 품질의 다른 정의들과 대조됩니다. 예를 들어, RNA-Seq 데이터를 이용한 차등 발현 분석에서 우리의 목적은 두 생물학적 조건 사이의 차등 발현 유전자를 검출하는 것일 수 있습니다. 우리는 리드 수, 리드 길이, 베이스 콜링 품질, 정렬된 리드의 비율과 같은 사양들을 확인할 수 있지만, 궁극적으로 이러한 측정값들만으로는 우리의 목적과 거의 관련이 없습니다. 더 적절한 것은 예상대로 작동하지 않는 샘플들(예: 샘플 뒤바뀜이나 분해 때문)이나, 제대로 측정되지 않은 유전자들을 식별하는 것입니다. [8.10.3절](08-chap.html#sec-countdata-dealingCooks)에서 이에 대한 예시를 보았습니다. 유용한 플롯으로는 [그림 8.6](08-chap.html#fig-countdata-PCA)과 같은 서열화 플롯과 [그림 8.7](08-chap.html#fig-figHeatmap-1)과 같은 히트맵이 있습니다. **품질 지표(quality metric)**는 품질을 측정하기 위해 사용하는 모든 수치이며, 명시적인 품질 지표를 갖는 것은 QA/QC를 자동화하는 데 도움이 됩니다.

4 <http://en.wikipedia.org/wiki/Quality_%28business%29>

## 13.7 종단적 데이터 (Longitudinal data)

**종단적 데이터(Longitudinal data)** 5는 시간을 공변량으로 가집니다. 첫 번째 질문은 우리가 소수의 시점을 보고 있는지 –예를 들어 약물 노출 후 48시간, 72시간, 96시간에 측정된 세포주의 반응– 아니면 길고 조밀하게 샘플링된 시계열을 보고 있는지 –예를 들어 전기생리학의 패치 클램프 데이터나 생세포 현미경 검사 영상– 하는 것입니다.

5 관련이 있지만 다른 개념으로 시간(time)이 결과 변수인 생존 데이터(survival data)가 있습니다.

첫 번째 경우, 시간은 대개 또 다른 이산적인 실험 요인으로 생각하는 것이 가장 좋습니다. 아마도 실험자가 어느 시점이 가장 유용한 결과를 줄지 확신하지 못했기 때문에 여러 시점이 선택되었을 것입니다. 그러면 가장 좋은 시점을 식별하고 그 시점에 집중할 수 있습니다. 데이터에 따라 다른 시점들은 어느 정도 반복 실험으로서 검증 용도로 쓰일 수 있습니다. 실험을 설계할 때, 우리는 더 많은 일이 일어날 것으로 예상되는 기간(예: 섭동 직후)을 더 조밀하게 커버하려고 노력할 것입니다.

스크리닝 문맥에서, 우리는 특정 시점이나 형태에 상관없이 효과가 전혀 있는지 여부를 \(F\)-검정 같은 것을 사용하여 물을 수 있습니다. 그런 다음 서로 다른 시점에서의 측정값들 사이의 의존성을 고려하고 그에 따라 귀무 분포를 결정하기만 하면 됩니다.

시계열 데이터가 있는 두 번째 경우, 우리는 데이터에 동적 모델(dynamical models)을 적합시키고 싶을 수 있습니다. 시간 \(t\)에서의 우리 시스템의 _상태_를 \(X(t)\)라고 쓸 수 있으며, 다음과 같은 조건에 따라 많은 선택지를 가집니다:

  * \(X\)가 연속형인지 이산형인지,

  * \(X\)의 _동역학(dynamics)_ 6이 결정론적인지 확률적인지,

  * 동역학이 매끄러운지(smooth) 그리고/또는 도약(jumpy)이 있는지,

  * 우리가 \(X\)를 직접 관찰하는지, 아니면 노이즈가 섞여 있거나 축소된 버전인 \(Y = g(X)+\varepsilon\) 7만을 관찰하는지.

6 시간 \(t\)에서의 \(X(t)\)가 주어졌을 때 \(X(t+\Delta t)\)의 값, 즉 시간적 진화

7 여기서 \(g\)는 벡터 값을 가진 \(X\)의 변수 중 일부를 버리는 등 정보를 잃는 함수를 나타내고, \(\varepsilon\)은 노이즈 항입니다.

우리는 다음과 같은 많은 모델링 도구들을 가지고 있습니다:

  * 마르코프 모델(Markov Models): 이산 상태 공간; 동역학은 확률적이며 상태 사이를 도약함으로써 발생합니다.

  * 상미분 또는 편미분 방정식: 연속 상태 공간; 동역학은 결정론적이고 매끄러우며, 물리학이나 화학에 뿌리를 둔 제1원리로부터 도출되었을 수도 있는 미분 방정식으로 설명됩니다.

  * 마스터 방정식, 포커-플랑크 방정식(Fokker-Planck equation): 동역학은 확률적이며 공간과 시간에서의 \(X\)의 확률 분포에 대한 (편)미분 방정식으로 설명됩니다.

  * 부분 결정론적 확률 과정(Piece-wise deterministic stochastic processes): 위의 것들의 조합으로, 과정의 표본은 매끄러운 결정론적 움직임뿐만 아니라 가끔씩 발생하는 도약을 포함합니다.

만약 우리가 \(X\)를 직접 관찰하지 못하고 노이즈가 섞여 있거나 요약된 버전인 \(Y\)만을 본다면, 마르코프 모델의 경우 **은닉 마르코프 모델(Hidden Markov Models)** ([Durbin et al. 1998](16-chap.html#ref-DEKM))의 형식주의를 통해 그러한 모델을 적합시키는 것이 상대적으로 간단해집니다. 다른 유형의 과정들에 대해서도 유사한 접근 방식이 가능하지만, 이들은 기술적으로 더 까다롭고 전문 문헌을 참조해야 합니다.

모델 중심적인 관점이 아닌 데이터 중심적인 관점을 취한다면, 시계열 데이터를 분석하는 방법들은 다음과 같습니다:

  * 비모수적 평활화(smoothing) 후 원형적인 형태들로의 군집화 또는 분류

  * 변화점 탐지(Change point detection)

  * 자기회귀 모델(Autoregressive models)

  * 푸리에 및 웨이블릿 분해

자세한 내용을 다루는 것은 이 책의 범위를 벗어나며, 수많은 선택지가 있습니다 8. 많은 방법들이 경제학이나 신호 처리 분야에서 유래했으므로, 해당 분야의 문헌을 훑어보는 것이 가치가 있습니다.

8 한 가지 시작점은 CRAN 태스크 뷰 <https://cran.r-project.org/web/views/TimeSeries.html>입니다.

## 13.8 데이터 통합: 알고 있는(혹은 알 수 있는) 모든 것을 활용하라

[![자신이 멍청한 척하지 마세요.](imgs/devil.png)](imgs/devil.png "자신이 멍청한 척하지 마세요.")

자신이 멍청한 척하지 마세요.

손에 쥔 데이터를 이전 지식에 대한 언급 없이 분석하려는, 겉보기에 "편향되지 않은" 접근 방식에는 매력이 있습니다. 통계적 방법들이 종종 일반적이고 자기 완비적으로 개발되어 왔다는 사실이 이러한 경향을 강화합니다. 예를 들어, 응용 분야에서 행과 열이 무엇을 의미하는지나 다른 관련 데이터가 있을 수 있는지에 대한 구체적인 언급 없이 일반적인 행렬에 대해 작동하도록 개발된 경우입니다.

일반적인 접근 방식은 시작하기에 좋은 방법이며, 분석이 간단하고 검정력이 매우 높은 경우에는 그러한 접근 방식이 효과적일 수 있습니다. 하지만 종종 그것은 낭비입니다. RNA-Seq 실험의 차등 발현 사례를 떠올려 보십시오. [6장](06-chap.html)과 [8장](08-chap.html)에서 보았듯이, 우리는 신호 강도 9나 다른 어떤 것과도 상관없이 기록된 각 유전자에 대해 가설 검정을 수행할 수 있고, 그런 다음 모든 검정을 똑같이(즉, 교환 가능한 것으로) 취급하는 다중 검정 방법을 실행할 수 있습니다. 하지만 이는 비효율적입니다: 검정력이 더 낮거나 참일 사전 확률 \(\pi_0\)가 더 높은 가설들을 필터링하거나 가중치를 낮춤으로써 우리의 검출력을 개선할 수 있습니다.

9 즉, 평균 리드 카운트.

유사하게, 개별 p-값의 해석에서도 우리가 알고 있는 다른 모든 것을 무시하고 어떤 일이 있어도 5% 컷오프를 맹목적으로 고수할 필요가 없습니다. 오히려 검정의 검정력과 \(\pi_0\)에 대한 사전 지식이 우리의 해석을 가이드하도록 할 수 있습니다 ([Altman and Krzywinski 2017](16-chap.html#ref-Altman:PoS:2017)).

잘못된 객관성의 다른 잠재적 예시는 다음과 같습니다:

  * 고차원 회귀나 분류에서의 벌점화(penalization) 또는 특징 선택. 모든 특징을 동일하게 취급하는 체계(예: 모든 특징을 평균 0, 분산 1로 표준화함)를 사용하기는 쉽습니다. 하지만 때때로 우리는 특징의 일부 클래스가 다른 것들보다 더 정보가 많을 가능성이 높다는 것을 알고 있습니다 ([Wiel et al. 2016](16-chap.html#ref-Wiel:StatMed:2016)). 또한 "다른" 데이터를 표현하기 위해 그래프나 네트워크를 사용할 수 있고, 고차원 모델링 시 페널티를 구조화하기 위해 그룹 또는 그래프 라쏘(group or graph lasso) ([Jacob, Obozinski, and Vert 2009](16-chap.html#ref-Jacob:GroupLasso:2009))와 같은 접근 방식을 사용할 수 있습니다.

  * 관심 대상(샘플, 유전자 또는 서열)의 비지도 군집화 및 후속적인 과다 표현 어노테이션 검색. 우리는 군집화 알고리즘에 그것들이 측정된 서로 다른 불확실성뿐만 아니라 서로 다른 빈도들을 통합함으로써 더 나은 결과를 얻을 수 있습니다. 우리는 확률과 유사성을 사용하여 군집의 구성원들이 무작위로 뽑은 두 대상보다 더 유사한지 확인할 수 있습니다 ([Callahan et al. 2016](16-chap.html#ref-dada2)).

분석에 착수할 때, 단일 방법을 적용하고 곧바로 결과를 얻어 끝나는 경우는 드물다는 것을 예상하는 것이 중요합니다. 우리는 다른 관련 데이터 세트들을 파헤쳐야 하고, 우리의 결과에 대한 확인(또는 반증)을 찾아야 하며, 추가적인 해석을 얻어야 합니다. 한 가지 예가 유전자 세트 농축 분석(gene set enrichment analysis)입니다: 우리의 데이터를 분석하고 관심 비교군과 관련이 있어 보이는 유전자 리스트를 찾은 후, 관여하는 광범위한 생물학적 프로세스를 탐구하기 위해 [분자 시그니처 데이터베이스](http://software.broadinstitute.org/gsea/msigdb) ([Liberzon et al. 2011](16-chap.html#ref-MSigDB))의 것과 같은 다른 유전자 리스트들과 겹쳐볼 것입니다. 또는 맥락을 찾기 위해 우리 연구의 상류 또는 하류의 조절 수준 10을 살펴보는 데이터 세트들을 불러올 수도 있습니다.

10 게놈, 염색질 상태, 전사, mRNA 수명 주기, 번역, 단백질 수명 주기, 위치 및 상호작용; 대사산물, \(...\)

## 13.9 도구 갈고닦기: 재현 가능한 연구

분석 프로젝트는 종종 몇 가지 초기 아이디어를 시도하고 파일럿 데이터의 품질을 탐색하기 위한 단순한 스크립트로 시작됩니다. 그런 다음 더 많은 아이디어가 추가되고, 더 많은 데이터가 들어오고, 다른 데이터 세트가 통합되며, 더 많은 사람들이 참여하게 됩니다. 결국 논문을 써야 하고, 그림들을 '제대로' 그려야 하며, 분석 내용은 과학적 기록과 그 무결성을 증명하기 위해 저장되어야 합니다. 여기에 그러한 과정에 도움이 될 수 있는 몇 가지 원칙들이 있습니다 11.

11 데이터 관리, 프로그래밍, 동료와의 협업, 프로젝트 조직, 작업 추적 및 원고 작성을 포함하여 연구자를 위한 좋은 컴퓨팅 실무에 대한 훌륭하고 매우 읽기 쉬운 개요가 Wilson 등 ([2017](16-chap.html#ref-Wilson:Goodenough:2017))에 의해 제시되었습니다.

**통합 개발 환경을 사용하세요.** **RStudio**는 훌륭한 선택입니다. Emacs나 Eclipse와 같은 다른 플랫폼들도 있습니다.

**리터레이트 프로그래밍(literate programming)** 도구인 **Rmarkdown**이나 Jupyter를 사용하세요. 이는 소스 코드의 주석이나 별도의 README 파일에 설명과 사용 지침을 묻어두는 것보다 (자신과 다른 사람들에게) 더 읽기 쉽습니다. 게다가 이러한 문서에 그림과 표를 직접 포함시킬 수 있습니다. 이러한 문서들은 여러분의 논문 보충 자료를 위한 좋은 시작점이 됩니다. 더욱이, 여러분의 협력자들에게 분석 내용을 보고하는 데에도 훌륭합니다.

**데이터 형식과 소프트웨어의 재설계(re-engineering)를 예상하세요.** 처음에 데이터를 표현하고 분석 워크플로우를 구조화한 방식이 프로젝트가 진화함에 따라 계속 지원할 수 있는 경우는 드뭅니다. 여러분이 어색한 데이터 조작이나 반복적인 단계들을 많이 하고 있다는 것을 알아차리는 즉시, 과감하게 12 기존의 방식을 버리고 다시 설계하는 것을 두려워하지 마세요. 이는 보람 있는 시간 투자입니다. 거의 항상 버그를 찾아내는 데에도 도움이 됩니다.

12 전문가들도 그렇게 합니다: "Google의 대부분의 소프트웨어는 몇 년마다 다시 작성됩니다." ([Henderson 2017](16-chap.html#ref-Henderson:2017:SoftwareEngineeringGoogle))

**기존 도구들을 재사용하세요.** 바퀴를 새로 발명하지 마세요. 여러분의 시간은 실제로 새로운 것들에 쓰이는 것이 더 가치가 있습니다. 직접 만든 "휴리스틱"이나 임시적인 "지름길"을 사용하기 전에, 이와 같은 것이 이전에 수행된 적이 있는지 몇 분 동안 조사해 보세요. 대개는 이미 존재하며, 때로는 깔끔하고 확장 가능하며 이미 검증된 해결책이 있습니다.

**버전 관리** 를 사용하세요. 배우는 데 시간이 걸리지만, 이 시간은 보람 있게 쓰일 것입니다. 장기적으로 볼 때 버전 번호, 스위치 등을 사용하여 코드를 관리하려는 여러분의 모든 자생적인 시도들보다 무한히 더 나을 것입니다. 더욱이 이는 코드에 대한 협력 작업을 위한 가장 건전한 옵션이며, 서버가 여러분의 개인용 컴퓨터와 별개라면 코드베이스에 대한 추가적인 백업을 제공합니다.

**함수** 를 사용하세요. 코드 구간을 복사-붙여넣기하거나 반복적으로 `source`하는 대신 함수를 사용하세요.

**R 패키지 시스템을 사용하세요.** 곧 여러분의 서로 다른 스크립트들 사이에서 공유하고 싶은 반복적인 함수나 변수 정의들을 발견하게 될 것입니다. 처음에는 관리하기 위해 R 함수 `source`를 사용하는 것도 괜찮지만, 다른 사람들(혹은 자신)에게 어떤 기능을 어떻게 사용하는지 설명하는 이메일이나 코드 주석을 쓰기 시작할 때쯤이면 –늦어도– 그것들을 여러분만의 패키지로 옮기는 것이 좋습니다. 기존 코드를 R 패키지로 조립하는 것은 어렵지 않으며, 문서화, 코드 사용 예시 제시, 코드 테스트, 버전 관리 및 타인에게 제공하는 표준화된 방법들을 제공해 줍니다. 그리고 곧 네임스페이스를 사용하는 이점을 깨닫게 될 것입니다.

**가공되지 않은 데이터 파일의 위치를 중앙화하고 중간 데이터의 유도를 자동화하세요.** 입력 데이터를 전문적으로 백업되는 중앙 파일 서버에 저장하세요. 파일들을 읽기 전용으로 표시하세요. 가공되지 않은 파일들로부터 파생된 데이터(예: 정규화, 요약, 변환 등)를 계산하기 위한 명확하고 선형적인 워크플로우를 가지고, 이들을 별도의 디렉토리에 저장하세요. 이 워크플로우가 여러 번 실행되어야 할 것임을 예상하고 13 버전을 관리하세요. **[BiocFileCache](https://bioconductor.org/packages/BiocFileCache/)** 패키지를 사용하여 이러한 파일들을 개인용 컴퓨터에 미러링하세요 14.

13 항상 최종 데이터 프리즈(freeze) 직전의 정말 마지막 순간보다 한 번 더...

14 좀 더 기초적인 대안으로 유틸리티가 있습니다. 일부 조직에서 제공하는 인기 있는 솔루션은 [ownCloud](https://owncloud.org)에 기반합니다. Dropbox, Google Drive 등과 같은 상업적 옵션들도 있습니다.

15 컴퓨터 과학에서 데이터 웨어하우스(data warehouse)라는 용어가 이러한 개념으로 사용되기도 합니다.

**요리 레시피 관점에서 생각하고 자동화하려고 노력하세요.** 서로 다른 여러 데이터 유형을 한데 모으는 하류 분석 아이디어를 개발할 때, 데이터 유형 특이적인 형식에서 기계 학습이나 일반적인 통계 방법에 적합한 표현으로의 변환을 매번 즉석에서 새로 하고 싶지는 않을 것입니다. 서로 다른 재료들을 조립하고 그것들을 쉽게 소비 가능한 15 행렬, 데이터 프레임 또는 바이오컨덕터 _SummarizedExperiment_ 로 요리해 주는 _레시피_ 스크립트를 준비하세요.

**모든 분석 내용의 인덱스가 포함된 하이퍼링크 웹페이지를 유지하세요.** 이는 협력자들에게 도움이 되며(특히 페이지와 분석 내용이 웹 브라우저를 통해 접근 가능하다면), 또한 여러분의 논문 방법론 부분의 좋은 시작점이 됩니다. 시간순이나 논리적 순서, 또는 두 가지의 조합으로 구조화하세요.

## 13.10 데이터 표현

분석이나 시각화를 위해 데이터를 준비하는 과정에는 데이터가 분석 알고리즘이나 그래픽 루틴에 적합한 형태와 형식을 갖출 때까지 많은 셔플링(shuffling)이 수반되곤 합니다. [3장](03-chap.html)에서 보았듯이, **[ggplot2](https://cran.r-project.org/web/packages/ggplot2/)**는 측정 기록당 한 행을 가진 데이터 프레임 객체를 선호합니다. 이러한 선택의 배경은 Hadley Wickham의 **타이디 데이터(tidy data)** 에 관한 논문 ([Wickham 2014](16-chap.html#ref-Wickham:TidyData))에 잘 설명되어 있습니다.

### 13.10.1 넓은 테이블 형식 대 긴 테이블 형식

Hiiragi 데이터를 떠올려 봅시다 (공간상 4개의 유전자만 선택하고, `xwdf`의 처음 5개 열만 출력합니다):

    
    
    library("magrittr")
    data("x", package = "Hiiragi2013")
    xwdf = tibble(
      probe  = c("1420085_at", "1418863_at", "1425463_at", "1416967_at"),
      symbol = c(      "Fgf4",      "Gata4",      "Gata6",       "Sox2"))
    xwdf %<>% bind_cols(as_tibble(Biobase::exprs(x)[xwdf$probe, ]))
    dim(xwdf)
    
    
    [1]   4 103
    
    
    xwdf[, 1:5]
    
    
    # A tibble: 4 × 5
      probe      symbol `1 E3.25` `2 E3.25` `3 E3.25`
      <chr>      <chr>      <dbl>     <dbl>     <dbl>
    1 1420085_at Fgf4        3.03      9.29      2.94
    2 1418863_at Gata4       4.84      5.53      4.42
    3 1425463_at Gata6       5.50      6.16      4.58
    4 1416967_at Sox2        1.73      9.70      4.16

이 데이터 프레임의 각 행은 선택된 유전자 중 하나에 해당합니다. 처음 두 열은 Affymetrix 프로브 식별자와 유전자 심볼을 포함합니다. 나머지 101개 열은 각 샘플에 대해 측정된 발현 값을 보고합니다. 샘플 식별자는 샘플을 채취한 시점에 대한 정보와 함께 열 이름에 연결된 문자열로 기록되어 있습니다. 이것이 **넓은 형식(wide format)**의 데이터 테이블 예시입니다. 이제 **[tidyr](https://cran.r-project.org/web/packages/tidyr/)** 패키지의 `pivot_longer` 함수를 호출하고 그 출력을 살펴봅시다.

    
    
    library("tidyr")
    xldf = pivot_longer(xwdf, cols = !all_of(c("probe", "symbol")),
                              names_to = "sample")
    dim(xldf)
    
    
    [1] 404   4
    
    
    head(xldf)
    
    
    # A tibble: 6 × 4
      probe      symbol sample  value
      <chr>      <chr>  <chr>   <dbl>
    1 1420085_at Fgf4   1 E3.25  3.03
    2 1420085_at Fgf4   2 E3.25  9.29
    3 1420085_at Fgf4   3 E3.25  2.94
    4 1420085_at Fgf4   4 E3.25  9.72
    5 1420085_at Fgf4   5 E3.25  8.92
    6 1420085_at Fgf4   6 E3.25 11.3 

`xldf`에서 각 행은 `value` 열에 저장된 정확히 하나의 측정값에 해당합니다. 그리고 해당 측정값과 관련된 공변량들을 저장하는 추가적인 열들인 `probe`, `symbol`, `sample`이 있습니다. 이것이 **긴 형식(long format)**의 사례입니다.

`xwdf`에서 일부 열은 모든 샘플의 데이터와 관련이 있는 반면(즉, `probe`와 `symbol`), 다른 열들(발현 측정값이 있는 열들)은 샘플 특이적인 정보를 포함하고 있습니다. 우리는 데이터 프레임을 해석할 때 이를 어떻게든 "알고" 있어야 합니다. 이것이 바로 Hadley Wickham이 **지저분한 데이터(untidy data)** 라고 부르는 것입니다 16. 이와 대조적으로, 깔끔한(tidy) 데이터 프레임 `xldf`에서는 각 행이 정확히 하나의 관측치를 형성하며, 그 값은 `value`라는 이름의 열에 있고, 그 관측치와 관련된 다른 모든 정보는 같은 행의 다른 열에 있습니다. Ensembl 유전자 식별자나 염색체 위치와 같은 추가 열을 더하고 싶다면 간단히 추가하면 됩니다. 유사하게, 더 많은 유전자나 추가 샘플의 데이터를 더하고 싶다면 간단히 `xldf`에 해당 행들을 추가하면 됩니다. 어느 쪽이든, 우리는 기존의 코드를 깨뜨리지 않을 것이라고 가정할 수 있습니다. 이는 열을 추가하는 것이 데이터 열(측정값이 있는 열)과 공변량 열 사이의 구분을 확신할 수 없게 하여 기존 코드를 무효화할 수 있는 `xwdf`와는 대조적입니다.

16 [안나 카레니나 원리를 떠올려 보세요: 데이터가 지저분해지는 방법은 수없이 많습니다.](http://en.wikipedia.org/wiki/Anna_Karenina_principle)

또한, 프로브 식별자, 유전자 심볼 또는 샘플, 그리고 사실상 다른 모든 공변량에 의한 하위 집합 추출(subsetting)이 간단하며 항상 동일한 `dplyr::filter` 구문을 사용할 수 있습니다. 이와 대조적으로 `xwdf`에서는 샘플의 하위 집합 추출은 열 추출에 해당하고, 유전자의 하위 집합 추출은 행 추출에 해당한다는 것을 기억해야 합니다.

Hiiragi 데이터는 `xwdf` 외에도 또 다른 자연스러운 넓은 형식 표현을 가집니다: 유전자당 하나의 행과 서로 다른 샘플들에 대한 열 대신, 샘플당 하나의 행과 서로 다른 유전자들에 대한 열을 가질 수도 있습니다. 이 두 가지 넓은 표현 모두 유용할 수 있습니다. 예를 들어, `ggplot2`를 사용하여 두 샘플 사이의 모든 유전자 발현 값에 대한 산점도를 그리거나, 두 유전자 사이의 모든 샘플에 대한 산점도를 그리려면 두 넓은 형식 중 하나를 사용해야 합니다.

긴 형식에서 넓은 형식(둘 중 어느 것이든)으로 변환하려면, 위에서 이미 사용했던 `pivot_longer` 함수의 보완재인 **[tidyr](https://cran.r-project.org/web/packages/tidyr/)** 패키지의 `pivot_wider` 함수를 사용할 수 있습니다.

## 13.11 타이디 데이터 – 현명하게 사용하기

타이디 데이터(tidy data) ([Wickham 2014](16-chap.html#ref-Wickham:TidyData))에서는,

  1. 각 변수는 하나의 열을 형성합니다.

  2. 각 관측치는 하나의 행을 형성합니다.

  3. 각 유형의 관측 단위는 하나의 테이블을 형성합니다.

[tidyverse](https://www.tidyverse.org)의 성공은 그 기저의 아이디어의 힘과 구현의 품질을 증명합니다. 이 책의 많은 코드가 이러한 아이디어를 채택했고 tidyverse를 사용하고 있습니다.

그럼에도 불구하고, 긴 형식의 데이터 프레임이 만병통치약은 아닙니다. 다음 사항들을 염두에 두세요:

**효율성과 무결성.** 비록 프로브-유전자 심볼 관계는 4개뿐이지만, 우리는 이를 `xldf`의 행에 404번 반복해서 저장하고 있습니다. 이 사례에서 추가적인 저장 비용은 무시할 수 있습니다. 다른 사례에서는 더 상당할 수도 있습니다. 더 중요한 것은 정보의 확산입니다: 우리가 `xldf`와 같은 객체를 받고 그것이 사용하는 모든 프로브-유전자 심볼 관계를 알고 싶을 때, 우리는 데이터 프레임 내의 수많은 복사본으로부터 이 정보를 다시 모아야 합니다. 우리는 추가적인 확인 없이 중복된 복사본들이 서로 일치한다고 확신할 수 없으며, 정보를 업데이트하고 싶다면 여러 곳을 수정해야 합니다. 이는 `xldf`와 같은 객체를 장기적인 데이터 저장용으로 사용하지 않고, 분석의 비교적 늦은 단계에서 기본 데이터 객체를 포함하는 더 정규화된 17 데이터 컨테이너로부터 조립하여 사용하는 워크플로우 설계를 옹호하는 논거가 됩니다.

17 데이터 정규화(Data normalization)는 데이터베이스를 조직하여 중복을 줄이고 무결성을 개선하는 과정입니다. 예: <https://en.wikipedia.org/wiki/Database_normalization>.

**계약과 표준화의 부재.** 우리가 `xldf`와 같은 객체에 대해 작동할 것으로 기대되는 함수를 작성할 때, 우리는 `probe` 열이 실제로 유효한 프로브 식별자를 포함하고 있는지, 심지어 그러한 열이 존재하는지조차 보장받지 못합니다. tidyverse에는 " `xldf`와 같은 객체"가 의미하는 바를 프로그래밍 방식으로 표현하는 직접적인 방법조차 없습니다. 객체 지향(OO) 프로그래밍, 그리고 R에서의 그 화신인 S4가 이러한 문제들을 해결합니다. 예를 들어, 위에서 언급한 확인 작업들은 적절하게 정의된 클래스에 대한 `validObject` 메서드에 의해 수행될 수 있으며, 클래스 정의는 " `xldf`와 같은 객체"라는 개념을 공식화할 것입니다. 이러한 이슈들을 다루는 것이 _SummarizedExperiment_ 클래스와 같은 바이오컨덕터의 데이터 구조들의 객체 지향 설계 배경입니다. OO 데이터 표현의 다른 잠재적으로 유용한 특징들은 다음과 같습니다:

  * 구현으로부터 인터페이스의 추상화 및 캡슐화: 사용자는 정의된 채널을 통해서만 데이터에 접근하고 데이터가 "내부적으로" 어떻게 저장되는지 볼 필요가 없습니다 – 이는 사용자 수준의 코드를 깨뜨리지 않고 내부를 변경하고 최적화할 수 있음을 의미합니다.

  * 다형성(Polymorphism): 서로 다른 클래스의 객체들에 대해 `plot`이나 `filter`와 같이 동일한 이름을 가진 서로 다른 함수들을 가질 수 있으며, R이 여러분을 위해 어느 것을 호출할지 결정해 줍니다.

  * 상속(Inheritance): 단순한 것으로부터 더 복잡한 데이터 표현을 구축할 수 있습니다.

  * 성찰(Reflection) 및 자기 문서화: 객체에 프로그래밍 방식의 쿼리를 보내 자기 자신에 대한 정보를 물어볼 수 있습니다.

이 모든 것들은 비록 인프라와 "관료주의"에 대한 초기 투자가 더 많이 필요하긴 하지만, 구성 요소들의 구현 세부 사항보다는 큰 그림의 기능에 집중하는 고수준 코드를 작성하는 것을 더 쉽게 만들어 줍니다.

**데이터 출처 및 메타데이터.** `xldf`와 같은 객체에는 데이터 출처에 대한 정보, 예를 들어 누가 실험을 수행했는지, 어디에 발표되었는지, 어디서 데이터를 다운로드했는지 또는 우리가 보고 있는 데이터의 버전이 무엇인지(데이터 버그는 존재하니까요...)를 추가할 명백한 장소가 없습니다. 또한 단위나 어세이 유형과 같은 열에 대한 설명도 없습니다. 다시 말하지만, 바이오컨덕터의 데이터 클래스들이 이러한 요구를 해결하려고 시도합니다.

[![](imgs/leakypipeline.png)](imgs/leakypipeline.png "그림 13.14: 순차적인 데이터 분석 워크플로우는 샐 수 있습니다. 만약 한 단계에서 다음 단계로 충분한 정보가 전달되지 않는다면, 절차는 결국 최적화되지 못하고 검정력을 잃게 될 수 있습니다.")

그림 13.14: 순차적인 데이터 분석 워크플로우는 샐 수 있습니다. 만약 한 단계에서 다음 단계로 충분한 정보가 전달되지 않는다면, 절차는 결국 최적화되지 못하고 검정력을 잃게 될 수 있습니다.

**행렬 형태의 데이터.** 생물학의 많은 데이터 세트는 자연스러운 행렬 구조를 가집니다. 다수의 특성(예: 유전자; 관례상 행렬의 행)이 여러 샘플(관례상 행렬의 열)에서 분석되기 때문입니다. 행렬을 `xldf`와 같은 긴 형태로 풀어헤치는 것은 일부 연산(예: PCA, SVD, 특성 또는 샘플의 군집화)을 더 번거롭게 만듭니다.

## 13.12 새는 파이프라인과 통계적 충분성

고처리량 생물학에서의 데이터 분석 파이프라인은 종종 데이터를 순차적으로 요약하고 압축하는 '깔때기'처럼 작동합니다. 고처리량 시퀀싱에서 우리는 플로우 셀의 현미경 이미지로 시작하여, 베이스 콜링(base calling)을 수행하여 시퀀싱 리드를 도출하고, 이를 참조 서열에 정렬한 다음, 정렬된 리드만을 각 위치별로 세고, 위치들을 유전자(또는 다른 종류의 영역)별로 요약하고, 이 수치들을 라이브러리 크기에 따라 "정규화"하여 라이브러리 간에 비교 가능하게 만드는 식입니다. 각 단계에서 우리는 정보를 잃게 되지만, 당면한 과제에 대해 여전히 충분한 정보를 가지고 있는지 확인하는 것이 중요합니다 18. 이 문제는 우리가 파이프라인을 각기 다른 개발자들이 만든 일련의 구성 요소들로 구축할 때 특히 심각해집니다.

18 예를 들어, [8장](08-chap.html)에서 보았던 RNA-Seq 차등 발현 분석을 위해서는 "정규화된" 버전이 아닌 실제 리드 카운트가 필요했습니다. 어떤 분석에는 유전자 수준의 요약으로 충분할 수 있지만, 다른 분석에서는 엑손이나 이소형 수준을 살펴보고 싶을 것입니다.

통계학자들은 특정 요약 정보가 데이터의 모든 관련 정보를 재구성할 수 있게 해주는지에 대한 개념을 가지고 있습니다: **충분성(sufficiency)**. 시행 횟수 \(n\)이 알려진 베르누이 무작위 실험에서, 성공 횟수는 성공 확률 \(p\)를 추정하기 위한 충분 통계량입니다.



질문 13.14

13장에서 보았던 것과 같은 4개 상태(A, C, G, T) 마르코프 체인에서, 전이 확률을 추정하기 위한 충분 통계량은 무엇인가요?

EM 알고리즘을 사용했을 때와 유사한 반복적인 접근 방식은 때때로 정보 손실을 피하는 데 도움이 될 수 있습니다. 예를 들어, 질량 분석 데이터를 분석할 때, 첫 번째 실행은 각 샘플에 대해 개별적으로 피크를 추측합니다. 이러한 예비적인 스펙트럼 포착 후, 다른 반복 단계를 통해 다른 샘플들로부터 힘을 빌려 이전에 간과되었던(노이즈처럼 보였던) 스펙트럼을 포착할 수 있게 됩니다.

## 13.13 효율적인 계산

데이터 획득 기술의 빠른 발전은 점점 더 거대한 데이터 세트로 이어지며, 이를 다루는 것은 하나의 도전 과제입니다. 빅데이터와 확장성을 위해 설계된 소프트웨어 기술로 곧장 뛰어들고 싶은 유혹이 생깁니다. 하지만 대개는 먼저 한 걸음 물러나서 생각하는 것이 더 도움이 됩니다. 소프트웨어 엔지니어들은 **조기 최적화(premature optimization)** 의 위험성을 알고 있습니다. 혹은 John Tukey의 말을 빌리자면 19: "올바른 문제에 대한 느리고 서툰 해결책이 잘못된 문제에 대한 빠르고 확장 가능한 해결책보다 훨씬 더 가치 있다." 때로는 확장성과 성능을 추구하기 전에 데이터의 하위 집합에서 올바른 해결책이 무엇인지 먼저 알아내는 것이 좋은 전략입니다.

19 <http://stats.stackexchange.com/a/744>

또한 CPU 시간보다는 여러분 자신의 시간의 가치를 염두에 두는 것이 좋습니다. 긴 계산 시간을 대가로 코드 개발 시간을 절약할 수 있다면, 그것은 가치 있는 상충 관계일 수 있습니다.

이 모든 것을 고려한 후, 성능에 대해 이야기해 봅시다. R은 속도가 느리고 메모리를 낭비한다는 평판이 있으며, 그러한 인식이 다른 플랫폼을 선택하는 동기로 언급되기도 합니다. 어떤 경우에는 이것이 정당화됩니다: 아무도 단일 리드 정렬기(short read aligner)나 자율 주행차의 조종 로직을 R로 작성하라고 권하지 않을 것입니다. 그러나 통계 분석의 경우, 다음 중 하나 이상의 개념을 사용하여 매우 효율적인 코드를 작성하는 것이 가능합니다:

**벡터화(Vectorization).** 동일한 결과를 계산하는 다음의 대안적인 선택지들을 고려해 보세요.

    
    
    a = runif(1e6)
    b = runif(length(a))
    system.time({
      z1 = numeric(length(a))
      for (i in seq(along = a))
        z1[i] = a[i]^2 * b[i]
    })
    
    
       user  system elapsed 
      0.076   0.001   0.076 
    
    
    system.time({
      z2 = a^2 * b
    })
    
    
       user  system elapsed 
      0.003   0.000   0.003 
    
    
    identical(z1, z2)
    
    
    [1] TRUE

벡터화된 버전(`z2`)은 명시적으로 인덱싱된 버전(`z1`)보다 여러 배 빠르며 읽기도 더 쉽습니다. 때로는 인덱스를 사용하여 공식화된 알고리즘을 번역하는 것이 조금 더 어려울 때가 있습니다 – 예를 들어 `if` 조건문이 있거나, 인덱스 `i`에 대한 계산이 인덱스 `i-1`의 결과를 포함하는 경우입니다. `ifelse`를 사용한 벡터화된 조건문, **[dplyr](https://cran.r-project.org/web/packages/dplyr/)** 패키지의 `lead`나 `lag`와 같은 함수를 사용한 벡터 이동, 그리고 일반적으로 (행 단위가 아닌) 데이터 프레임 전체에 대한 계산을 표현하도록 설계된 **[dplyr](https://cran.r-project.org/web/packages/dplyr/)** 의 인프라가 도움이 될 수 있습니다.

**병렬화(Parallelization).** R로 계산을 병렬화하는 것은 쉽습니다. 특히 R이 명시적인 입력과 출력을 가지고 부작용(side effects)이 없는 함수로 계산을 표현하는 것이 자연스러운 함수형 언어이기 때문입니다. 병렬 계산을 지원하는 R 패키지와 기능의 지형은 빠르게 변하고 있습니다. [CRAN 태스크 뷰 "고성능 및 병렬 컴퓨팅(High-Performance and Parallel Computing)"](https://cran.r-project.org/web/views/HighPerformanceComputing.html)과 **[BiocParallel](https://bioconductor.org/packages/BiocParallel/)** 패키지가 좋은 시작점입니다.

**메모리 부족 데이터 및 청킹(chunking).** 일부 데이터 세트는 랜덤 액세스 메모리(RAM)에 한꺼번에 올리고 조작하기에는 너무 큽니다. 청킹(Chunking)은 데이터를 관리 가능한 부분("청크")으로 나누고, 보조 저장 장치로부터 각 부분을 순차적으로 로드하여 계산하고 결과를 저장한 후, 다음 부분을 로드하기 전에 RAM에서 제거하는 것을 의미합니다. R은 또한 관계형 데이터베이스 관리 시스템(**[DBI](https://cran.r-project.org/web/packages/DBI/)** 패키지)이나 [HDF5](https://support.hdfgroup.org/HDF5)(**[rhdf5](https://bioconductor.org/packages/rhdf5/)** 패키지)에 저장된 대규모 데이터 세트로 작업하기 위한 인프라를 제공합니다. 바이오컨덕터 프로젝트는 _SummarizedExperiment_ 클래스를 제공하는데, 이는 이 클래스의 사용자에게 투명한 방식으로 대규모 데이터 행렬을 RAM이나 HDF5 백엔드에 저장할 수 있습니다.

**저수준 언어의 적절한 사용.** **[Rcpp](https://cran.r-project.org/web/packages/Rcpp/)** 패키지는 코드의 일부를 C++로 작성하고 이를 R 코드 내에 매끄럽게 포함시키는 것을 쉽게 만들어 줍니다. R 클래스인 _numeric_ 벡터를 감싸는 C++ 클래스 `NumericVector`와 같이 편리한 래퍼들이 많이 제공됩니다.

    
    
    library("Rcpp")
    cppFunction(" 
      NumericVector myfun(NumericVector x, NumericVector y) {
        int n = x.size();
        NumericVector out(n);
        for(int i = 0; i < n; ++i) {
          out[i] = pow(x[i], 2) * y[i];
        }
        return out;
      }")
    z3 = myfun(a, b)
    identical(z1, z3)
    
    
    [1] TRUE

실제로 위의 코드에는 `y`의 길이를 확인하는 절차도 포함되어야 할 것입니다. 여기서 우리는 C++ 코드를 R 문자 벡터로 **[Rcpp](https://cran.r-project.org/web/packages/Rcpp/)**에 제공했는데, 이는 짧은 삽입 구문에 편리합니다. 더 큰 함수의 경우, C++ 코드를 별도의 파일에 저장할 수 있습니다. 물론 아이디어는 모든 코드를 C++로 작성하는 것이 아니라, 가장 시간이 많이 걸리는 부분만을 작성하는 것입니다.

## 13.14 이 장의 요약

이 마지막 장에서 우리는 책 전반에 걸쳐 나타났던 몇 가지 개념과 아이디어들을 수집하고, 일반화하고, 분류하려고 노력했습니다. 이들은 여러분이 정보가 풍부한 실험이나 연구를 설계하고 이를 효과적으로 분석하는 데 도움을 줄 수 있습니다. 이러한 아이디어 중 일부는 직관적이고 자연스럽습니다. 13.4.3절의 Hotelling의 가중치 예시와 같이 덜 직관적인 아이디어들도 있습니다. 이는 공식적인 수학적 추론을 필요로 합니다. 분석적인 계산을 할 수 없는 경우라도, 서로 다른 비자명한 설계 선택지들을 벤치마킹하기 위해 시뮬레이션을 하거나 기존의 유사한 데이터를 가지고 계산해 볼 수 있을 것입니다.

또한 어떤 아이디어들은 훈련과 선견지명을 필요로 합니다: 예를 들어, "데일리(dailies)"는 시간과 주의를 끄는 다른 많은 우려사항들과 경쟁하는 실험 캠페인의 열기 속에서 쉽게 잊히거나 합리화될 수 있습니다. 개별적인 상황에서 주방을 깔끔하게 유지하거나 건강하게 먹는 것을 건너뛰고 넘어갈 수도 있겠지만 – 일반적인 접근 방식으로는 권장되지 않습니다.

우리는 계산 실무의 중요성을 강조했습니다. 책 전체에 걸쳐 수많은 코드가 섞여 있고 거의 모든 데이터 시각화가 "라이브"로 이루어지는 과정을 통해, 우리는 계산 분석을 설정하는 많은 예시들을 보았습니다. 그럼에도 불구하고, 여러분 자신의 데이터로 직접 분석을 실행하는 것은 책의 계산 과정을 따라가는 것과는 매우 다릅니다 – 마치 요리책을 읽는 것이 연회를 준비하거나 심지어 단 한 가지 요리를 만드는 것과 매우 다른 것처럼 말이죠. 여러분을 더욱 무장시키기 위해, 13.15절에 언급된 리소스들을 강력히 추천합니다. 그리고 여러분의 즐거운 요리를 기원합니다!

## 13.15 더 읽을거리

  * 이 장은 _실험 설계_에 대한 실용적이고 간략한 소개만을 제시했습니다. 혼동을 피하고 검정력을 최적화하기 위해 실험을 설정하는 것에 대한 상세한 조언을 제공하는 수많은 교재들이 있습니다 ([Wu and Hamada 2011](16-chap.html#ref-wu2011experiments); [Box, Hunter, and Hunter 1978](16-chap.html#ref-box1978statistics); [Glass 2007](16-chap.html#ref-glass2007experimental)).

  * 우리는 더 정교한 절차들의 겉핥기조차 하지 못했습니다. 예를 들어 결정을 내릴 수 있게 되면 바로 중단할 수 있는 일련의 실험들을 설정할 가능성이 있다면, **순차적 설계(sequential design)** 를 공부해야 할 것입니다 ([Lai 2001](16-chap.html#ref-Lai:2001)). "좋은" 시작점을 선택하고 연속적인 결과를 사용하여 다음 지점들을 선택함으로써 복잡한 반응 표면(response surfaces)을 탐색하는 것은 매우 효과적일 수 있습니다. Box, Draper 등 ([1987](16-chap.html#ref-Box:1987))은 매우 소중한 리소스입니다.

  * Gentleman 등 ([2004](16-chap.html#ref-Bioconductor))은 바이오컨덕터의 데이터 구조와 소프트웨어 설계 이면의 아이디어를 설명하며, Huber 등 ([2015](16-chap.html#ref-Huber:2015))은 바이오컨덕터가 사용자 및 개발자를 위해 협력적 소프트웨어 개발을 어떻게 지원하는지에 대한 업데이트를 제공합니다.

  * **Git 및 GitHub.** Jenny Bryan의 웹사이트 [Happy Git and GitHub for the useR](http://happygitwithr.com)은 R과 함께 버전 관리를 사용하는 것에 대한 훌륭한 입문서입니다.

  * Wickham ([2014](16-chap.html#ref-Wickham:TidyData))은 **타이디 데이터** 의 원칙을 설명합니다.

  * **충분히 좋은 실무(Good enough practices).** Wilson 등 ([2017](16-chap.html#ref-Wilson:Goodenough:2017))은 과학적 계산에서 성공하기 위한 실용적이고 현명한 권장 사항들을 제시합니다.

  * 매뉴얼 [Writing R Extensions](https://cran.r-project.org/doc/manuals/r-release/R-exts.html)은 **R 패키지 제작** 을 위한 궁극적인 참고서입니다. 이는 바이오컨덕터의 [패키지 가이드라인](https://www.bioconductor.org/developers/package-guidelines)과 함께 읽는 것이 좋습니다.

## 13.16 연습 문제



연습 문제 13.1

여러분의 측정값이 대칭 라플라스 분포([4장](04-chap.html)에서 정의된 정규 분포의 무한 혼합)를 따르는 노이즈에 영향을 받을 것임을 알고 있을 때, 얼마나 많은 피험자가 필요한지 결정하기 위한 시뮬레이션 실험을 설정하세요. 서로 다른 가능한 노이즈 수준과 효과 크기가 포함된 테이블을 설정해야 할 것입니다.



연습 문제 13.2

바이오컨덕터 패키지 **[PROPER](https://bioconductor.org/packages/PROPER/)**를 사용하여 RNA-Seq 실험을 위한 샘플 수를 결정하고, 그 결과를 **[RNASeqPower](https://bioconductor.org/packages/RNASeqPower/)** 바이오컨덕터 패키지의 결과와 비교해 보세요.



연습 문제 13.3

R의 `model.matrix` 함수를 확인해 보세요. 매뉴얼 페이지를 읽고 거기 제공된 예제들을 탐색해 보세요.



연습 문제 13.4

여러분의 최근 데이터 분석 중 하나로 돌아가서 이를 R 패키지로 조립해 보세요.



해결책



  * 하나 이상의 반복적인 작업(예: 플롯)을 함수로 모으고 매뉴얼 페이지를 작성하세요 (**[roxygen2](https://cran.r-project.org/web/packages/roxygen2/)**를 사용할 수 있습니다).

  * `data` 또는 `inst/extdata` 디렉토리 아래에 데이터 세트를 추가하세요.

  * 이미 해당 형식이 아니라면, 여러분의 분석 스크립트를 Rmarkdown으로 변환하세요.

  * 모든 오류와 경고가 사라질 때까지 `R CMD build`와 `R CMD check`를 실행하세요.

간단한 소개가 여기에 있습니다: <https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch>. 더 자세한 내용은 모든 R 설치 시 함께 제공되는 매뉴얼 [Writing R Extensions](https://cran.r-project.org/doc/manuals/r-release/R-exts.html)에 있습니다.



연습 문제 13.5

GitHub 계정을 열고 여러분의 패키지를 업로드하세요. 힌트: Jenny Bryan의 [Happy Git and GitHub for the useR](http://happygitwithr.com) 사이트의 지침을 따르세요.



연습 문제 13.6

_renjin_ 프로젝트와 **renjin** 패키지를 확인해 보세요. `renjin`으로 컴파일된 코드와 순수 R 코드, 그리고 위에서와 같이 **[Rcpp](https://cran.r-project.org/web/packages/Rcpp/)**를 사용하여 C/C++로 번역된 코드를 비교해 보세요.



해결책



다음 Gist를 참조하세요: <https://gist.github.com/wolfganghuber/909e14e45af6888eec384b82682b3766>.

1000 Genomes Project Consortium. 2012. “An Integrated Map of Genetic Variation
from 1,092 Human Genomes.” _Nature_ 491 (7422): 56–65.

Altman, Naomi, and Martin Krzywinski. 2017. “Points of Significance:
Interpreting p Values.” _Nature Methods_ 14 (3): 213–14.
<https://doi.org/10.1038/nmeth.4210>.

Bacher, Rhonda, and Christina Kendziorski. 2016. “Design and Computational
Analysis of Single-Cell RNA-Sequencing Experiments.” _Genome Biology_ 17 (1):
1.

Box, George EP, Norman Richard Draper, et al. 1987. _Empirical Model-Building
and Response Surfaces_. Vol. 424. Wiley New York.

Box, George EP, William G Hunter, and J Stuart Hunter. 1978. _Statistics for
Experimenters: An Introduction to Design, Data Analysis, and Model Building_.
John Wiley & Sons.

Callahan, Benjamin J, Paul J McMurdie, Michael J Rosen, Andrew W Han, Amy J
Johnson, and Susan P Holmes. 2016. “DADA2: High Resolution Sample Inference
from Amplicon Data.” _Nature Methods_ , 1–4.

Diaconis, Persi, Susan Holmes, and Richard Montgomery. 2007. “Dynamical Bias
in the Coin Toss.” _SIAM Review_ 49 (2): 211–35.

Durbin, Richard, Sean Eddy, Anders Krogh, and Graeme Mitchison. 1998.
_Biological Sequence Analysis_. Cambridge University Press.

Fisher, Ronald Aylmer. 1935. _The Design of Experiments_. Oliver & Boyd.

Gentleman, Robert C, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel
Dettling, Sandrine Dudoit, Byron Ellis, et al. 2004. “Bioconductor: Open
Software Development for Computational Biology and Bioinformatics.” _Genome
Biology_ 5 (10): R80. <https://doi.org/10.1186/gb-2004-5-10-r80>.

Glass, David J. 2007. _Experimental Design for Biologists_. Cold Spring Harbor
Laboratory Press.

Henderson, Fergus. 2017. “Software Engineering at Google.” _ArXiv e-Prints_.
<https://arxiv.org/abs/1702.01715>.

Hotelling, Harold. 1944. “Some Improvements in Weighing and Other Experimental
Techniques.” _The Annals of Mathematical Statistics_ 15 (3): 297–306.

Huber, Wolfgang, Vincent J Carey, Robert Gentleman, Simon Anders, Marc
Carlson, Benilton S Carvalho, Hector Corrada Bravo, et al. 2015.
“Orchestrating High-Throughput Genomic Analysis with Bioconductor.” _Nature
Methods_ 12 (2): 115–21.

Jacob, Laurent, Guillaume Obozinski, and Jean-Philippe Vert. 2009. “Group
Lasso with Overlap and Graph Lasso.” In _Proceedings of the 26th Annual
International Conference on Machine Learning_ , 433–40. ACM.

Page built at 01:33 on 2025-09-01 using R version 4.5.1 (2025-06-13)