{"title":"8.1 Goals of this chapter","markdown":{"headingText":"8.1 Goals of this chapter","containsRefs":false,"markdown":"![](imgs/xkcd-1725-linear_regression_2x.png)\n\nMany measurement devices in biotechnology are based on massively parallel\nsampling and counting of molecules. One example is high-throughput DNA\nsequencing. Its applications fall broadly into two main classes of data\noutput: in the first case, the output of interest are the sequences\nthemselves, perhaps also their polymorphisms or differences to other sequences\nseen before. In the second case, the sequences themselves are more or less\nwell-understood (say, we have a well-assembled and annotated genome), and our\ninterest is on how abundant different sequence regions are in our sample.\n\nFor instance, in **RNA-Seq** ([Ozsolak and Milos 2011](16-chap.html#ref-\nOzsolakMilos)), we sequence the RNA molecules found in a population of cells\nor in a tissue.\n\n[![Strictly speaking, we don’t sequence the RNA but the complementary DNA\n\\(cDNA\\) obtained from reverse transcription. The pool of all RNA might be\nreduced to a subset of interest \\(e.,g., messenger RNA\\) by biochemical means,\nsuch as poly-A selection or ribosomal RNA depletion. Sensitive variants of\nRNA-Seq exist that enable assaying single cells, and large numbers of\nthem.](imgs/devil.png)](imgs/devil.png \"Strictly speaking, we don’t sequence\nthe RNA but the complementary DNA \\(cDNA\\) obtained from reverse\ntranscription. The pool of all RNA might be reduced to a subset of interest\n\\(e.,g., messenger RNA\\) by biochemical means, such as poly-A selection or\nribosomal RNA depletion. Sensitive variants of RNA-Seq exist that enable\nassaying single cells, and large numbers of them.\")\n\nStrictly speaking, we don’t sequence the RNA but the complementary DNA (cDNA)\nobtained from reverse transcription. The pool of all RNA might be reduced to a\nsubset of interest (e.,g., messenger RNA) by biochemical means, such as poly-A\nselection or ribosomal RNA depletion. Sensitive variants of RNA-Seq exist that\nenable assaying single cells, and large numbers of them.\n\nIn **ChIP-Seq** , we sequence DNA regions that are bound to particular DNA-\nbinding proteins (selected by immuno-precipitation); in **RIP-Seq** , RNA\nmolecules or regions of them bound to a particular RNA-binding protein; in\n**DNA-Seq** , we sequence genomic DNA and are interested in the prevalence of\ngenetic variants in heterogeneous populations of cells, for instance the\nclonal composition of a tumor. In high-throughput chromatin conformation\ncapture (**HiC**) we aim to map the 3D spatial arrangement of DNA; in\n**genetic screens** (using, say, RNAi or CRISPR-Cas9 libraries for\nperturbation and high-throughput sequencing for readout), we’re interested in\nthe proliferation or survival of cells upon gene knockdown, knockout or\nmodification. In microbiome analysis, we study the abundance of different\nmicrobial species in complex microbial habitats.\n\nIdeally we might want to sequence and count _all_ molecules of interest in the\nsample. Generally this is not possible: the biochemical protocols are not 100%\nefficient, and some molecules or intermediates get lost along the way.\nMoreover it’s often also not even necessary. Instead, we sequence and count a\n_statistical sample_. The sample size will depend on the complexity of the\nsequence pool assayed; it can go from tens of thousands to billions. This\n_sampling_ nature of the data is important when it comes to analyzing them. We\nhope that the sampling is sufficiently representative for us to identify\ninteresting trends and patterns.\n\n\nIn this chapter, we will become familiar with count data in high-throughput\nsequencing applications such as RNA-Seq. We will understand and model the\nsampling processes that underlie the data in order to interpret them. Our main\naim is to detect and quantify systematic changes between samples from\ndifferent conditions, say _untreated_ versus _treated_ , where the task is to\ndistinguish such systematic changes from sampling variations and experimental\nvariability within the same conditions. In order to do this, we will also\nequip ourselves with a set of needed statistical concepts and tools:\n\n  * multifactorial designs, linear models and analysis of variance\n\n  * generalized linear models\n\n  * robustness and outlier detection\n\n  * shrinkage estimation\n\nIn fact, these concepts have a much wider range of applications: they can also\nbe applied to other types of data where want to detect differences in noisy\ndata as a function of some experimental covariate. In particular, the\nframework of generalized linear models is quite abstract and generic, but this\nhas the advantage that it can be adapted to many different data types, so that\nwe don’t need to reinvent the wheel, but rather can immediately enjoy a wide\nrange of associated tools and diagnostics.\n\nAs a bonus, we will also look at data transformations that make the data\namenable to unsupervised methods such as those that we saw in Chapters\n[5](05-chap.html) and [7](07-chap.html), and which make it easier to visualize\nthe data.\n\n## 8.2 Some core concepts\n\nBefore we start, let’s settle some key terminology.\n\n  * A _sequencing library_ is the collection of DNA molecules used as input for the sequencing machine.\n\n  * _Fragments_ are the molecules being sequenced. Since the currently most widely used technology1 can only deal with molecules of length around 300–1000 nucleotides, these are obtained by fragmenting the (generally longer) DNA or cDNA molecules of interest.\n\n  * A **read** is the sequence obtained from a fragment. With the current technology, the read covers not the whole fragment, but only one or both ends of it, and the read length on either side is up to around 150 nucleotides.\n\n1 We refer to <https://www.illumina.com/techniques/sequencing.html>\n\n2 For any particular application, it’s best to check the recent literature on\nthe most appropriate approaches and choices.\n\n3 E.g., in the case of RNA-Seq, the genome together with an annotation of its\ntranscripts.\n\nBetween sequencing and counting, there is an important _aggregation_ or\nclustering step involved, which aggregates sequences that belong together: for\ninstance, all reads belonging to the same gene (in RNA-Seq), or to the same\nbinding region (ChIP-Seq). There are several approaches to this and choices to\nbe made, depending on the aim of the experiment2. The methods include explicit\nalignment or hash-based mapping to a reference sequence3, and reference-\nindependent sequence-similarity based clustering of the reads – especially if\nthere is no obvious reference, such as in metagenomics or metatranscriptomics.\nWe need to choose whether to consider different alleles or isoforms\nseparately, or to merge them into an equivalence class. For simplicity, we’ll\nuse the term _gene_ in this chapter for these operational aggregates, even\nthough they can be various things depending on the particular application.\n\n## 8.3 Count data\n\nLet us load an example dataset. It resides in the experiment data package\n**[pasilla](https://bioconductor.org/packages/pasilla/)**.\n\n    \n    \n    fn = system.file(\"extdata\", \"pasilla_gene_counts.tsv\",\n                      package = \"pasilla\", mustWork = TRUE)\n    counts = as.matrix(read.csv(fn, sep = \"\\t\", row.names = \"gene_id\"))__\n\n[![In the code shown here, we use the function system.file to locate a file\nthat is shipped together with the pasilla package. When you work with your own\ndata, you will need to prepare the matrix counts\nyourself.](imgs/devil.png)](imgs/devil.png \"In the code shown here, we use the\nfunction system.file to locate a file that is shipped together with the\npasilla package. When you work with your own data, you will need to prepare\nthe matrix counts yourself.\")\n\nIn the code shown here, we use the function `system.file` to locate a file\nthat is shipped together with the\n**[pasilla](https://bioconductor.org/packages/pasilla/)** package. When you\nwork with your own data, you will need to prepare the matrix `counts`\nyourself.\n\nThe data are stored as a rectangular table in a tab-delimited file, which\nwe’ve read into the matrix `counts`.\n\n    \n    \n    dim(counts)__\n    \n    \n    [1] 14599     7\n    \n    \n    counts[ 2000+(0:3), ]__\n    \n    \n                untreated1 untreated2 untreated3 untreated4 treated1 treated2\n    FBgn0020369       3387       4295       1315       1853     4884     2133\n    FBgn0020370       3186       4305       1824       2094     3525     1973\n    FBgn0020371          1          0          1          1        1        0\n    FBgn0020372         38         84         29         28       63       28\n                treated3\n    FBgn0020369     2165\n    FBgn0020370     2120\n    FBgn0020371        0\n    FBgn0020372       27\n\nThe matrix tallies the number of reads seen for each gene in each sample. We\ncall it the **count table**. It has 14599 rows, corresponding to the genes,\nand 7 columns, corresponding to the samples. When loading data from a file, a\ngood plausibility check is to print out some of the data, and maybe not only\nat the very beginning, but also at some random point in the middle, as we have\ndone above.\n\nThe table is a matrix of integer values: the value in the \\\\(i\\\\)th row and\nthe \\\\(j\\\\)th column of the matrix indicates how many reads have been mapped\nto gene \\\\(i\\\\) in sample \\\\(j\\\\). The statistical sampling models that we\ndiscuss in this chapter rely on the fact that the values are the direct, “raw”\ncounts of sequencing reads – not some derived quantity, such as normalized\ncounts, counts of covered base pairs, or the like; this would only lead to\nnonsensical results.\n\n### 8.3.1 The challenges of count data\n\nWhat are the challenges that we need to overcome with such count data?\n\n  * The data have a large dynamic range, starting from zero up to millions. The variance, and more generally, the distribution shape of the data in different parts of the dynamic range are very different. We need to take this phenomenon, called **heteroskedasticity** , into account.\n\n  * The data are non-negative integers, and their distribution is not symmetric – thus normal or log-normal distribution models may be a poor fit.\n\n  * We need to understand the systematic sampling biases and adjust for them. Confusingly, this is often called **normalization**. Examples are the total sequencing depth of an experiment (even if the true abundance of a gene in two libraries is the same, we expect different numbers of reads for it depending on the total number of reads sequenced), or differing sampling probabilities (even if the true abundance of two genes within a biological sample is the same, we expect different numbers of reads for them if their biophysical properties differ, such as length, GC content, secondary structure, binding partners).\n\n  * We need to understand the stochastic properties of the sampling, as well as other sources of stochastic experimental variation. For studies with large numbers of biological samples, this is usually straightforward, and we can even fall back on resampling- or permutation-based methods. For designed experiments, however, sample sizes tend to be limited.\n\n[![There are important conceptual and practical differences between\nexperiments and studies – see also sec-\ndesign.](imgs/devil.png)](imgs/devil.png \"There are important conceptual and\npractical differences between experiments and studies – see also sec-design.\")\n\nThere are important conceptual and practical differences between experiments\nand studies – see also [Chapter 13](13-chap.html).\n\nFor instance, there are four replicates from the _untreated_ and three from\nthe _treated_ condition in the pasilla data. This means that resampling- or\npermutation-based methods will not have enough power. To proceed, we need to\nmake distributional assumptions. Essentially, what such assumptions do is that\nthey let us compute the probabilities of rare events in the tails of the\ndistribution – i.e., extraordinarily high or low counts – from a small number\nof distribution parameters.\n\n  * But even that is often not enough, in particular the estimation of dispersion parameters4 is difficult with small sample sizes. In that case, we need to make further assumptions, such as that genes with similar locations also have similar dispersions. This is called sharing of information across genes, and we’ll come back to it in Section 8.10.1.\n\n4 Distributions can be parameterized in various ways; often the parameters\ncorrespond to some measure of location and some measure of dispersion; a\nfamiliar measure of location is the mean, and a familiar measure of dispersion\nis the variance (or standard deviation), but for some distributions other\nmeasures are also in use.\n\n### 8.3.2 RNA-Seq: what about gene structures, splicing, isoforms?\n\nEukaryotic genes are complex: most of them consist of multiple exons, and\nmRNAs result from concatenation of exons through a process called splicing.\nAlternative splicing and multiple possible choices of start and stop sites\nenable the generation of multiple, alternative isoforms from the same gene\nlocus. It is possible to use high-throughput sequencing to detect the isoform\nstructures of transcripts. From the fragments that are characteristic for\nspecific isoforms, it is also possible to detect isoform specific abundances.\nWith current RNA-Seq data, which only give us relatively short fragments of\nthe full-length isoforms, it tends to be difficult to assemble and deconvolute\nfull-length isoform structures and abundances ([Steijger et al.\n2013](16-chap.html#ref-SteijgerBertone:2013)). Because of that, procedures\nwith the more modest aim of making only local statements (e.g., inclusion or\nexclusion of individual exons) have been formulated ([Anders, Reyes, and Huber\n2012](16-chap.html#ref-Reyes:GnomeResearch:2012)), and these can be more\nrobust. We can expect that future technologies will sequence full-length\ntranscripts.\n\n## 8.4 Modeling count data\n\n### 8.4.1 Dispersion\n\nConsider a sequencing library that contains \\\\(n_1\\\\) fragments corresponding\nto gene 1, \\\\(n_2\\\\) fragments for gene 2, and so on, with a total library\nsize of \\\\(n = n_1+n_2+\\cdots\\\\). We submit the library to sequencing and\ndetermine the identity of \\\\(r\\\\) randomly sampled fragments. A welcome\nsimplification comes from looking at the orders of magnitude of these numbers:\n\n  * the number of genes is in the tens of thousands;\n\n  * the value of \\\\(n\\\\) depends on the amount of cells that were used to prepare, but for bulk RNA-Seq it will be in the billions or trillions;\n\n  * the number of reads \\\\(r\\\\) is usually in the tens of millions, and thus much smaller than \\\\(n\\\\).\n\nFrom this we can conclude that the probability that a given read maps to the\n\\\\(i^{\\text{th}}\\\\) gene is \\\\(p_i=n_i/n\\\\), and that this is pretty much\nindependent of the outcomes for all the other reads. So we can model the\nnumber of reads for gene \\\\(i\\\\) by a Poisson distribution, where the _rate_\nof the Poisson process is the product of \\\\(p_i\\\\), the initial proportion of\nfragments for the \\\\(i^{\\text{th}}\\\\) gene, times \\\\(r\\\\), that is:\n\\\\(\\lambda_i=rp_i\\\\).\n\n[![In principle, we should consider sampling without replacement and the\nmultinomial distribution here: the probability of sampling a read for the\ni^{\\\\text{th}} gene depends on how many times the same gene, and other genes,\nhave already been sampled. However, these dependencies are so negligibly small\nthat we’ll ignore them. This is because n is so much larger than r, the number\nof genes is large, and each individual n_i is small compared to\nn.](imgs/devil.png)](imgs/devil.png \"In principle, we should consider sampling\nwithout replacement and the multinomial distribution here: the probability of\nsampling a read for the i^{\\\\text{th}} gene depends on how many times the same\ngene, and other genes, have already been sampled. However, these dependencies\nare so negligibly small that we’ll ignore them. This is because n is so much\nlarger than r, the number of genes is large, and each individual n_i is small\ncompared to n.\")\n\nIn principle, we should consider **sampling without replacement** and the\nmultinomial distribution here: the probability of sampling a read for the\n\\\\(i^{\\text{th}}\\\\) gene depends on how many times the same gene, and other\ngenes, have already been sampled. However, these dependencies are so\nnegligibly small that we’ll ignore them. This is because \\\\(n\\\\) is so much\nlarger than \\\\(r\\\\), the number of genes is large, and each individual\n\\\\(n_i\\\\) is small compared to \\\\(n\\\\).\n\nIn practice, we are usually not interested in modeling the read counts within\na single library, but in comparing the counts between libraries. That is, we\nwant to know whether any differences that we see between different biological\nconditions – say, the same cell line with and without drug treatment – are\nlarger than expected “by chance”, i.e., larger than what we may expect even\nbetween biological replicates. Empirically, it turns out that replicate\nexperiments vary more than what the Poisson distribution predicts.\nIntuitively, what happens is that \\\\(p_i\\\\) and therefore also \\\\(\\lambda_i\\\\)\nvary even between biological replicates; perhaps the temperature at which the\ncells grew was slightly different, or the amount of drug added varied by a few\npercent, or the incubation time was slightly longer. To account for that, we\nneed to add another layer of modeling on top. We already saw hierarchical\nmodels and mixtures in [Chapter 4](04-chap.html). It turns out that the\n**gamma-Poisson** (a.k.a. negative binomial) distribution suits our modeling\nneeds. Instead of a single \\\\(\\lambda\\\\) – which represents both mean and\nvariance –, this distribution has two parameters. In principle, these can be\ndifferent for each gene, and we will come back to the question of how to\nestimate them from the data.\n\n### 8.4.2 Normalization\n\nOften, there are systematic biases that have affected the data generation and\nare worth taking into account. Unfortunately, the term **normalization** is\ncommonly used for that aspect of the analysis, even though it is misleading:\nit has nothing to do with the normal distribution, norms in a vector space, or\nnormal vectors. Rather, what we aim for is identifying the nature and\nestimating the magnitude of systematic biases, and take them into account in\nour model-based analysis of the data.\n\nThe most important systematic bias stems from variations in the total number\nof reads in each sample. If we have more reads for one library than in\nanother, then we might assume that, everything else being equal, the counts\nare proportional to each other with some proportionality factor \\\\(s\\\\).\nNaively, we could propose that a decent estimate of \\\\(s\\\\) for each sample is\nsimply given by the sum of the counts of all genes. However, it turns out that\nwe can do better. To understand this, a toy example helps.\n\n[![](08-chap_files/figure-html/fig-countdata-\nnormalization-1.png)](08-chap_files/figure-html/fig-countdata-\nnormalization-1.png \"Figure 8.1: Size factor estimation. The points correspond\nto hypothetical genes whose counts in two samples are indicated by their x-\nand y-coordinates. The lines indicate two different ways of size factor\nestimation explained in the text.\")\n\nFigure 8.1: Size factor estimation. The points correspond to hypothetical\ngenes whose counts in two samples are indicated by their \\\\(x\\\\)\\- and\n\\\\(y\\\\)-coordinates. The lines indicate two different ways of size factor\nestimation explained in the text.\n\nConsider a dataset with 5 genes and two samples as displayed in Figure 8.1. If\nwe estimate \\\\(s\\\\) for each of the two samples by its sum of counts, then the\nslope of the blue line represents their ratio. According to this, gene C is\ndown-regulated in sample 2 compared to sample 1, while the other genes are all\nsomewhat up-regulated. If we now instead estimate \\\\(s\\\\) such that their\nratios correspond to the red line, then we will still conclude that gene C is\ndown-regulated, while the other genes are unchanged. The second version is\nmore parsimonious and is often preferred by scientists. The slope of the red\nline can be obtained by robust regression. This is what the\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** method does.\n\n__\n\nQuestion 8.1\n\nFor the example dataset `count` of Section 8.3, how does the output of\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** ’s\n`estimateSizeFactorsForMatrix` compare to what you get by simply taking the\ncolumn sums?\n\n__\n\nSolution\n\n__\n\nSee Figure 8.2, produced by the code below. In this case, there is not much\ndifference, the results are nearly proportional.\n\n    \n    \n    library(\"tibble\")\n    library(\"ggplot2\")\n    library(\"DESeq2\")\n    ggplot(tibble(\n      `size factor` = estimateSizeFactorsForMatrix(counts),\n      `sum` = colSums(counts)), aes(x = `size factor`, y = `sum`)) +\n      geom_point()__\n\n[![](08-chap_files/figure-html/fig-countdata-\nsfvssum-1.png)](08-chap_files/figure-html/fig-countdata-sfvssum-1.png\n\"Figure 8.2: Size factors versus sums for the pasilla data.\")\n\nFigure 8.2: Size factors versus sums for the pasilla data.\n\n__\n\nTask\n\nLocate the R sources for this book and have a look at the code that produces\nFigure 8.1.\n\n__\n\nQuestion 8.2\n\nPlot the mean-variance relationship for the biological replicates in the\npasilla dataset.\n\n__\n\nSolution\n\n__\n\nSee Figure 8.3, produced by the following code.\n\n    \n    \n    library(\"matrixStats\")\n    sf = estimateSizeFactorsForMatrix(counts)\n    ncounts  = counts / matrix(sf,\n       byrow = TRUE, ncol = ncol(counts), nrow = nrow(counts))\n    uncounts = ncounts[, grep(\"^untreated\", colnames(ncounts)),\n                         drop = FALSE]\n    ggplot(tibble(\n            mean = rowMeans(uncounts),\n            var  = rowVars( uncounts)),\n         aes(x = log(mean), y = log(var))) +\n      geom_hex() + coord_fixed() + theme(legend.position = \"none\") +\n      geom_abline(slope = 1:2, color = c(\"forestgreen\", \"red\"))__\n\n[![](08-chap_files/figure-html/fig-countdata-\nvarmean-1.png)](08-chap_files/figure-html/fig-countdata-varmean-1.png\n\"Figure 8.3: Variance versus mean for the \\(size factor adjusted\\) counts\ndata. The axes are logarithmic. Also shown are lines through the origin with\nslopes 1 \\(green\\) and 2 \\(red\\).\")\n\nFigure 8.3: Variance versus mean for the (size factor adjusted) `counts` data.\nThe axes are logarithmic. Also shown are lines through the origin with slopes\n1 (green) and 2 (red).\n\nThe green line (slope 1) is what we expect if the variance (\\\\(v\\\\)) equals\nthe mean (\\\\(m\\\\)), as is the case for a Poisson-distributed random variable:\n\\\\(v=m\\\\). We see that this approximately fits the data in the lower range.\nThe red line (slope 2) corresponds to the quadratic mean-variance relationship\n\\\\(v=m^2\\\\); lines parallel to it (not shown) would represent \\\\(v = cm^2\\\\)\nfor various values of \\\\(c\\\\). We can see that in the upper range of the data,\nthe quadratic relationship approximately fits the data, for some value of\n\\\\(c<1\\\\).\n\n## 8.5 A basic analysis\n\n### 8.5.1 Example dataset: the pasilla data\n\nLet’s return to the **[pasilla](https://bioconductor.org/packages/pasilla/)**\ndata from Section 8.3. These data are from an experiment on _Drosophila\nmelanogaster_ cell cultures that investigated the effect of RNAi knock-down of\nthe splicing factor _pasilla_ ([Brooks et al. 2011](16-chap.html#ref-\nBrooks2010)) on the cells’ transcriptome. There were two experimental\nconditions, termed _untreated_ and _treated_ in the header of the count table\nthat we loaded. They correspond to negative control and to siRNA against\n_pasilla_. The experimental metadata of the 7 samples in this dataset are\nprovided in a spreadsheet-like table, which we load.\n\n[![In the code shown here, we load the file pasilla_sample_annotation.csv that\ncomes with the pasilla package. We locate it with the function system.file.\nWhen you work with your own data, you will need to prepare an analogous file,\nor directly a dataframe like\npasillaSampleAnno.](imgs/devil.png)](imgs/devil.png \"In the code shown here,\nwe load the file pasilla_sample_annotation.csv that comes with the pasilla\npackage. We locate it with the function system.file. When you work with your\nown data, you will need to prepare an analogous file, or directly a dataframe\nlike pasillaSampleAnno.\")\n\nIn the code shown here, we load the file `pasilla_sample_annotation.csv` that\ncomes with the **[pasilla](https://bioconductor.org/packages/pasilla/)**\npackage. We locate it with the function `system.file`. When you work with your\nown data, you will need to prepare an analogous file, or directly a dataframe\nlike `pasillaSampleAnno`.\n\n    \n    \n    annotationFile = system.file(\"extdata\",\n      \"pasilla_sample_annotation.csv\",\n      package = \"pasilla\", mustWork = TRUE)\n    pasillaSampleAnno = readr::read_csv(annotationFile)\n    pasillaSampleAnno __\n    \n    \n    # A tibble: 7 × 6\n      file    condition type  `number of lanes` total number of read…¹ `exon counts`\n      <chr>   <chr>     <chr>             <dbl> <chr>                          <dbl>\n    1 treate… treated   sing…                 5 35158667                    15679615\n    2 treate… treated   pair…                 2 12242535 (x2)               15620018\n    3 treate… treated   pair…                 2 12443664 (x2)               12733865\n    4 untrea… untreated sing…                 2 17812866                    14924838\n    5 untrea… untreated sing…                 6 34284521                    20764558\n    6 untrea… untreated pair…                 2 10542625 (x2)               10283129\n    7 untrea… untreated pair…                 2 12214974 (x2)               11653031\n    # ℹ abbreviated name: ¹​`total number of reads`\n\nAs we see here, the overall dataset was produced in two batches, the first one\nconsisting of three sequencing libraries that were subjected to single read\nsequencing, the second batch consisting of four libraries for which paired end\nsequencing was used. As so often, we need to do some data wrangling: we\nreplace the hyphens in the `type` column by underscores, as arithmetic\noperators in factor levels are discouraged by\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** , and convert the\n`type` and `condition` columns into factors, explicitly specifying our\nprefered order of the levels (the default is alphabetical).\n\n    \n    \n    library(\"dplyr\")\n    pasillaSampleAnno = mutate(pasillaSampleAnno,\n    condition = factor(condition, levels = c(\"untreated\", \"treated\")),\n    type = factor(sub(\"-.*\", \"\", type), levels = c(\"single\", \"paired\")))__\n\nWe note that the design is approximately balanced between the factor of\ninterest, `condition`, and the “nuisance factor” `type`:\n\n    \n    \n    with(pasillaSampleAnno,\n           table(condition, type))__\n    \n    \n               type\n    condition   single paired\n      untreated      2      2\n      treated        1      2\n\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** uses a specialized\ndata container, called _DESeqDataSet_ to store the datasets it works with.\nSuch use of specialized containers – or, in R terminology, _classes_ – is a\ncommon principle of the Bioconductor project, as it helps users to keep\ntogether related data. While this way of doing things requires users to invest\na little more time upfront to understand the classes, compared to just using\nbasic R data types like _matrix_ and dataframe, it helps avoiding bugs due to\nloss of synchronization between related parts of the data. It also enables the\nabstraction and encapsulation of common operations that could be quite wordy\nif always expressed in basic terms5. _DESeqDataSet_ is an extension of the\nclass _SummarizedExperiment_ in Bioconductor. The _SummarizedExperiment_ class\nis also used by many other packages, so learning to work with it will enable\nyou to use quite a range of tools.\n\n5 Another advantage is that classes can contain _validity_ methods, which make\nsure that the data always fulfill certain expectations, for instance, that the\ncounts are positive integers, or that the columns of the counts matrix align\nwith the rows of the sample annotation dataframe.\n\n6 Note how in the code below, we have to put in extra work to match the column\nnames of the `counts` object with the `file` column of the `pasillaSampleAnno`\ndataframe, in particular, we need to remove the `\"fb\"` that happens to be used\nin the `file` column for some reason. Such data wrangling is very common. One\nof the reasons for storing the data in a _DESeqDataSet_ object is that we then\nno longer have to worry about such things.\n\nWe use the constructor function `DESeqDataSetFromMatrix` to create a\n_DESeqDataSet_ from the count data matrix `counts` and the sample annotation\ndataframe `pasillaSampleAnno`6.\n\n    \n    \n    mt = match(colnames(counts), sub(\"fb$\", \"\", pasillaSampleAnno$file))\n    stopifnot(!any(is.na(mt)))\n    \n    pasilla = DESeqDataSetFromMatrix(\n      countData = counts,\n      colData   = pasillaSampleAnno[mt, ],\n      design    = ~ condition)\n    class(pasilla)__\n    \n    \n    [1] \"DESeqDataSet\"\n    attr(,\"package\")\n    [1] \"DESeq2\"\n    \n    \n    is(pasilla, \"SummarizedExperiment\")__\n    \n    \n    [1] TRUE\n\nThe _SummarizedExperiment_ class – and therefore _DESeqDataSet_ – also\ncontains facilities for storing annotation of the rows of the count matrix.\nFor now, we are content with the gene identifiers from the row names of the\n`counts` table.\n\n__\n\nQuestion 8.3\n\nHow can we access the row metadata of a _SummarizedExperiment_ object, i.e.,\nhow can we read it out, how can we change it?\n\n__\n\nSolution\n\n__\n\nCheck the manual page of the _SummarizedExperiment_ class and of the methods\n`rowData` and `rowData<-`.\n\n### 8.5.2 The **[DESeq2](https://bioconductor.org/packages/DESeq2/)** method\n\nAfter these preparations, we are now ready to jump straight into differential\nexpression analysis. Our aim is to identify genes that are differentially\nabundant between the treated and the untreated cells. To this end, we will\napply a test that is conceptually similar to the \\\\(t\\\\)-test, which we\nencountered in [Section 6.5](06-chap.html#sec-testing-ttest), although\nmathematically somewhat more involved. We will postpone these details for now,\nand will come back to them in Section 8.7. A choice of standard analysis steps\nare wrapped into a single function, `DESeq`.\n\n    \n    \n    pasilla = DESeq(pasilla)__\n\nThe `DESeq` function is simply a wrapper that calls, in order, the functions\n`estimateSizeFactors` (for normalization, as discussed in Section 8.4.2),\n`estimateDispersions` (dispersion estimation) and `nbinomWaldTest` (hypothesis\ntests for differential abundance). The test is between the two levels\nextttuntreated and exttttreated of the factor `condition`, since this is what\nwe specified when we constructed the `pasilla` object through the argument\n`design=\\simcondition`. You can always call each of these three functions\nindividually if you want to modify their behavior or interject custom steps.\nLet us look at the results.\n\n    \n    \n    res = results(pasilla)\n    res[order(res$padj), ] |> head()__\n    \n    \n    log2 fold change (MLE): condition treated vs untreated \n    Wald test p-value: condition treated vs untreated \n    DataFrame with 6 rows and 6 columns\n                 baseMean log2FoldChange     lfcSE      stat       pvalue\n                <numeric>      <numeric> <numeric> <numeric>    <numeric>\n    FBgn0039155   730.596       -4.61901 0.1687068  -27.3789 4.88599e-165\n    FBgn0025111  1501.411        2.89986 0.1269205   22.8479 1.53430e-115\n    FBgn0029167  3706.117       -2.19700 0.0969888  -22.6521 1.33042e-113\n    FBgn0003360  4343.035       -3.17967 0.1435264  -22.1539 9.56283e-109\n    FBgn0035085   638.233       -2.56041 0.1372952  -18.6490  1.28772e-77\n    FBgn0039827   261.916       -4.16252 0.2325888  -17.8965  1.25663e-71\n                        padj\n                   <numeric>\n    FBgn0039155 4.06661e-161\n    FBgn0025111 6.38497e-112\n    FBgn0029167 3.69104e-110\n    FBgn0003360 1.98979e-105\n    FBgn0035085  2.14354e-74\n    FBgn0039827  1.74316e-68\n\n### 8.5.3 Exploring the results\n\nThe first step after a differential expression analysis is the visualization\nof the following three or four basic plots:\n\n  * the histogram of p-values (Figure 8.4),\n\n  * the MA plot (Figure 8.5) and\n\n  * an ordination plot (Figure 8.6).\n\n  * In addition, a heatmap (Figure 8.7) can be instructive.\n\nThese are essential data quality assessment measures – and the general advice\non quality assessment and control given in [Section 13.6](13-chap.html#sec-\ndesign-quality) also applies here.\n\nThe p-value histogram is straightforward (Figure 8.4).\n\n    \n    \n    ggplot(as(res, \"data.frame\"), aes(x = pvalue)) +\n      geom_histogram(binwidth = 0.01, fill = \"Royalblue\", boundary = 0)__\n\n[![](08-chap_files/figure-html/fig-countdata-\nhist1-1.png)](08-chap_files/figure-html/fig-countdata-hist1-1.png \"Figure 8.4:\nHistogram of p-values of a differential expression analysis.\")\n\nFigure 8.4: Histogram of p-values of a differential expression analysis.\n\nThe distribution displays two main components: a uniform background with\nvalues between 0 and 1, and a peak of small p-values at the left. The uniform\nbackground corresponds to the non-differentially expressed genes. Usually this\nis the majority of genes. The left hand peak corresponds to differentially\nexpressed genes7. As we already saw in [Chapter 6](06-chap.html), the ratio of\nthe level of the background to the height of the peak gives us a rough\nindication of the false discovery rate (FDR) that would be associated with\ncalling the genes in the leftmost bin differentially expressed. In our case,\nthe leftmost bin contains all p-values between 0 and 0.01, which correspond to\n993 genes. The background level is at around 100, so the FDR associated with\ncalling all genes in the leftmost bin would be around 10%.\n\n7 For the data shown here, the histogram also contains a few isolated peaks in\nthe middle or towards the right; these stem from genes with small counts and\nreflect the discreteness of the data.\n\nSometimes it turns out that the background distribution is not uniform, but\nshows a tilted shape with an increase towards the right. This tends to be an\nindication of batch effects; you can explore this further in Exercise 8.1.\n\nTo produce the MA plot, we can use the function `plotMA` in the\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** package (Figure 8.5).\n\n    \n    \n    plotMA(pasilla, ylim = c( -2, 2))__\n\n[![](08-chap_files/figure-html/fig-countdata-MA-1.png)](08-chap_files/figure-\nhtml/fig-countdata-MA-1.png \"Figure 8.5: MA plot: fold change versus mean of\nsize-factor normalized counts. Logarithmic scaling is used for both axes. By\ndefault, points are colored red if the adjusted p-value is less than 0.1.\nPoints which fall out of the y-axis range are plotted as triangles.\")\n\nFigure 8.5: [MA plot](https://en.wikipedia.org/wiki/MA_plot): fold change\nversus mean of size-factor normalized counts. Logarithmic scaling is used for\nboth axes. By default, points are colored red if the adjusted p-value is less\nthan 0.1. Points which fall out of the \\\\(y\\\\)-axis range are plotted as\ntriangles.\n\nTo produce PCA plots similar to those we saw in [Chapter 7](07-chap.html), we\ncan use the **[DESeq2](https://bioconductor.org/packages/DESeq2/)** function\n`plotPCA` (Figure 8.6).\n\n    \n    \n    pas_rlog = rlogTransformation(pasilla)\n    plotPCA(pas_rlog, intgroup=c(\"condition\", \"type\")) + coord_fixed()__\n\n[![](08-chap_files/figure-html/fig-countdata-PCA-1.png)](08-chap_files/figure-\nhtml/fig-countdata-PCA-1.png \"Figure 8.6: PCA plot. The 7 samples are shown in\nthe 2D plane spanned by their first two principal components.\")\n\nFigure 8.6: PCA plot. The 7 samples are shown in the 2D plane spanned by their\nfirst two principal components.\n\nAs we saw in the previous chapter, this type of plot is useful for visualizing\nthe overall effect of experimental covariates and/or to detect batch effects.\nHere, the first principal axis, PC1, is mostly aligned with the experimental\ncovariate of interest (untreated / treated), while the second axis is roughly\naligned with the sequencing protocol (single / paired).\n\nWe used a data transformation, the **regularized logarithm** or **rlog** ,\nwhich we will investigate more closely in Section 8.10.2.\n\n__\n\nQuestion 8.4\n\nDo the axes of PCA plot always have to align with known experimental\ncovariates?\n\nHeatmaps can be a powerful way of quickly getting an overview over a matrix-\nlike dataset, count tables included. Below you see how to make a heatmap from\nthe rlog-transformed data. For a matrix as large as `counts(pasilla)`, it is\nnot practical to plot all of it, so we plot the submatrix of the 30 genes with\nthe highest average expression.\n\n    \n    \n    library(\"pheatmap\")\n    select = order(rowMeans(assay(pas_rlog)), decreasing = TRUE)[1:30]\n    pheatmap( assay(pas_rlog)[select, ],\n         scale = \"row\",\n         annotation_col = as.data.frame(\n            colData(pas_rlog)[, c(\"condition\", \"type\")] ))__\n\n[![](08-chap_files/figure-html/fig-figHeatmap-1-1.png)](08-chap_files/figure-\nhtml/fig-figHeatmap-1-1.png \"Figure 8.7: Heatmap of regularized log\ntransformed data of the top 30 genes.\")\n\nFigure 8.7: Heatmap of regularized log transformed data of the top 30 genes.\n\nIn Figure 8.7, `pheatmap` arranged the rows and columns of the matrix by the\ndendrogram from an unsupervised clustering, and the clustering of the columns\n(samples) is dominated by the `type` factor. This highlights that our\ndifferential expression analysis above was probably too naive, and that we\nshould adjust for this strong “nuisance” factor when we are interested in\ntesting for differentially expressed genes between conditions. We will do this\nin Section 8.9.\n\n__\n\nTask\n\nProduce a plot similar to Figure 8.7, but selecting the 30 most highly\nvariable genes instead. What is different? How do the genes with very high\nmean and those with very high variance relate? How does their data look?\n\n### 8.5.4 Exporting the results\n\nAn HTML report of the results with plots and sortable/filterable columns can\nbe exported using the\n**[ReportingTools](https://bioconductor.org/packages/ReportingTools/)**\npackage on a _DESeqDataSet_ that has been processed by the `DESeq` function.\nFor a code example, see the _RNA-Seq differential expression_ vignette of the\n**[ReportingTools](https://bioconductor.org/packages/ReportingTools/)**\npackage or the manual page for the `publish` method for the _DESeqDataSet_\nclass.\n\nA CSV file of the results can be exported using `write.csv` (or its\ncounterpart from the\n**[readr](https://cran.r-project.org/web/packages/readr/)** package).\n\n    \n    \n    write.csv(as.data.frame(res), file = \"treated_vs_untreated.csv\")__\n\n## 8.6 Critique of default choices and possible modifications\n\n### 8.6.1 The few changes assumption\n\nUnderlying the default normalization and the dispersion estimation in\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** (and many other\ndifferential expression methods) is that most genes are not differentially\nexpressed.\n\n[![For the normalization, although not for the dispersion estimation, one can\nslightly relax this assumption: it is still valid if many genes are changing,\nbut in a way that is balanced between up- and downward\ndirections.](imgs/devil.png)](imgs/devil.png \"For the normalization, although\nnot for the dispersion estimation, one can slightly relax this assumption: it\nis still valid if many genes are changing, but in a way that is balanced\nbetween up- and downward directions.\")\n\nFor the normalization, although not for the dispersion estimation, one can\nslightly relax this assumption: it is still valid if many genes are changing,\nbut in a way that is balanced between up- and downward directions.\n\nThis assumption is often reasonable (well-designed experiments usually ask\nspecific questions, so that not everything changes all at once), but what\nshould we do if it does not hold? Instead of applying these operations on the\ndata from all genes, we will then need to identify a subset of (“negative\ncontrol”) genes for which we believe the assumption is tenable, either because\nof prior biological knowledge, or because we explicitly controlled their\nabundance as external “spiked in” features.\n\n__\n\nTask\n\nRun the **[DESeq2](https://bioconductor.org/packages/DESeq2/)** workflow with\nsize factors and dispersion parameters estimated only from a predefined subset\nof genes.\n\n### 8.6.2 Point-like null hypothesis\n\nAs a default, the `DESeq` function tests against the null hypothesis that each\ngene has the same abundance across conditions; this is a simple and pragmatic\nchoice. Indeed, if the sample size is limited, what is statistically\nsignificant also tends to be strong enough to be biologically interesting. But\nas sample size increases, statistical significance in these tests may be\npresent without much biological relevance. For instance, many genes may be\nslightly perturbed by downstream, indirect effects. We can modify the test to\nuse a more permissive, interval-based null hypothesis; we will further explore\nthis in Section 8.10.4.\n\n## 8.7 Multi-factor designs and linear models\n\n### 8.7.1 What is a multifactorial design?\n\nLet’s assume that in addition to the siRNA knockdown of the pasilla gene, we\nalso want to test the effect of a certain drug. We could then envisage an\nexperiment in which the experimenter treats the cells either with negative\ncontrol, with the siRNA against pasilla, with the drug, or with both. To\nanalyse this experiment, we can use the notation\n\n\\\\[ y = \\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + x_1x_2\\beta_{12}. \\tag{8.1}\\\\]\n\nThis equation can be parsed as follows. The left hand side, \\\\(y\\\\), is the\nexperimental measurement of interest. In our case, this is the suitably\ntransformed expression level (we’ll discuss this in Section 8.8.3) of a gene.\nSince in an RNA-Seq experiment there are lots of genes, we’ll have as many\ncopies of Equation 8.1, one for each. The coefficient \\\\(\\beta_0\\\\) is the\nbase level of the measurement in the negative control; often it is called the\n**intercept**.\n\n[![Sometimes Equation eq-countdata-basiclm is written with an additional term\nx_0 that is multiplied with \\\\beta_0, where it is understood that x_0=1\nalways. It turns out that this makes subsequent notation and bookkeeping\neasier since then the intercept can be handled consistently together with the\nother \\\\betas, instead of being a separate\ncase.](imgs/devil.png)](imgs/devil.png \"Sometimes Equation eq-countdata-\nbasiclm is written with an additional term x_0 that is multiplied with\n\\\\beta_0, where it is understood that x_0=1 always. It turns out that this\nmakes subsequent notation and bookkeeping easier since then the intercept can\nbe handled consistently together with the other \\\\betas, instead of being a\nseparate case.\")\n\nSometimes Equation 8.1 is written with an additional term \\\\(x_0\\\\) that is\nmultiplied with \\\\(\\beta_0\\\\), where it is understood that \\\\(x_0=1\\\\) always.\nIt turns out that this makes subsequent notation and bookkeeping easier since\nthen the intercept can be handled consistently together with the other\n\\\\(\\beta\\\\)s, instead of being a separate case.\n\nThe design factors \\\\(x_1\\\\) and \\\\(x_2\\\\) are binary indicator variables:\n\\\\(x_1\\\\) takes the value 1 if the siRNA was transfected and 0 if not, and\nsimilarly, \\\\(x_2\\\\) indicates whether the drug was administered. In the\nexperiment where only the siRNA is used, \\\\(x_1=1\\\\) and \\\\(x_2=0\\\\), and the\nthird and fourth terms of Equation 8.1 vanish. Then, the equation simplifies\nto \\\\(y=\\beta_0+\\beta_1\\\\). This means that \\\\(\\beta_1\\\\) represents the\ndifference between treatment and control. If our measurements are on a\nlogarithmic scale, then\n\n\\\\[ \\begin{align} \\beta_1 = y-\\beta_0\n&=\\log_2(\\text{expression}_{\\text{treated}})\n-\\log_2(\\text{expression}_{\\text{untreated}})\\\\\\ &=\\log_2\\frac\n{\\text{expression}_{\\text{treated}}} {\\text{expression}_{\\text{untreated}}}\n\\end{align} \\tag{8.2}\\\\]\n\nis the logarithmic fold change due to treatment with the siRNA. In exactly the\nsame way, \\\\(\\beta_2\\\\) is the logarithmic fold change due to treatment with\nthe drug. What happens if we treat the cells with both siRNA and drug? In that\ncase, \\\\(x_1=x_2=1\\\\), and Equation 8.1 can be rewritten as\n\n\\\\[ \\beta_{12} = y - (\\beta_0 + \\beta_1 + \\beta_2). \\tag{8.3}\\\\]\n\nThis means that \\\\(\\beta_{12}\\\\) is the difference between the observed\noutcome, \\\\(y\\\\), and the outcome expected from the individual treatments,\nobtained by adding to the baseline the effect of siRNA alone, \\\\(\\beta_1\\\\),\nand of drug alone, \\\\(\\beta_2\\\\).\n\nWe call \\\\(\\beta_{12}\\\\) the _interaction_ effect of siRNA and drug. It has\nnothing to do with a physical interaction, the terminology indicates that the\neffects of these two different experimental factors do not simply add up, but\ncombine in a more complicated fashion.\n\n[![Note that the addition is on the logarithmic scale, which corresponds to\nmultiplication on the original scale.](imgs/devil.png)](imgs/devil.png \"Note\nthat the addition is on the logarithmic scale, which corresponds to\nmultiplication on the original scale.\")\n\nNote that the addition is on the logarithmic scale, which corresponds to\nmultiplication on the original scale.\n\nFor instance, if the target of the drug and of the siRNA were equivalent,\nleading to the same effect on the cells, then we biologically expect that\n\\\\(\\beta_1=\\beta_2\\\\). We also expect that their combination has no further\neffect, so that \\\\(\\beta_{12}=-\\beta_1\\\\). If, on the other hand, the targets\nof the drug and of the siRNA are in parallel pathways that can buffer each\nother, we’ll expect that \\\\(\\beta_1\\\\) and \\\\(\\beta_2\\\\) are both relatively\nsmall, but that the combined effect is synergistic, and \\\\(\\beta_{12}\\\\) is\nlarge.\n\nNot always do we care about interactions. Many experiments are designed with\nmultiple factors where we care most about each of their individual effects. In\nthat case, the combinatorial treatment might not be present in the\nexperimental design, and the model to use for the analysis is a version of\nEquation 8.1 with the rightmost term removed.\n\nWe can succinctly encode the design of the experiment in the _design matrix_.\nFor instance, for the combinatorial experiment described above, the design\nmatrix is\n\n\\\\[ \\begin{array}{c|c|c} x_0 & x_1 & x_2\\\\\\ \\hline 1&0&0\\\\\\ 1&1&0\\\\\\ 1&0&1\\\\\\\n1&1&1\\end{array} \\tag{8.4}\\\\]\n\nThe columns of the design matrix correspond to the experimental factors, and\nits rows represent the different experimental conditions, four in our case.\nIf, instead, the combinatorial treatment is not performed, then the design\nmatrix is reduced to only the first three rows of 8.4.\n\n### 8.7.2 What about noise and replicates?\n\nEquation 8.1 provides a conceptual decomposition of the observed data into the\neffects caused by the different experimental variables. If our data (the\n\\\\(y\\\\)s) were absolutely precise, we could set up a linear system of\nequations, one equation for each of the four possible experimental conditions\nrepresented by the \\\\(x\\\\)s, and solve for the \\\\(\\beta\\\\)s.\n\nOf course, we usually wish to analyze real data that are affected by noise. We\nthen need replicates to estimate the levels of noise and assess the\nuncertainty of our estimated \\\\(\\beta\\\\)s. Only then we can empirically assess\nwhether any of the observed changes between conditions are significantly\nlarger than those occuring just due to experimental or natural variation. We\nneed to slightly extend the equation,\n\n\\\\[ y_{j} = x_{j0} \\; \\beta_0 + x_{j1} \\; \\beta_1 + x_{j2} \\; \\beta_2 +\nx_{j1}\\,x_{j2}\\;\\beta_{12} + \\varepsilon_j. \\tag{8.5}\\\\]\n\nWe have added the index \\\\(j\\\\) and a new term \\\\(\\varepsilon_j\\\\). The index\n\\\\(j\\\\) now explicitly counts over our individual replicate experiments; for\ninstance, if for each of the four conditions we perform three replicates, then\n\\\\(j\\\\) counts from 1 to 12. The design matrix has now 12 rows, and\n\\\\(x_{jk}\\\\) is the value of the matrix in its \\\\(j\\\\)th row and \\\\(k\\\\)th\ncolumn.\n\n[![Remember that since \\\\beta_0 is the intercept, x_{j0}=1 for all\nj.](imgs/devil.png)](imgs/devil.png \"Remember that since \\\\beta_0 is the\nintercept, x_{j0}=1 for all j.\")\n\nRemember that since \\\\(\\beta_0\\\\) is the intercept, \\\\(x_{j0}=1\\\\) for all\n\\\\(j\\\\).\n\nThe additional terms \\\\(\\varepsilon_j\\\\), which we call the **residuals** ,\nare there to absorb differences between replicates. However, one additional\nmodeling component is needed: the system of twelve equations 8.5 would be\nunderdetermined without further information, since it has now more variables\n(twelve epsilons and four betas) than it has equations (twelve, one for each\n\\\\(j\\\\)). To fix this, we require that the \\\\(\\varepsilon_j\\\\) be small. One\npopular way – we’ll encounter others – to overcome this is to minimize the sum\nof squared residuals,\n\n\\\\[ \\sum_j \\varepsilon_j^2 \\quad\\to\\quad\\text{min}. \\tag{8.6}\\\\]\n\nIt turns out that with this requirement satisfied, the \\\\(\\beta\\\\)s represent\nthe _average_ effects of each of the experimental factors, while the residuals\n\\\\(\\varepsilon_j\\\\) reflect the experimental fluctuations around the mean\nbetween the replicates. This approach, which is called the **least sum of\nsquares fitting** , is mathematically convenient, since it can achieved by\nstraightforward matrix algebra. It is what the R function `lm` does.\n\n__\n\nQuestion 8.5\n\nAn alternative way to write Equation 8.5 is\n\n\\\\[ y_{j} = \\sum_k x_{jk} \\; \\beta_k + \\varepsilon_j. \\tag{8.7}\\\\]\n\nHow can this be mapped to Equation 8.5, i.e., what’s with the interaction term\n\\\\(x_{j1}\\,x_{j2}\\;\\beta_{12}\\\\)?\n\n__\n\nSolution\n\n__\n\nThis is really just a trivial matter of notation: the sum extends over\n\\\\(k=0,...,3\\\\), where the terms for \\\\(k=0,1,2\\\\) are exactly as we know them\nalready. We write \\\\(\\beta_{3}\\\\) instead of \\\\(\\beta_{12}\\\\), and\n\\\\(x_{j3}\\\\) is defined to be \\\\(x_{j1}x_{j2}\\\\). The generic notation 8.7 is\npractical to use in computer software that implements linear models and in\nmathematical proofs. It also highlights that the “scientific content” of a\nlinear model is condensed in its design matrix.\n\n__\n\nTask\n\nShow that if we have fit Equation 8.5 to data such that objective 8.6 holds,\nthe fit residuals \\\\(\\hat{\\varepsilon}_j\\\\) have an average of 0.\n\n### 8.7.3 Analysis of variance\n\nA model like 8.5 is called a **linear model** , and often it is implied that\ncriterion 8.6 is used to fit it to data. This approach is elegant and\npowerful, but for novices it can take some time to appreciate all its facets.\nWhat is the advantage over just simply taking, for each distinct experimental\ncondition, the average over replicates and comparing these values across\nconditions? In simple cases, the latter approach can be intuitive and\neffective. However, it comes to its limits when the replicate numbers are not\nall the same in the different groups, or when one or more of the\n\\\\(x\\\\)-variables is continuous-valued. In these cases, one will invariably\nend up with something like fitting 8.5 to the data. A useful way to think\nabout 8.5 is contained in the term **analysis of variance** , abbreviated\nANOVA. In fact, what Equation 8.5 does is decompose the variability of \\\\(y\\\\)\nthat we observed in the course of our experiments into elementary components:\nits baseline value \\\\(\\beta_0\\\\), its variability caused by the effect of the\nfirst variable, \\\\(\\beta_1\\\\), its variability caused by the effect of the\nsecond variable, \\\\(\\beta_2\\\\), its variability caused by the effect of the\ninteraction, \\\\(\\beta_{12}\\\\), and variability that is unaccounted for. The\nlast of these we commonly call _noise_ , the other ones, _systematic\nvariability_.\n\n[![The distinction between noise and systematic variability is in the eye of\nthe beholder, and depends on our model, not on\nreality.](imgs/devil.png)](imgs/devil.png \"The distinction between noise and\nsystematic variability is in the eye of the beholder, and depends on our\nmodel, not on reality.\")\n\nThe distinction between noise and systematic variability is in the eye of the\nbeholder, and depends on our model, not on reality.\n\n### 8.7.4 Robustness\n\nThe sum 8.6 is sensitive to outliers in the data. A single measurement\n\\\\(y_{j}\\\\) with an outlying value can draw the \\\\(\\beta\\\\) estimates far away\nfrom the values implied by the other replicates. This is the well-known fact\nthat methods based on least sum of squares have a low **breakdown point** : if\neven only a single data point is outlying, the whole statistical result can be\nstrongly affected. For instance, the average of a set of \\\\(n\\\\) numbers has a\nbreakdown point of \\\\(\\frac{1}{n}\\\\), meaning that it can be arbitrarily\nchanged by changing only a single one of the numbers. On the other hand, the\nmedian has a much higher breakdown point. Changing a single number often has\nno effect at all, and when it does, the effect is limited to the range of the\ndata points in the middle of the ranking (i.e., those adjacent to rank\n\\\\(\\frac{n}{2}\\\\)). To change the median by an arbitrarily high amount, you\nneed to change half the observations. We call the median **robust** , and its\nbreakdown point is \\\\(\\frac{1}{2}\\\\). Remember that the median of a set of\nnumbers \\\\(y_1, y_2, ...\\\\) minimizes the sum \\\\(\\sum_j|y_j-\\beta_0|\\\\).\n\nTo achieve a higher degree of robustness against outliers, other choices than\nthe sum of squares 8.6 can be used as the objective of minimization. Among\nthese are:\n\n\\\\[ \\begin{align} R &= \\sum_j |\\varepsilon_j| & \\text{Least absolute\ndeviations} \\\\\\ R &= \\sum_j \\rho_s(\\varepsilon_j) & \\text{M-estimation} \\\\\\ R\n&= Q_{\\theta}\\left( \\\\{\\varepsilon_1^2, \\varepsilon_2^2,... \\\\} \\right) &\n\\text{LTS, LQS} \\\\\\ R &= \\sum_j w_j \\varepsilon_j^2 & \\text{general weighted\nregression} \\end{align} \\tag{8.8}\\\\]\n\nHere, \\\\(R\\\\) is the quantity to be minimized. The first choice in Equation\n8.8 is called **least absolute deviations** regression. It can be viewed as a\ngeneralization of the median. Although conceptually simple, and attractive on\nfirst sight, it is harder to minimize than the sum of squares, and it can be\nless stable and less efficient especially if the data are limited, or do not\nfit the model8. The second choice in Equation 8.8, also called\n**M-estimation** , uses a penalization function \\\\(\\rho_s\\\\) (least-squares\nregression is the special case with \\\\(\\rho_s(\\varepsilon)=\\varepsilon^2\\\\))\nthat looks like a quadratic function for a limited range of \\\\(\\varepsilon\\\\),\nbut has a smaller slope, flattens out, or even drops back to zero, for\nabsolute values \\\\(|\\varepsilon|\\\\) that are larger than the scale parameter\n\\\\(s\\\\). The intention behind this is to downweight the effect of outliers,\ni.e. of data points that have large residuals ([Huber 1964](16-chap.html#ref-\nHuber:AMS:1964)). A choice of \\\\(s\\\\) needs to be made and determines what is\ncalled an outlier. One can even drop the requirement that \\\\(\\rho_s\\\\) is\nquadratic around 0 (as long as its second derivative is positive), and a\nvariety of choices for the function \\\\(\\rho_s\\\\) have been proposed in the\nliterature. The aim is to give the estimator desirable statistical properties\n(say, bias and efficiency) when and where the data fit the model, but to limit\nor nullify the influence of those data points that do not, and to keep\ncomputations tractable.\n\n8 The [Wikipedia\narticle](https://en.wikipedia.org/wiki/Least_absolute_deviations) gives an\noverview.\n\n__\n\nQuestion 8.6\n\nPlot the graph of the function \\\\(\\rho_s(\\varepsilon)\\\\) proposed by Huber\n([1964](16-chap.html#ref-Huber:AMS:1964)) for M-estimators.\n\n__\n\nSolution\n\n__\n\nHuber’s paper defines, on Page 75:\n\n\\\\[ \\rho_s(\\varepsilon) = \\left\\\\{ \\begin{array}{cc} \\frac{1}{2}\\varepsilon^2,\n\\quad\\text{for }|\\varepsilon|< s\\\\\\ s|\\varepsilon|-\\frac{1}{2}s^2,\n\\quad\\text{for }|\\varepsilon|\\ge s\\\\\\ \\end{array} \\right. \\\\]\n\nThe graph produced by the below code is shown in Figure 8.8.\n\n    \n    \n    rho = function(x, s)\n      ifelse(abs(x) < s, x^2 / 2,  s * abs(x) - s^2 / 2)\n    \n    df = tibble(\n      x        = seq(-7, 7, length.out = 100),\n      parabola = x ^ 2 / 2,\n      Huber    = rho(x, s = 2))\n    \n    ggplot(reshape2::melt(df, id.vars = \"x\"),\n      aes(x = x, y = value, col = variable)) + geom_line()__\n\n[![](08-chap_files/figure-html/fig-countdata-\nmestimator-1.png)](08-chap_files/figure-html/fig-countdata-mestimator-1.png\n\"Figure 8.8: Graph of \\\\rho_s\\(\\\\varepsilon\\), for a choice of s=2.\")\n\nFigure 8.8: Graph of \\\\(\\rho_s(\\varepsilon)\\\\), for a choice of \\\\(s=2\\\\).\n\nChoice three in 8.8 generalises the least sum of squares method in yet another\nway. In **least quantile of squares** (LQS) regression, the the sum over the\nsquared residuals is replaced with a quantile, for instance, \\\\(Q_{50}\\\\), the\nmedian, or \\\\(Q_{90}\\\\), the 90%-quantile ([Peter J. Rousseeuw\n1987](16-chap.html#ref-Rousseeuw:1987)). In a variation thereof, **least\ntrimmed sum of squares** (LTS) regression, a sum of squared residuals is used,\nbut the sum extends not over all residuals, but only over the fraction\n\\\\(0\\le\\theta\\le1\\\\) of smallest residuals. The motivation in either case is\nthat outlying data points lead to large residuals, and as long as they are\nrare, they do not affect the quantile or the trimmed sum.\n\nHowever, there is a price: while the least sum of squares optimization 8.6 can\nbe done through straightforward linear algebra, more complicated iterative\noptimization algorithms are needed for M-estimation, LQS and LTS regression.\n\nThe final approach in 8.8 represents an even more complex way of weighting\ndown outliers. It assumes that we have some way of deciding what weight\n\\\\(w_j\\\\) we want to give to each observation, presumably down-weighting\noutliers. For instance, in Section 8.10.3, we will encounter the approach used\nby the **[DESeq2](https://bioconductor.org/packages/DESeq2/)** package, in\nwhich the leverage of each data point on the estimated \\\\(\\beta\\\\)s is\nassessed using a measure called Cook’s distance. For those data whose Cook’s\ndistance is deemed too large, the weight \\\\(w_j\\\\) is set to zero, whereas the\nother data points get \\\\(w_j=1\\\\). In effect, this means that the outlying\ndata points are discarded and that ordinary regression is performed on the\nothers. The extra computational effort of carrying the weights along is\nnegligible, and the optimization is still straightforward linear algebra.\n\nAll of these approaches to outlier robustness introduce a degree of\nsubjectiveness and rely on sufficient replication. The subjectiveness is\nreflected by the parameter choices that need to be made: \\\\(s\\\\) in 8.8 (2),\n\\\\(\\theta\\\\) in 8.8 (3), the weights in 8.8 (4). One scientist’s outlier may\nbe the Nobel prize of another. On the other hand, outlier removal is no remedy\nfor sloppy experiments and no justification for wishful thinking.\n\n__\n\nTask\n\nSearch the documentation of R and CRAN packages for implementations of the\nabove robust regression methods. A good place to start is the [CRAN task view\non robust statistical\nmethods](https://cran.r-project.org/web/views/Robust.html).\n\n## 8.8 Generalized linear models\n\nWe need to explore two more theoretical concepts before we can proceed to our\nnext application example. Equations of the form 8.5 model the expected value\nof the outcome variable, \\\\(y\\\\), as a linear function of the design matrix,\nand they are fit to data according to the least sum of squares criterion 8.6;\nor a robust variant thereof. We now want to generalize these assumptions.\n\n### 8.8.1 Modeling the data on a transformed scale\n\nWe already saw that it can be fruitful to consider the data not on the scale\nthat we obtained them, but after some transformation, for instance, the\nlogarithm. This idea can be generalized, since depending on the context, other\ntransformations are useful. For instance, the linear model 8.5 would not\ndirectly be useful for modeling outcomes that are bounded within an interval,\nsay, \\\\([0,1]\\\\) as an indicator of disease risk. In a linear model, the\nvalues of \\\\(y\\\\) cover, in principle, the whole real axis. However, if we\ntransform the expression on the right hand with a sigmoid function, for\ninstance, \\\\(f(y) = 1/(1+e^{-y})\\\\), then the range of this function9, is\nbounded between 0 and 1 and can be used to model such an outcome.\n\n9 It is called the logistic function ([Verhulst 1845](16-chap.html#ref-\nVerhulst:1845)), and the associated regression model is called **logistic\nregression**.\n\n### 8.8.2 Other error distributions\n\nThe other generalization regards the minimization criterion 8.6. In fact, this\ncriterion can be derived from a specific probabilistic model and the **maximum\nlikelihood** principle (we already encountered this in [Chapter\n2](02-chap.html)). To see this, consider the probabilistic model\n\n\\\\[ p(\\varepsilon_j) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\n\\left(-\\frac{\\varepsilon_j^2}{2\\sigma^2}\\right), \\tag{8.9}\\\\]\n\nthat is, we believe that the residuals follow a normal distribution with mean\n0 and standard deviation \\\\(\\sigma\\\\). Then it is plausible to demand from a\ngood model (i.e., from a good set of \\\\(\\beta\\\\)s) that these probabilities\nare large. Formally,\n\n\\\\[ \\prod_j p(\\varepsilon_j) \\quad\\to\\quad\\text{max}. \\tag{8.10}\\\\]\n\n__\n\nQuestion 8.7\n\nShow that the maximizing the likelihood 8.10 is equivalent to minimizing the\nsum of squared residuals 8.6.\n\n__\n\nSolution\n\n__\n\nInsert 8.9 into 8.10 and take the logarithm.\n\nLet’s revise some core concepts: the left hand side of Equation 8.10, i.e.,\nthe product of the probabilities of the residuals, is a function of both the\nmodel parameters \\\\(\\beta_1, \\beta_2, ...\\\\) and the data \\\\(y_1, y_2, ...\\\\);\ncall it \\\\(f(\\beta,y)\\\\). If we think of the model parameters \\\\(\\beta\\\\) as\ngiven and fixed, then the collapsed function \\\\(f(y)\\\\) simply indicates the\nprobability of the data. We could use it, for instance, to simulate data. If,\non the other hand, we consider the data as given, then \\\\(f(\\beta)\\\\) is a\nfunction of the model parameters, and it is called the _likelihood_. The\nsecond view is the one we take when we optimise 8.6 (and thus 8.10), and hence\nthe \\\\(\\beta\\\\)s obtained this way are what is called _maximum-likelihood\nestimates_.\n\n[![It is good to remember that, while we can use the normal distribution as a\nconvenient argument to motivate least sum of squares regression through the\nmaximum likelihood principle, the data do not have to be distributed according\nto the normal for least sum of squares regression to provide a useful result.\nIn fact, least sum of squares fitting often provides useful estimates for the\n\\\\betas even when the data are non-normal, although that depends on the\nspecific circumstances.](imgs/devil.png)](imgs/devil.png \"It is good to\nremember that, while we can use the normal distribution as a convenient\nargument to motivate least sum of squares regression through the maximum\nlikelihood principle, the data do not have to be distributed according to the\nnormal for least sum of squares regression to provide a useful result. In\nfact, least sum of squares fitting often provides useful estimates for the\n\\\\betas even when the data are non-normal, although that depends on the\nspecific circumstances.\")\n\nIt is good to remember that, while we can use the normal distribution as a\nconvenient argument to motivate least sum of squares regression through the\nmaximum likelihood principle, the data do not have to be distributed according\nto the normal for least sum of squares regression to provide a useful result.\nIn fact, least sum of squares fitting often provides useful estimates for the\n\\\\(\\beta\\\\)s even when the data are non-normal, although that depends on the\nspecific circumstances.\n\nThe generalization that we can now make is to use a different probabilistic\nmodel. We can use the densities of other distributions than the normal instead\nof Equation 8.9. For instance, to be able to deal with count data, we will use\nthe gamma-Poisson distribution.\n\n### 8.8.3 A generalized linear model for count data\n\nThe differential expression analysis in\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** uses a generalized\nlinear model of the form:\n\n\\\\[ \\begin{align} K_{ij} & \\sim \\text{GP}(\\mu_{ij}, \\alpha_i) \\\\\\ \\mu_{ij} &=\ns_j\\, q_{ij} \\\\\\ \\log_2(q_{ij}) &= \\sum_k x_{jk} \\beta_{ik}. \\end{align}\n\\tag{8.11}\\\\]\n\nLet us unpack this step by step. The counts \\\\(K_{ij}\\\\) for gene \\\\(i\\\\),\nsample \\\\(j\\\\) are modeled using a gamma-Poisson (GP) distribution with two\nparameters, the mean \\\\(\\mu_{ij}\\\\) and the dispersion \\\\(\\alpha_i\\\\). By\ndefault, the dispersion is different for each gene \\\\(i\\\\), but the same\nacross all samples, therefore it has no index \\\\(j\\\\). The second line in\nEquation 8.11 states that the mean is composed of a sample-specific size\nfactor \\\\(s_j\\\\)10 and \\\\(q_{ij}\\\\), which is proportional to the true\nexpected concentration of fragments for gene \\\\(i\\\\) in sample \\\\(j\\\\). The\nvalue of \\\\(q_{ij}\\\\) is given by the linear model in the third line via the\n_link function_ , \\\\(\\log_2\\\\). The design matrix \\\\((x_{jk})\\\\) is the same\nfor all genes (and therefore does not depend on \\\\(i\\\\)). Its rows \\\\(j\\\\)\ncorrespond to the samples, its columns \\\\(k\\\\) to the experimental factors. In\nthe simplest case, for a pairwise comparison, the design matrix has only two\ncolumns, one of them everywhere filled with 1 (corresponding to \\\\(\\beta_0\\\\)\nof Section 8.7.1) and the other one containing 0 or 1 depending on whether the\nsample belongs to one or the other group. The coefficients \\\\(\\beta_{ik}\\\\)\ngive the \\\\(\\log_2\\\\) fold changes for gene \\\\(i\\\\) for each column of the\ndesign matrix \\\\(X\\\\).\n\n10 The model can be generalized to use sample- **and** gene-dependent\nnormalization factors \\\\(s_{ij}\\\\). This is explained in the documentation of\nthe **[DESeq2](https://bioconductor.org/packages/DESeq2/)** package.\n\n## 8.9 Two-factor analysis of the pasilla data\n\nBesides the treatment with siRNA, which we have already considered in Section\n8.5, the **[pasilla](https://bioconductor.org/packages/pasilla/)** data have\nanother covariate, `type`, which indicates the type of sequencing that was\nperformed.\n\nWe saw in the exploratory data analysis (EDA) plots in Section 8.5.3 that the\nlatter had a considerable systematic effect on the data. Our basic analysis of\nSection 8.5 did not take this account, but we will do so now. This should help\nus get a more correct picture of which differences in the data are\nattributable to the treatment, and which are confounded – or masked – by the\nsequencing type.\n\n    \n    \n    pasillaTwoFactor = pasilla\n    design(pasillaTwoFactor) = formula(~ type + condition)\n    pasillaTwoFactor = DESeq(pasillaTwoFactor)__\n\nOf the two variables `type` and `condition`, the one of primary interest is\n`condition`, and in **[DESeq2](https://bioconductor.org/packages/DESeq2/)** ,\nthe convention is to put it at the end of the formula. This convention has no\neffect on the model fitting, but it helps simplify some of the subsequent\nresults reporting. Again, we access the results using the `results` function,\nwhich returns a dataframe with the statistics of each gene.\n\n    \n    \n    res2 = results(pasillaTwoFactor)\n    head(res2, n = 3)__\n    \n    \n    log2 fold change (MLE): condition treated vs untreated \n    Wald test p-value: condition treated vs untreated \n    DataFrame with 3 rows and 6 columns\n                 baseMean log2FoldChange     lfcSE       stat    pvalue      padj\n                <numeric>      <numeric> <numeric>  <numeric> <numeric> <numeric>\n    FBgn0000003  0.171569      0.6745518  3.871091  0.1742537  0.861666        NA\n    FBgn0000008 95.144079     -0.0406731  0.222215 -0.1830351  0.854770  0.951975\n    FBgn0000014  1.056572     -0.0849880  2.111821 -0.0402439  0.967899        NA\n\nIt is also possible to retrieve the \\\\(\\log_2\\\\) fold changes, p-values and\nadjusted p-values associated with the `type` variable. The function `results`\ntakes an argument `contrast` that lets users specify the name of the variable,\nthe level that corresponds to the numerator of the fold change and the level\nthat corresponds to the denominator of the fold change.\n\n    \n    \n    resType = results(pasillaTwoFactor,\n      contrast = c(\"type\", \"single\", \"paired\"))\n    head(resType, n = 3)__\n    \n    \n    log2 fold change (MLE): type single vs paired \n    Wald test p-value: type single vs paired \n    DataFrame with 3 rows and 6 columns\n                 baseMean log2FoldChange     lfcSE      stat    pvalue      padj\n                <numeric>      <numeric> <numeric> <numeric> <numeric> <numeric>\n    FBgn0000003  0.171569      -1.611546  3.871083 -0.416304  0.677188        NA\n    FBgn0000008 95.144079      -0.262255  0.220686 -1.188362  0.234691  0.543822\n    FBgn0000014  1.056572       3.290586  2.087243  1.576522  0.114905        NA\n\nSo what did we gain from this analysis that took into account `type` as a\nnuisance factor (sometimes also called, more politely, a _blocking factor_),\ncompared to the simple comparison between two groups of Section 8.5? Let us\nplot the p-values from both analyses against each other.\n\n    \n    \n    trsf = function(x) ifelse(is.na(x), 0, (-log10(x)) ^ (1/6))\n    ggplot(tibble(pOne = res$pvalue,\n                  pTwo = res2$pvalue),\n        aes(x = trsf(pOne), y = trsf(pTwo))) +\n        geom_hex(bins = 75) + coord_fixed() +\n        xlab(\"Single factor analysis (condition)\") +\n        ylab(\"Two factor analysis (type + condition)\") +\n        geom_abline(col = \"orange\")__\n\n[![](08-chap_files/figure-html/fig-countdata-\nscpres1res2-1.png)](08-chap_files/figure-html/fig-countdata-scpres1res2-1.png\n\"Figure 8.9: Comparison of p-values from the models with a single factor\n\\(condition\\) and with two factors \\(type + condition\\). The axes correspond\nto \\(-\\\\log_{10}p\\)^{\\\\frac{1}{6}}, an arbitrarily chosen monotonically\ndecreasing transformation that compresses the dynamic range of the p-values\nfor the purpose of visualization. We can see a trend for the joint\ndistribution to lie above the bisector, indicating that the small p-values in\nthe two-factor analysis are generally smaller than those in the one-factor\nanalysis.\")\n\nFigure 8.9: Comparison of p-values from the models with a single factor\n(condition) and with two factors (type + condition). The axes correspond to\n\\\\((-\\log_{10}p)^{\\frac{1}{6}}\\\\), an arbitrarily chosen monotonically\ndecreasing transformation that compresses the dynamic range of the p-values\nfor the purpose of visualization. We can see a trend for the joint\ndistribution to lie above the bisector, indicating that the small p-values in\nthe two-factor analysis are generally smaller than those in the one-factor\nanalysis.\n\nAs we can see in Figure 8.9, the p-values in the two-factor analysis are\nsimilar to those from the one-factor analysis, but are generally smaller. The\nmore sophisticated analysis has led to an, albeit modest, increase in power.\nWe can also see this by counting the number of genes that pass a certain\nsignificance threshold in each case:\n\n    \n    \n    compareRes = table(\n       `simple analysis` = res$padj < 0.1,\n       `two factor` = res2$padj < 0.1 )\n    addmargins( compareRes )__\n    \n    \n                   two factor\n    simple analysis FALSE TRUE  Sum\n              FALSE  6973  289 7262\n              TRUE     25 1036 1061\n              Sum    6998 1325 8323\n\nThe two-factor analysis found 1325 genes differentially expressed at an FDR\nthreshold of 10%, while the one-factor analysis found 1061. The two-factor\nanalysis has increased detection power. In general, the gain can be even much\nlarger, or also smaller, depending on the data. The proper choice of the model\nrequires informed adaptation to the experimental design and data quality.\n\n__\n\nQuestion 8.8\n\n_Why_ do we detect fewer significant genes when we do not take into account\nthe `type` variable? More generally, what does this mean about the benefit of\ntaking into account (or not) blocking factors?\n\n__\n\nSolution\n\n__\n\nWithout modeling the blocking factor, the variability in the data that is due\nto it has to be absorbed by the \\\\(\\varepsilon\\\\)s. This means that they are\ngenerally larger than in the model with the blocking factor. The higher level\nof noise leads to higher uncertainty in the \\\\(\\beta\\\\)-estimates. On the\nother hand, the model with the blocking factor has more parameters that need\nto be estimated. In statistical parlance, the fit has fewer “degrees of\nfreedom”. Both of these effects are counteracting, and which of them prevails,\nand which of the modeling choices yields more or fewer significant results\ndepends on the data.\n\n__\n\nQuestion 8.9\n\nWhat is confounding? Can _not_ taking into account a blocking factor also lead\nto the detection of _more_ genes?\n\n__\n\nSolution\n\n__\n\nYes. Imagine the variables `condition` and `type` were not as nicely balanced\nas they are, but partially or fully confounded. In that case, differences in\nthe data due to `type` could be attributed to `condition` if a model is fit\nthat does not make it possible to absorb them in the `type`-effect.\nScientifically, such an experiment (and analysis) can be quite an\nembarrassment.\n\n__\n\nQuestion 8.10\n\nConsider a paired experimenal design, say, 10 different cell lines each with\nand without drug treatment. How should this be analyzed?\n\n__\n\nSolution\n\n__\n\nIf we just did a simple two-group comparison (treated versus untreated) many\nof the treatment effects would probably go under in the strong cell line to\ncell line variation. However, we can set up a _paired_ analysis simply by\nadding cell line identity as a blocking factor. (Cell line is then really an R\n_factor_ with 10 different levels, rather than just a 0 vs 1 indicator\nvariable as with the variables that we looked at so far; R’s linear modeling\nfacilities, and also **[DESeq2](https://bioconductor.org/packages/DESeq2/)** ,\nhave no problem dealing with that.)\n\n__\n\nQuestion 8.11\n\nWhat can you do if you suspect there are “hidden” factors that affect your\ndata, but they are not documented? (Sometimes, such undocumented covariates\nare also called **batch effects**.)\n\n__\n\nSolution\n\n__\n\nThere are methods that try to identify blocking factors in an unsupervised\nfashion, see e.g., Leek and Storey ([2007](16-chap.html#ref-LeekStorey:2007);\n[Stegle et al. 2010](16-chap.html#ref-Stegle:2010)).\n\n## 8.10 Further statistical concepts\n\n### 8.10.1 Sharing of dispersion information across genes\n\nWe already saw an explanation of Bayesian (or empirical Bayes) analysis in\n[Figure 6.16](06-chap.html#fig-testing-sunexplode). The idea is to use\nadditional information to improve our estimates (information that we either\nknown a priori, or have from analysis of other, but similar data). This idea\nis particularly useful if the data per se are relatively noisy.\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** uses an empirical\nBayes approach for the estimation of the dispersion parameters (the\n\\\\(\\alpha\\\\)s in the third line of Equation 8.11) and, optionally, the\nlogarithmic fold changes (the \\\\(\\beta\\\\)s). The priors are, in both cases,\ntaken from the distributions of the maximum-likelihood estimates (MLEs) across\nall genes. It turns out that both of these distributions are uni-modal; in the\ncase of the \\\\(\\beta\\\\)s, with a peak at around 0, in the case of the\n\\\\(\\alpha\\\\), at a particular value, the typical dispersion. The empirical\nBayes machinery then shrinks each per-gene MLE towards that peak, by an amount\nthat depends on the sharpness of the empirical prior distribution and the\nprecision of the ML estimate (the better the latter, the less shrinkage will\nbe done). The mathematics are explained in ([Michael I. Love, Huber, and\nAnders 2014](16-chap.html#ref-LoveDESeq2)), and Figure 8.10 visualizes the\napproach for the \\\\(\\beta\\\\)s.\n\n__\n\nTask\n\nAdvanced: check the R code that produces Figure 8.10.\n\n[![](08-chap_files/figure-html/fig-countdata-\nposterior-1.png)](08-chap_files/figure-html/fig-countdata-posterior-1.png\n\"Figure 8.10 \\(a\\): \")\n\n(a)\n\n[![](08-chap_files/figure-html/fig-countdata-\nposterior-2.png)](08-chap_files/figure-html/fig-countdata-posterior-2.png\n\"Figure 8.10 \\(b\\): \")\n\n(b)\n\nFigure 8.10: Shrinkage estimation of logarithmic fold change estimates by use\nof an empirical prior in\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)**. Two genes with\nsimilar mean count and MLE logarithmic fold change are highlighted in green\nand blue. The normalized counts for these genes (a) reveal low dispersion for\nthe gene in blue and high dispersion for the gene in green. In (b), the\ndensity plots are shown of the normalized likelihoods (solid lines) and of the\nposteriors (dashed lines) for the green and blue gene. In addition, the solid\nblack line shows the prior estimated from the MLEs of all genes. Due to the\nhigher dispersion of the green gene, its likelihood is wider and less sharp\n(indicating less information), and the prior has more influence on its\nposterior than in the case of the blue gene.\n\n### 8.10.2 Count data transformations\n\nFor testing for differential expression we operate on raw counts and use\ndiscrete distributions. For other downstream analyses – e.g., for\nvisualization or clustering – it might however be useful to work with\ntransformed versions of the count data.\n\nMaybe the most obvious choice of transformation is the logarithm. However,\nsince count values for a gene can become zero, some advocate the use of\n**pseudocounts** , i.e., transformations of the form\n\n\\\\[ y = \\log_2(n + 1)\\quad\\mbox{or more generally,}\\quad y = \\log_2(n + n_0),\n\\tag{8.12}\\\\]\n\nwhere \\\\(n\\\\) represents the count values and \\\\(n_0\\\\) is a somehow chosen\npositive constant.\n\nLet’s look at two alternative approaches that offer more theoretical\njustification, and a rational way of choosing the parameter equivalent to\n\\\\(n_0\\\\) above. One method incorporates priors on the sample differences, and\nthe other uses the concept of variance-stabilizing transformations.\n\n#### Variance-stabilizing transformation\n\nWe already explored **variance-stabilizing transformations** in [Section\n4.4.4](04-chap.html#sec-mixtures-vst). There we computed a piece-wise linear\ntransformation for a discrete set of random variables ([Figure\n4.26](04-chap.html#fig-pcwlin-1)) and also saw how to use calculus to derive a\nsmooth variance-stabilizing transformation for a gamma-Poisson mixture. These\ncomputations are implemented in the\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** package ([Anders and\nHuber 2010](16-chap.html#ref-Anders:2010:GB)):\n\n    \n    \n    vsp = varianceStabilizingTransformation(pasilla)__\n\nLet us explore the effect of this on the data, using the first sample as an\nexample, and comparing it to the \\\\(\\log_2\\\\) transformation; the plot is\nshown in Figure 8.11 and is made with the following:\n\n    \n    \n    j = 1\n    ggplot(\n      tibble(\n        counts = rep(assay(pasilla)[, j], 2),\n        transformed = c(\n          assay(vsp)[, j],\n          log2(assay(pasilla)[, j])\n          ),\n        transformation = rep(c(\"VST\", \"log2\"), each = nrow(pasilla))\n      ),\n      aes(x = counts, y = transformed, col = transformation)) +\n      geom_line() + xlim(c(0, 600)) + ylim(c(0, 9))__\n\n[![](08-chap_files/figure-html/fig-countdata-\nplotvst-1.png)](08-chap_files/figure-html/fig-countdata-plotvst-1.png\n\"Figure 8.11: Graph of variance-stabilizing transformation for the data of one\nof the samples, and for comparison also of the \\\\log_2 transformation. The\nvariance-stabilizing transformation has finite values and finite slope even\nfor counts close to zero, whereas the slope of \\\\log_2 becomes very steep for\nsmall counts and is undefined for counts of zero. For large counts, the two\ntransformation are essentially the same.\")\n\nFigure 8.11: Graph of variance-stabilizing transformation for the data of one\nof the samples, and for comparison also of the \\\\(\\log_2\\\\) transformation.\nThe variance-stabilizing transformation has finite values and finite slope\neven for counts close to zero, whereas the slope of \\\\(\\log_2\\\\) becomes very\nsteep for small counts and is undefined for counts of zero. For large counts,\nthe two transformation are essentially the same.\n\n#### Regularized logarithm (rlog) transformation\n\nThere is a second way to come up with a data transformation. It is\nconceptually distinct from variance stabilization. Instead, it builds upon the\nshrinkage estimation that we already explored in Section 8.10.1. It works by\ntransforming the original count data to a \\\\(\\log_2\\\\)-like scale by fitting a\n“trivial” model with a separate term for each sample and a prior distribution\non the coefficients which is estimated from the data. The fitting employs the\nsame regularization as what we discussed in Section 8.10.1. The transformed\ndata \\\\(q_{ij}\\\\) are defined by the third line of Equation 8.11, where the\ndesign matrix \\\\(\\left(x_{jk}\\right)\\\\) is of size \\\\(K \\times (K+1)\\\\) – here\n\\\\(K\\\\) is the number of samples– and has the form\n\n\\\\[\nX=\\left(\\begin{array}{ccccc}1&1&0&0&\\cdot\\\\\\1&0&1&0&\\cdot\\\\\\1&0&0&1&\\cdot\\\\\\\\\\cdot&\\cdot&\\cdot&\\cdot&\\cdot\\end{array}\\right).\n\\tag{8.13}\\\\]\n\nWithout priors, this design matrix would lead to a non-unique solution,\nhowever the addition of a prior on non-intercept \\\\(\\beta\\\\)s allows for a\nunique solution to be found.\n\nIn **[DESeq2](https://bioconductor.org/packages/DESeq2/)** , this\nfunctionality is implemented in the function `rlogTransformation`. It turns\nout in practice that the rlog transformation is also approximately variance-\nstabilizing, but in contrast to the variance-stabilizing transformation of\nSection 8.10.2 it deals better with data in which the size factors of the\ndifferent samples are very distinct.\n\n__\n\nQuestion 8.12\n\nPlot mean against standard deviation between replicates for the shifted\nlogarithm 8.12, the regularized log transformation and the variance-\nstabilizing transformation.\n\n__\n\nSolution\n\n__\n\nSee Figure 8.12.\n\n    \n    \n    library(\"vsn\")\n    rlp = rlogTransformation(pasilla)\n    \n    msd = function(x)\n      meanSdPlot(x, plot = FALSE)$gg + ylim(c(0, 1)) +\n         theme(legend.position = \"none\")\n    \n    gridExtra::grid.arrange(\n      msd(log2(counts(pasilla, normalized = TRUE) + 1)) +\n        ylab(\"sd(log2)\"),\n      msd(assay(vsp)) + ylab(\"sd(vst)\"),\n      msd(assay(rlp)) + ylab(\"sd(rlog)\"),\n      ncol = 3\n    )__\n\n[![](08-chap_files/figure-html/fig-countdata-\nmeansd-1.png)](08-chap_files/figure-html/fig-countdata-meansd-1.png\n\"Figure 8.12: Per-gene standard deviation \\(sd, taken across samples\\) against\nthe rank of the mean, for the shifted logarithm \\\\log_2\\(n+1\\), the variance-\nstabilizing transformation \\(vst\\) and the rlog. Note that for the leftmost\n\\\\approx 2,500 genes, the counts are all zero, and hence their standard\ndeviation is zero. The mean-sd dependence becomes more interesting for genes\nwith non-zero counts. Note also the high value of the standard deviation for\ngenes that are weakly detected \\(but not with all zero counts\\) when the\nshifted logarithm is used, and compare to the relatively flat shape of the\nmean-sd relationship for the variance-stabilizing transformation.\")\n\nFigure 8.12: Per-gene standard deviation (sd, taken across samples) against\nthe rank of the mean, for the shifted logarithm \\\\(\\log_2(n+1)\\\\), the\nvariance-stabilizing transformation (vst) and the rlog. Note that for the\nleftmost \\\\(\\approx\\\\) 2,500 genes, the counts are all zero, and hence their\nstandard deviation is zero. The mean-sd dependence becomes more interesting\nfor genes with non-zero counts. Note also the high value of the standard\ndeviation for genes that are weakly detected (but not with all zero counts)\nwhen the shifted logarithm is used, and compare to the relatively flat shape\nof the mean-sd relationship for the variance-stabilizing transformation.\n\n### 8.10.3 Dealing with outliers\n\nThe data sometimes contain isolated instances of very large counts that are\napparently unrelated to the experimental or study design, and which may be\nconsidered outliers. There are many reasons why outliers can arise, including\nrare technical or experimental artifacts, read mapping problems in the case of\ngenetically differing samples, and genuine, but rare biological events. In\nmany cases, users appear primarily interested in genes that show a consistent\nbehaviour, and this is the reason why by default, genes that are affected by\nsuch outliers are set aside by `DESeq`. The function calculates, for every\ngene and for every sample, a diagnostic test for outliers called **Cook’s\ndistance**([Cook 1977](16-chap.html#ref-Cook1977Detection)). Cook’s distance\nis a measure of how much a single sample is influencing the fitted\ncoefficients for a gene, and a large value of Cook’s distance is intended to\nindicate an outlier count.\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** automatically flags\ngenes with Cook’s distance above a cutoff and sets their p-values and adjusted\np-values to `NA`.\n\nThe default cutoff depends on the sample size and number of parameters to be\nestimated; **[DESeq2](https://bioconductor.org/packages/DESeq2/)** uses the\n\\\\(99\\%\\\\) quantile of the \\\\(F(p,m-p)\\\\) distribution (with \\\\(p\\\\) the\nnumber of parameters including the intercept and \\\\(m\\\\) number of samples).\n\n__\n\nQuestion 8.13\n\nCheck the documentation to see how the default cutoff can be changed, and how\nthe outlier removal functionality can be disabled altogether. How can the\ncomputed Cook’s distances be accessed?\n\nWith many degrees of freedom – i.e., many more samples than number of\nparameters to be estimated – it might be undesirable to remove entire genes\nfrom the analysis just because their data include a single count outlier. An\nalternate strategy is to replace the outlier counts with the trimmed mean over\nall samples, adjusted by the size factor for that sample. This approach is\nconservative: it will not lead to false positives, as it replaces the outlier\nvalue with the value predicted by the null hypothesis.\n\n### 8.10.4 Tests of \\\\(\\log_2\\\\) fold change above or below a threshold\n\nLet’s come back to the point we raised in Section 8.6: how to build into the\ntests our requirement that we want to detect effects that have a strong enough\nsize, as opposed to ones that are statistically significant, but very small.\nTwo arguments to the `results` function allow for threshold-based Wald tests:\n`lfcThreshold`, which takes a numeric of a non-negative threshold value, and\n`altHypothesis`, which specifies the kind of test. It can take one of the\nfollowing four values, where \\\\(\\beta\\\\) is the \\\\(\\log_2\\\\) fold change\nspecified by the `name` argument, and \\\\(\\theta\\\\) represents `lfcThreshold`:\n\n  * `greater`: \\\\(\\beta > \\theta\\\\)\n\n  * `less`: \\\\(\\beta < (-\\theta)\\\\)\n\n  * `greaterAbs`: \\\\(\\left|\\beta\\right| > \\theta\\\\) (two-tailed test)\n\n  * `lessAbs`: \\\\(|\\beta| < \\theta\\\\) (p-values are the maximum of the upper and lower tests)\n\nThese are demonstrated in the following code and visually by MA-plots in\nFigure 8.13. (Note that the `plotMA` method, which is defined in the\n**[DESeq2](https://bioconductor.org/packages/DESeq2/)** package, uses base\ngraphics.)\n\n    \n    \n    par(mfrow = c(4, 1), mar = c(2, 2, 1, 1))\n    myMA = function(h, v, theta = 0.5) {\n      plotMA(pasilla, lfcThreshold = theta, altHypothesis = h,\n             ylim = c(-2.5, 2.5))\n      abline(h = v * theta, col = \"dodgerblue\", lwd = 2)\n    }\n    myMA(\"greaterAbs\", c(-1, 1))\n    myMA(\"lessAbs\",    c(-1, 1))\n    myMA(\"greater\",          1)\n    myMA(\"less\",         -1   )__\n\n[![](08-chap_files/figure-html/fig-countdata-\nlfcThresh-1.png)](08-chap_files/figure-html/fig-countdata-lfcThresh-1.png\n\"Figure 8.13: MA-plots of tests of \\\\log_2 fold change with respect to a\nthreshold value. From top to bottom, the tests are for altHypothesis =\n\"greaterAbs\", \"lessAbs\", \"greater\", and \"less\".\")\n\nFigure 8.13: MA-plots of tests of \\\\(\\log_2\\\\) fold change with respect to a\nthreshold value. From top to bottom, the tests are for `altHypothesis =\n\"greaterAbs\"`, `\"lessAbs\"`, `\"greater\"`, and `\"less\"`.\n\nTo produce the results tables instead of MA plots, the same arguments as to\n`plotMA` (except `ylim`) would be provided to the `results` function.\n\n## 8.11 Summary of this chapter\n\nWe have seen how to analyze count tables from high-throughput sequencing (and\nanalagous data types) for differential abundance. We built upon the powerful\nand elegant framework of linear models. In this framework, we can analyze a\nbasic two-groups comparison as well as more complex multifactorial designs, or\nexperiments with covariates that have more than two levels or are continuous.\nIn ordinary linear models, the sampling distribution of the data around the\nexpected value is assumed to be independent and normal, with zero mean and the\nsame variances. For count data, the distributions are discrete and tend to be\nskewed (asymmetric) with highly different variances across the dynamic range.\nWe therefore employed a generalization of ordinary linear models, called\ngeneralized linear models (GLMs), and in particular considered gamma-Poisson\ndistributed data with dispersion parameters that we needed to estimate from\nthe data.\n\nSince the sampling depth is typically different for different sequencing runs\n(replicates), we need to estimate the effect of this variable parameter and\ntake it into account in our model. We did this through the size factors\n\\\\(s_i\\\\). Often this part of the analysis is called _normalization_ (the term\nis not particularly descriptive, but unfortunately it is now well-settled in\nthe literature).\n\nFor designed experiments, the number of replicates is (and should be) usually\ntoo small to estimate the dispersion parameter (and perhaps even the model\ncoefficients) from the data for each gene alone. Therefore we use shrinkage or\nempirical Bayes techniques, which promise large gains in precision for\nrelatively small costs of bias.\n\nWhile GLMs let us model the data on their original scale, sometimes it is\nuseful to transform the data to a scale where the data are more homoskedastic\nand fill out the range more uniformly – for instance, for plotting the data,\nor for subjecting them to general purpose clustering, dimension reduction or\nlearning methods. To this end, we saw the variance stabilizing transformation.\n\nA major, and quite valid critique of differential expression testing such as\nexercised here is that the null hypothesis – the effect size is exactly zero –\nis almost never true, and therefore our approach does not provide consistent\nestimates of what the differentially expressed gene are. In practice, this may\nbe overcome by considering effect size as well as statistical significance.\nMoreover, we saw how to use “banded” null hypotheses.\n\n## 8.12 Further reading\n\n  * The **[DESeq2](https://bioconductor.org/packages/DESeq2/)** method is explained in the paper by Michael I. Love, Huber, and Anders ([2014](16-chap.html#ref-LoveDESeq2)), and practical aspects of the software in the package vignette. See also the **[edgeR](https://bioconductor.org/packages/edgeR/)** package and paper ([Robinson, McCarthy, and Smyth 2009](16-chap.html#ref-edgeR:Robinson:2009)) for a related approach.\n\n  * A classic textbook on robust regression and outlier detection is the book by Peter J. Rousseeuw and Leroy ([1987](16-chap.html#ref-Rousseeuw:RobustBook:1987)). For more recent developments the [CRAN task view on Robust Statistical Methods](https://cran.r-project.org/web/views/Robust.html) is a good starting point.\n\n  * The Bioconductor RNA-Seq workflow at <https://www.bioconductor.org/help/workflows/rnaseqGene> ([Michael I. Love et al. 2015](16-chap.html#ref-BiocRNASeqWorkflow)) covers a number of issues related specifically to RNA-Seq that we have sidestepped here.\n\n  * An extension of the generalized linear model that we saw to detecting alternative exon usage from RNA-Seq data is presented in the **[DEXSeq](https://bioconductor.org/packages/DEXSeq/)** paper ([Anders, Reyes, and Huber 2012](16-chap.html#ref-Reyes:GnomeResearch:2012)), and applications of these ideas to biological discovery were described by Reyes et al. ([2013](16-chap.html#ref-Reyes:PNAS:2013)) and Reyes and Huber ([2017](16-chap.html#ref-Reyes:NAR:2017)).\n\n  * For some sequencing-based assays, such as RIP-Seq, CLIP-Seq, the biological analysis goal boils down to testing whether the ratio of _input_ and _immunoprecipitate_ (IP) has changed between conditions. Mike Love’s post on the Bioconductor forum provides a clear and quick how-to: <https://support.bioconductor.org/p/61509>.\n\n## 8.13 Exercises\n\n__\n\nExercise 8.1\n\n**Depletion of small p-values.** Consider the following simple generative\nmodel for a histogram of p-values that shows a depletion of small p-values. In\nFigure 8.14, p-values are shown from a differential expression analysis (in\nthis case, simple \\\\(t\\\\)-tests) in the absence of an association with the\ntested two-level categorical variable `groups`. While the histogram is\napproximately uniform for `x1`, small p-values are depleted for `x2`. This is\nbecause the batch (encoded by the eponymous variable), which is orthogonal to\n`groups` and balanced, introduces additional variability that inflates the\ndenominator of the test statistic.\n\n    \n    \n    library(\"magrittr\")\n    ng = 10000\n    ns = 12\n    x1 = x2 = matrix(rnorm(ns * ng), ncol = ns, nrow= ng)\n    group = factor(letters[1 + seq_len(ns) %% 2])  %T>% print __\n    \n    \n     [1] b a b a b a b a b a b a\n    Levels: a b\n    \n    \n    batch = factor(ifelse(seq_len(ns) <= ns/2, \"B1\", \"B2\")) %T>% print __\n    \n    \n     [1] B1 B1 B1 B1 B1 B1 B2 B2 B2 B2 B2 B2\n    Levels: B1 B2\n    \n    \n    table(group, batch)__\n    \n    \n         batch\n    group B1 B2\n        a  3  3\n        b  3  3\n    \n    \n    x2[, batch==\"B2\"] = x2[, batch==\"B2\"] + 2 * rnorm(ng)\n    pvals = rbind(\n      cbind(type = \"x1\", genefilter::rowttests(x1, fac = group)),\n      cbind(type = \"x2\", genefilter::rowttests(x2, fac = group)))\n    ggplot(pvals, aes(x = p.value)) + \n      geom_histogram(binwidth = 0.02, boundary = 0) +\n      facet_grid(type ~ .)__\n\nReplace the \\\\(t\\\\)-test by a linear model, first, one with only `group` as a\nfactor, second, one with `group + batch` (in R’s formula language). Show that\nthe histogram of p-values for the coefficient of `group` is uniform in both\ncases, `x1` and `x2`.\n\n[![](08-chap_files/figure-html/fig-countdata-\nexbatch-1.png)](08-chap_files/figure-html/fig-countdata-exbatch-1.png\n\"Figure 8.14: p-values for the tests performed on x1 and x2 \\(see code\\).\")\n\nFigure 8.14: p-values for the tests performed on `x1` and `x2` (see code).\n\n__\n\nExercise 8.2\n\n**edgeR.** Do the analyses of Section 8.5 with the\n**[edgeR](https://bioconductor.org/packages/edgeR/)** package and compare the\nresults: make a scatterplot of the \\\\(\\log_{10}\\\\) p-values, pick some genes\nwhere there are large differences, and visualize the raw data to see what is\ngoing on. Based on this can you explain the differences?\n\n__\n\nExercise 8.3\n\n**Robustness.** Write a\n**[shiny](https://cran.r-project.org/web/packages/shiny/)** app that performs\nlinear regression on an example \\\\((x, y)\\\\) dataset (for instance, from the\n`mtcars` data) and displays the data as well as the fitted line. Add a widget\nthat lets you move one of the points in \\\\(x\\\\)\\- and/or \\\\(y\\\\)\\- direction\nin a wide range (extending a few times outside the original data range). Add a\nradio buttons widget that lets you choose between `lm`, `rlm` and `lqs` with\nits different choices of `method` (the latter two are in the\n**[MASS](https://cran.r-project.org/web/packages/MASS/)** package). Bonus: add\nfunctions from the\n**[robustbase](https://cran.r-project.org/web/packages/robustbase/)** package.\n\n__\n\nSolution\n\n__\n\nCode for the file `ui.R` in the app:\n\n    \n    \n    library(\"shiny\")\n    shinyUI(fluidPage(\n      titlePanel(\"Breakdown\"),\n      sidebarLayout(\n        sidebarPanel(     # select oulier shift\n          sliderInput(\"shift\", \"Outlier:\", min = 0, max = 100, value = 0),\n          radioButtons(\"method\", \"Method:\",\n                       c(\"Non-robust least squares\" = \"lm\",\n                         \"M-estimation\" = \"rlm\"))\n        ),\n        mainPanel(       # show fit\n          plotOutput(\"regPlot\")\n        )\n      )\n    ))__\n\nCode for the file `server.R` in the app:\n\n    \n    \n    library(\"shiny\")\n    library(\"ggplot2\")\n    library(\"MASS\")\n    shinyServer(function(input, output) {\n      output$regPlot = renderPlot({\n        whpt = 15\n        mtcars_new = mtcars\n        mtcars_new$mpg[whpt] = mtcars_new$mpg[whpt] + input$shift\n        reg = switch(input$method,\n          lm = lm(mpg ~ disp, data = mtcars_new),\n          rlm = rlm(mpg ~ disp, data = mtcars_new),\n          stop(\"Unimplemented method:\", input$method)\n        )\n        ggplot(mtcars_new, aes(x = disp, y = mpg)) + geom_point() +\n          geom_abline(intercept = reg$coefficients[\"(Intercept)\"],\n                      slope = reg$coefficients[\"disp\"], col = \"blue\")\n      })\n    })__\n\nOf course you can add many more features.\n\nAnders, Simon, and Wolfgang Huber. 2010. “Differential Expression Analysis for\nSequence Count Data.” _Genome Biology_ 11: R106.\n<http://genomebiology.com/2010/11/10/R106>.\n\nAnders, Simon, Alejandro Reyes, and Wolfgang Huber. 2012. “Detecting\ndifferential usage of exons from RNA-Seq data.” _Genome Research_ 22 (10):\n2008–17.\n\nBrooks, Angela N, Li Yang, Michael O Duff, Kasper D Hansen, Jung W Park,\nSandrine Dudoit, Steven E Brenner, and Brenton R Graveley. 2011. “Conservation\nof an RNA Regulatory Map Between Drosophila and Mammals.” _Genome Research_ ,\n193–202. <https://doi.org/10.1101/gr.108662.110>.\n\nCook, R. Dennis. 1977. “Detection of Influential Observation in Linear\nRegression.” _Technometrics_.\n\nHuber, Peter J. 1964. “Robust Estimation of a Location Parameter.” _The Annals\nof Mathematical Statistics_ 35: 73–101.\n\nLeek, Jeffrey T., and John D. Storey. 2007. “Capturing heterogeneity in gene\nexpression studies by surrogate variable analysis.” _PLoS Genetics_ 3 (9):\n1724–35.\n\nLove, Michael I., Simon Anders, Vladislav Kim, and Wolfgang Huber. 2015. “RNA-\nSeq Workflow: Gene-Level Exploratory Analysis and Differential Expression.”\n_F1000Research_ 4 (1070). <https://doi.org/10.12688/f1000research.7035.1>.\n\nLove, Michael I, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation\nof Fold Change and Dispersion for RNA-seq Data with DESeq2.” _Gnome Biology_\n15 (12): 1–21.\n\nOzsolak, Fatih, and Patrice M Milos. 2011. “RNA sequencing: advances,\nchallenges and opportunities.” _Nature Reviews Genetics_ 12: 87–98.\n\nReyes, Alejandro, Simon Anders, Robert J. Weatheritt, Toby J. Gibson, Lars M.\nSteinmetz, and Wolfgang Huber. 2013. “Drift and Conservation of Differential\nExon Usage Across Tissues in Primate Species.” _Proceedings of the National\nAcademy of Sciences_ 110 (38): 15377–82.\n<https://doi.org/10.1073/pnas.1307202110>.\n\nReyes, Alejandro, and Wolfgang Huber. 2017. “Alternative Start and Termination\nSites of Transcription Drive Most Transcript Isoform Differences Across Human\nTissues.” _Nucleic Acids Research_ 46 (2): 582–92.\n<https://doi.org/10.1093/nar/gkx1165>.\n\nRobinson, M. D., D. J. McCarthy, and G. K. Smyth. 2009. “edgeR: A Bioconductor\nPackage for Differential Expression Analysis of Digital Gene Expression Data.”\n_Bioinformatics_ 26 (1): 139–40.\n<https://doi.org/10.1093/bioinformatics/btp616>.\n\nRousseeuw, Peter J. 1987. “Silhouettes: A Graphical Aid to the Interpretation\nand Validation of Cluster Analysis.” _Journal of Computational and Applied\nMathematics_ 20: 53–65.\n\nRousseeuw, Peter J., and Annick M. Leroy. 1987. _Robust Regression and Outlier\nDetection_. Wiley. <https://doi.org/10.1002/0471725382>.\n\nStegle, O., L. Parts, R. Durbin, and J. Winn. 2010. “A Bayesian framework to\naccount for complex non-genetic factors in gene expression levels greatly\nincreases power in eQTL studies.” _PLoS Computational Biology_ 6 (5):\ne1000770.\n\nSteijger, T., J. F. Abril, P. G. Engstrom, F. Kokocinski, T. J. Hubbard, R.\nGuigo, J. Harrow, et al. 2013. “Assessment of transcript reconstruction\nmethods for RNA-seq.” _Nature Methods_ 10 (12): 1177–84.\n\nVerhulst, Pierre-François. 1845. “Recherches mathématiques Sur La Loi\nd’accroissement de La Population.” _Nouveaux Mémoires de l’Académie Royale Des\nSciences Et Belles-Lettres de Bruxelles_ 18: 1–42.\n\nPage built at 01:33 on 2025-09-01 using R version 4.5.1 (2025-06-13)\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["msmb.css"],"toc":true,"output-file":"08-chap.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}