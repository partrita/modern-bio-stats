<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; 8.1 이 장의 목표 – Modern Statistics for Modern Biology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./09-chap.html" rel="next">
<link href="./07-chap.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7bf12d62aa84b4fa538b342f1416a45b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="msmb.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./08-chap.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">8.1 이 장의 목표</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modern Statistics for Modern Biology</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">홈</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">주제: 이질성</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">1.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">2.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">3.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">4.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">5.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">6.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">7.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-chap.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">8.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">9.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">10.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">11.1 이 장의 목표</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">12.1 Goals for this chapter</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">13.1 Goals for this chapter</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">14-chap.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">15-chap.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-chap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">16-chap.html</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#몇-가지-핵심-개념" id="toc-몇-가지-핵심-개념" class="nav-link active" data-scroll-target="#몇-가지-핵심-개념"><span class="header-section-number">10.1</span> 8.2 몇 가지 핵심 개념</a></li>
  <li><a href="#카운트-데이터count-data" id="toc-카운트-데이터count-data" class="nav-link" data-scroll-target="#카운트-데이터count-data"><span class="header-section-number">10.2</span> 8.3 카운트 데이터(Count data)</a>
  <ul class="collapse">
  <li><a href="#카운트-데이터의-과제들" id="toc-카운트-데이터의-과제들" class="nav-link" data-scroll-target="#카운트-데이터의-과제들"><span class="header-section-number">10.2.1</span> 8.3.1 카운트 데이터의 과제들</a></li>
  <li><a href="#rna-seq-유전자-구조-스플라이싱-이소형은-어떠한가요" id="toc-rna-seq-유전자-구조-스플라이싱-이소형은-어떠한가요" class="nav-link" data-scroll-target="#rna-seq-유전자-구조-스플라이싱-이소형은-어떠한가요"><span class="header-section-number">10.2.2</span> 8.3.2 RNA-Seq: 유전자 구조, 스플라이싱, 이소형은 어떠한가요?</a></li>
  </ul></li>
  <li><a href="#카운트-데이터-모델링" id="toc-카운트-데이터-모델링" class="nav-link" data-scroll-target="#카운트-데이터-모델링"><span class="header-section-number">10.3</span> 8.4 카운트 데이터 모델링</a>
  <ul class="collapse">
  <li><a href="#분산dispersion" id="toc-분산dispersion" class="nav-link" data-scroll-target="#분산dispersion"><span class="header-section-number">10.3.1</span> 8.4.1 분산(Dispersion)</a></li>
  <li><a href="#normalization" id="toc-normalization" class="nav-link" data-scroll-target="#normalization"><span class="header-section-number">10.3.2</span> 8.4.2 Normalization</a></li>
  </ul></li>
  <li><a href="#a-basic-analysis" id="toc-a-basic-analysis" class="nav-link" data-scroll-target="#a-basic-analysis"><span class="header-section-number">10.4</span> 8.5 A basic analysis</a>
  <ul class="collapse">
  <li><a href="#example-dataset-the-pasilla-data" id="toc-example-dataset-the-pasilla-data" class="nav-link" data-scroll-target="#example-dataset-the-pasilla-data"><span class="header-section-number">10.4.1</span> 8.5.1 Example dataset: the pasilla data</a></li>
  <li><a href="#deseq2-방법" id="toc-deseq2-방법" class="nav-link" data-scroll-target="#deseq2-방법"><span class="header-section-number">10.4.2</span> 8.5.2 <strong>DESeq2</strong> 방법</a></li>
  <li><a href="#결과-탐색하기" id="toc-결과-탐색하기" class="nav-link" data-scroll-target="#결과-탐색하기"><span class="header-section-number">10.4.3</span> 8.5.3 결과 탐색하기</a></li>
  <li><a href="#exporting-the-results" id="toc-exporting-the-results" class="nav-link" data-scroll-target="#exporting-the-results"><span class="header-section-number">10.4.4</span> 8.5.4 Exporting the results</a></li>
  </ul></li>
  <li><a href="#critique-of-default-choices-and-possible-modifications" id="toc-critique-of-default-choices-and-possible-modifications" class="nav-link" data-scroll-target="#critique-of-default-choices-and-possible-modifications"><span class="header-section-number">10.5</span> 8.6 Critique of default choices and possible modifications</a>
  <ul class="collapse">
  <li><a href="#the-few-changes-assumption" id="toc-the-few-changes-assumption" class="nav-link" data-scroll-target="#the-few-changes-assumption"><span class="header-section-number">10.5.1</span> 8.6.1 The few changes assumption</a></li>
  <li><a href="#point-like-null-hypothesis" id="toc-point-like-null-hypothesis" class="nav-link" data-scroll-target="#point-like-null-hypothesis"><span class="header-section-number">10.5.2</span> 8.6.2 Point-like null hypothesis</a></li>
  </ul></li>
  <li><a href="#multi-factor-designs-and-linear-models" id="toc-multi-factor-designs-and-linear-models" class="nav-link" data-scroll-target="#multi-factor-designs-and-linear-models"><span class="header-section-number">10.6</span> 8.7 Multi-factor designs and linear models</a>
  <ul class="collapse">
  <li><a href="#what-is-a-multifactorial-design" id="toc-what-is-a-multifactorial-design" class="nav-link" data-scroll-target="#what-is-a-multifactorial-design"><span class="header-section-number">10.6.1</span> 8.7.1 What is a multifactorial design?</a></li>
  </ul></li>
  <li><a href="#차등-풍부도differential-abundance" id="toc-차등-풍부도differential-abundance" class="nav-link" data-scroll-target="#차등-풍부도differential-abundance"><span class="header-section-number">10.7</span> 8.6 차등 풍부도(Differential abundance)</a></li>
  <li><a href="#선형-모델" id="toc-선형-모델" class="nav-link" data-scroll-target="#선형-모델"><span class="header-section-number">10.8</span> 8.7 선형 모델</a>
  <ul class="collapse">
  <li><a href="#요인-설계-및-상호작용" id="toc-요인-설계-및-상호작용" class="nav-link" data-scroll-target="#요인-설계-및-상호작용"><span class="header-section-number">10.8.1</span> 8.7.1 요인 설계 및 상호작용</a></li>
  <li><a href="#노이즈와-반복-실험replicates은-어떠한가요" id="toc-노이즈와-반복-실험replicates은-어떠한가요" class="nav-link" data-scroll-target="#노이즈와-반복-실험replicates은-어떠한가요"><span class="header-section-number">10.8.2</span> 8.7.2 노이즈와 반복 실험(Replicates)은 어떠한가요?</a></li>
  <li><a href="#분산-분석analysis-of-variance" id="toc-분산-분석analysis-of-variance" class="nav-link" data-scroll-target="#분산-분석analysis-of-variance"><span class="header-section-number">10.8.3</span> 8.7.3 분산 분석(Analysis of variance)</a></li>
  <li><a href="#강건성robustness" id="toc-강건성robustness" class="nav-link" data-scroll-target="#강건성robustness"><span class="header-section-number">10.8.4</span> 8.7.4 강건성(Robustness)</a></li>
  </ul></li>
  <li><a href="#generalized-linear-models" id="toc-generalized-linear-models" class="nav-link" data-scroll-target="#generalized-linear-models"><span class="header-section-number">10.9</span> 8.8 Generalized linear models</a>
  <ul class="collapse">
  <li><a href="#modeling-the-data-on-a-transformed-scale" id="toc-modeling-the-data-on-a-transformed-scale" class="nav-link" data-scroll-target="#modeling-the-data-on-a-transformed-scale"><span class="header-section-number">10.9.1</span> 8.8.1 Modeling the data on a transformed scale</a></li>
  <li><a href="#other-error-distributions" id="toc-other-error-distributions" class="nav-link" data-scroll-target="#other-error-distributions"><span class="header-section-number">10.9.2</span> 8.8.2 Other error distributions</a></li>
  <li><a href="#a-generalized-linear-model-for-count-data" id="toc-a-generalized-linear-model-for-count-data" class="nav-link" data-scroll-target="#a-generalized-linear-model-for-count-data"><span class="header-section-number">10.9.3</span> 8.8.3 A generalized linear model for count data</a></li>
  </ul></li>
  <li><a href="#two-factor-analysis-of-the-pasilla-data" id="toc-two-factor-analysis-of-the-pasilla-data" class="nav-link" data-scroll-target="#two-factor-analysis-of-the-pasilla-data"><span class="header-section-number">10.10</span> 8.9 Two-factor analysis of the pasilla data</a></li>
  <li><a href="#further-statistical-concepts" id="toc-further-statistical-concepts" class="nav-link" data-scroll-target="#further-statistical-concepts"><span class="header-section-number">10.11</span> 8.10 Further statistical concepts</a>
  <ul class="collapse">
  <li><a href="#sharing-of-dispersion-information-across-genes" id="toc-sharing-of-dispersion-information-across-genes" class="nav-link" data-scroll-target="#sharing-of-dispersion-information-across-genes"><span class="header-section-number">10.11.1</span> 8.10.1 Sharing of dispersion information across genes</a></li>
  <li><a href="#count-data-transformations" id="toc-count-data-transformations" class="nav-link" data-scroll-target="#count-data-transformations"><span class="header-section-number">10.11.2</span> 8.10.2 Count data transformations</a></li>
  <li><a href="#dealing-with-outliers" id="toc-dealing-with-outliers" class="nav-link" data-scroll-target="#dealing-with-outliers"><span class="header-section-number">10.11.3</span> 8.10.3 Dealing with outliers</a></li>
  <li><a href="#tests-of-_2-fold-change-above-or-below-a-threshold" id="toc-tests-of-_2-fold-change-above-or-below-a-threshold" class="nav-link" data-scroll-target="#tests-of-_2-fold-change-above-or-below-a-threshold"><span class="header-section-number">10.11.4</span> 8.10.4 Tests of \(_2\) fold change above or below a threshold</a></li>
  </ul></li>
  <li><a href="#summary-of-this-chapter" id="toc-summary-of-this-chapter" class="nav-link" data-scroll-target="#summary-of-this-chapter"><span class="header-section-number">10.12</span> 8.11 Summary of this chapter</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">10.13</span> 8.12 Further reading</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">10.14</span> 8.13 Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">8.1 이 장의 목표</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><img src="imgs/xkcd-1725-linear_regression_2x.png" class="img-fluid"></p>
<p>생명공학의 많은 측정 장치들은 분자의 대규모 병렬 샘플링과 카운팅에 기초합니다. 한 가지 예로 고처리량 DNA 시퀀싱(high-throughput DNA sequencing)이 있습니다. 그 응용 분야는 데이터 출력 방식에 따라 크게 두 가지 주요 클래스로 나뉩니다: 첫 번째 경우, 관심 있는 출력은 서열 그 자체이며, 아마도 그들의 다형성(polymorphisms)이나 이전에 보았던 다른 서열들과의 차이일 것입니다. 두 번째 경우, 서열 그 자체는 어느 정도 잘 이해되어 있으며(예를 들어, 잘 조립되고 어노테이션된 게놈을 가지고 있음), 우리의 관심은 샘플 내에서 서로 다른 서열 영역들이 얼마나 풍부하게 존재하는지에 있습니다.</p>
<p>예를 들어, <strong>RNA-Seq</strong> (<a href="16-chap.html#ref-OzsolakMilos">Ozsolak and Milos 2011</a>)에서는 세포 집단이나 조직에서 발견되는 RNA 분자들의 서열을 분석합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="엄밀히 말하면, 우리는 RNA의 서열을 분석하는 것이 아니라 역전사를 통해 얻은 상보적 DNA(cDNA)의 서열을 분석합니다. 전체 RNA 풀은 폴리-A 선택(poly-A selection)이나 리보솜 RNA 고갈(ribosomal RNA depletion)과 같은 생화학적 수단을 통해 관심 있는 하위 집합(예: 메신저 RNA)으로 줄어들 수 있습니다. 단일 세포와 대량의 세포를 분석할 수 있게 해주는 RNA-Seq의 민감한 변체들이 존재합니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>엄밀히 말하면, 우리는 RNA의 서열을 분석하는 것이 아니라 역전사를 통해 얻은 상보적 DNA(cDNA)의 서열을 분석합니다. 전체 RNA 풀은 폴리-A 선택(poly-A selection)이나 리보솜 RNA 고갈(ribosomal RNA depletion)과 같은 생화학적 수단을 통해 관심 있는 하위 집합(예: 메신저 RNA)으로 줄어들 수 있습니다. 단일 세포와 대량의 세포를 분석할 수 있게 해주는 RNA-Seq의 민감한 변체들이 존재합니다.</figcaption>
</figure>
</div>
<p>엄밀히 말하면, 우리는 RNA의 서열을 분석하는 것이 아니라 역전사를 통해 얻은 상보적 DNA(cDNA)의 서열을 분석합니다. 전체 RNA 풀은 폴리-A 선택(poly-A selection)이나 리보솜 RNA 고갈(ribosomal RNA depletion)과 같은 생화학적 수단을 통해 관심 있는 하위 집합(예: 메신저 RNA)으로 줄어들 수 있습니다. 단일 세포와 대량의 세포를 분석할 수 있게 해주는 RNA-Seq의 민감한 변체들이 존재합니다.</p>
<p><strong>ChIP-Seq</strong>에서는 특정 DNA 결합 단백질에 결합된 DNA 영역(면역 침전을 통해 선택됨)의 서열을 분석합니다. <strong>RIP-Seq</strong>에서는 특정 RNA 결합 단백질에 결합된 RNA 분자나 그 영역을, <strong>DNA-Seq</strong>에서는 게놈 DNA의 서열을 분석하며 이질적인 세포 집단에서의 유전적 변이의 유병률(예: 종양의 클론 구성)에 관심을 가집니다. 고처리량 염색질 구조 포착(<strong>HiC</strong>)에서는 DNA의 3차원 공간적 배치를 매핑하는 것을 목표로 하며, <strong>유전적 스크리닝</strong>(변동을 위해 RNAi나 CRISPR-Cas9 라이브러리를 사용하고 리드아웃을 위해 고처리량 시퀀싱을 사용하는 경우)에서는 유전자 넉다운(knockdown), 넉아웃(knockout) 또는 수정에 따른 세포의 증식이나 생존에 관심을 가집니다. 마이크로바이옴 분석에서는 복잡한 미생물 서식지에 있는 서로 다른 미생물 종의 풍부도를 연구합니다.</p>
<p>이상적으로는 샘플 내의 관심 있는 <em>모든</em> 분자를 시퀀싱하고 세고 싶을 것입니다. 일반적으로 이는 불가능합니다: 생화학적 프로토콜은 100% 효율적이지 않으며, 일부 분자나 중간 생성물은 과정 중에 소실됩니다. 게다가 대개 그럴 필요조차 없습니다. 대신, 우리는 _통계적 표본(statistical sample)_을 시퀀싱하고 셉니다. 표본 크기는 분석되는 서열 풀의 복잡성에 따라 달라질 것이며, 수만 개에서 수십억 개에 이를 수 있습니다. 이러한 데이터의 <em>샘플링</em> 특성은 이를 분석할 때 중요합니다. 우리는 샘플링이 충분히 대표성이 있어 흥미로운 경향과 패턴을 식별할 수 있기를 희망합니다.</p>
<p>이 장에서 우리는 RNA-Seq과 같은 고처리량 시퀀싱 응용 분야의 카운트 데이터(count data)에 익숙해질 것입니다. 데이터를 해석하기 위해 데이터의 근간이 되는 샘플링 프로세스를 이해하고 모델링할 것입니다. 우리의 주요 목표는 서로 다른 조건(예: <em>처리되지 않은</em> 군 대 <em>처리된</em> 군)의 샘플들 사이에서 체계적인 변화를 감지하고 정량화하는 것이며, 이때의 과제는 그러한 체계적인 변화를 동일한 조건 내에서의 샘플링 변동 및 실험적 가변성과 구별하는 것입니다. 이를 위해 다음과 같은 필요한 통계적 개념과 도구들을 갖출 것입니다:</p>
<ul>
<li><p>다요인 설계(multifactorial designs), 선형 모델 및 분산 분석(analysis of variance)</p></li>
<li><p>일반화 선형 모델(generalized linear models)</p></li>
<li><p>강건성(robustness) 및 이상치 탐지</p></li>
<li><p>수축 추정(shrinkage estimation)</p></li>
</ul>
<p>사실 이러한 개념들은 훨씬 더 넓은 범위의 응용 분야를 가집니다: 이들은 어떤 실험적 공변량의 함수로서 노이즈가 섞인 데이터의 차이를 감지하고자 하는 다른 유형의 데이터에도 적용될 수 있습니다. 특히 일반화 선형 모델의 프레임워크는 상당히 추상적이고 일반적이지만, 이는 많은 서로 다른 데이터 유형에 맞춰 조정될 수 있다는 장점이 있습니다. 따라서 우리는 바퀴를 새로 발명할 필요 없이 관련된 광범위한 도구와 진단 기능을 즉시 즐길 수 있습니다.</p>
<p>보너스로, <a href="05-chap.html">5장</a>과 <a href="07-chap.html">7장</a>에서 보았던 비지도 학습 방법들에 데이터를 적합하게 만들고 데이터 시각화를 더 쉽게 만들어주는 데이터 변환에 대해서도 살펴볼 것입니다.</p>
<section id="몇-가지-핵심-개념" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="몇-가지-핵심-개념"><span class="header-section-number">10.1</span> 8.2 몇 가지 핵심 개념</h2>
<p>시작하기 전에 몇 가지 주요 용어를 정리해 봅시다.</p>
<ul>
<li><p>_시퀀싱 라이브러리(sequencing library)_는 시퀀싱 장비의 입력으로 사용되는 DNA 분자들의 집합입니다.</p></li>
<li><p>_단편(Fragments)_은 시퀀싱되는 분자들입니다. 현재 가장 널리 사용되는 기술1은 길이가 약 300~1000 뉴클레오타이드인 분자만 처리할 수 있기 때문에, 이들은 관심 있는 (일반적으로 더 긴) DNA나 cDNA 분자를 단편화하여 얻어집니다.</p></li>
<li><p><strong>리드(read)</strong>는 단편으로부터 얻은 서열입니다. 현재 기술로 리드는 단편 전체가 아니라 그 단편의 한쪽 끝 또는 양쪽 끝만을 포괄하며, 양쪽의 리드 길이는 최대 약 150 뉴클레오타이드입니다.</p></li>
</ul>
<p>1 <a href="https://www.illumina.com/techniques/sequencing.html" class="uri">https://www.illumina.com/techniques/sequencing.html</a>를 참조하십시오.</p>
<p>2 특정 응용 분야의 경우, 가장 적절한 접근 방식과 선택에 대해 최신 문헌을 확인하는 것이 가장 좋습니다.</p>
<p>3 예: RNA-Seq의 경우, 게놈과 그 전사체에 대한 어노테이션.</p>
<p>시퀀싱과 카운팅 사이에는 함께 속하는 서열들을 모으는 중요한 <em>집계(aggregation)</em> 또는 군집화 단계가 포함됩니다: 예를 들어, (RNA-Seq에서) 동일한 유전자에 속하는 모든 리드나, (ChIP-Seq에서) 동일한 결합 영역에 속하는 모든 리드를 모으는 것입니다. 실험의 목적에 따라 이에 대한 여러 접근 방식과 선택 사항이 있습니다2. 방법에는 참조 서열(reference sequence)에 대한 명시적인 정렬(alignment) 또는 해시 기반 매핑3, 그리고 리드들의 참조 독립적인 서열 유사성 기반 군집화가 포함됩니다 — 특히 메타제노믹스나 메타전사체학에서와 같이 명확한 참조 서열이 없는 경우에 그렇습니다. 우리는 서로 다른 대립유전자(alleles)나 이소형(isoforms)을 별도로 고려할지, 아니면 이들을 하나의 동등 클래스(equivalence class)로 병합할지 선택해야 합니다. 단순함을 위해 이 장에서는 특정 응용 분야에 따라 다양한 대상이 될 수 있음에도 불구하고 이러한 운영상의 집계 단위에 대해 _유전자(gene)_라는 용어를 사용하겠습니다.</p>
</section>
<section id="카운트-데이터count-data" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="카운트-데이터count-data"><span class="header-section-number">10.2</span> 8.3 카운트 데이터(Count data)</h2>
<p>예시 데이터 세트를 불러와 봅시다. 이 데이터는 실험 데이터 패키지인 <strong><a href="https://bioconductor.org/packages/pasilla/">pasilla</a></strong>에 들어 있습니다.</p>
<pre><code>fn = system.file("extdata", "pasilla_gene_counts.tsv",
                  package = "pasilla", mustWork = TRUE)
counts = as.matrix(read.csv(fn, sep = "\t", row.names = "gene_id"))__</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="여기서 보여주는 코드에서는 pasilla 패키지와 함께 제공되는 파일을 찾기 위해 system.file 함수를 사용합니다. 여러분 자신의 데이터로 작업할 때는 counts 행렬을 직접 준비해야 할 것입니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>여기서 보여주는 코드에서는 pasilla 패키지와 함께 제공되는 파일을 찾기 위해 system.file 함수를 사용합니다. 여러분 자신의 데이터로 작업할 때는 counts 행렬을 직접 준비해야 할 것입니다.</figcaption>
</figure>
</div>
<p>여기서 보여주는 코드에서는 <code>system.file</code> 함수를 사용하여 <strong><a href="https://bioconductor.org/packages/pasilla/">pasilla</a></strong> 패키지와 함께 제공되는 파일을 찾습니다. 여러분 자신의 데이터로 작업할 때는 <code>counts</code> 행렬을 직접 준비해야 할 것입니다.</p>
<p>데이터는 탭으로 구분된 파일에 직사각형 표 형태로 저장되어 있으며, 이를 <code>counts</code> 행렬로 읽어 들였습니다.</p>
<pre><code>dim(counts)__


[1] 14599     7


counts[ 2000+(0:3), ]__


            untreated1 untreated2 untreated3 untreated4 treated1 treated2
FBgn0020369       3387       4295       1315       1853     4884     2133
FBgn0020370       3186       4305       1824       2094     3525     1973
FBgn0020371          1          0          1          1        1        0
FBgn0020372         38         84         29         28       63       28
            treated3
FBgn0020369     2165
FBgn0020370     2120
FBgn0020371        0
FBgn0020372       27</code></pre>
<p>이 행렬은 각 샘플에서 각 유전자에 대해 관찰된 리드의 수를 집계합니다. 우리는 이를 <strong>카운트 테이블(count table)</strong>이라고 부릅니다. 유전자에 해당하는 14,599개의 행과 샘플에 해당하는 7개의 열로 이루어져 있습니다. 파일에서 데이터를 불러올 때 좋은 타당성 검사는 데이터의 일부를 출력해 보는 것인데, 위에서 했던 것처럼 아주 앞부분뿐만 아니라 중간의 무작위 지점도 확인해 보는 것이 좋습니다.</p>
<p>이 표는 정수 값들의 행렬입니다: 행렬의 \(i\)번째 행과 \(j\)번째 열의 값은 샘플 \(j\)에서 유전자 \(i\)에 매핑된 리드가 몇 개인지를 나타냅니다. 이 장에서 논의할 통계적 샘플링 모델은 이 값들이 시퀀싱 리드의 직접적이고 “가공되지 않은(raw)” 카운트라는 사실에 의존합니다 — 정규화된 카운트나 포괄된 염기쌍의 수와 같은 파생된 수치가 아닙니다. 그러한 수치들은 무의미한 결과로 이어질 뿐입니다.</p>
<section id="카운트-데이터의-과제들" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="카운트-데이터의-과제들"><span class="header-section-number">10.2.1</span> 8.3.1 카운트 데이터의 과제들</h3>
<p>우리가 이러한 카운트 데이터로 극복해야 할 과제들은 무엇일까요?</p>
<ul>
<li><p>데이터는 0부터 수백만까지 넓은 동적 범위를 가집니다. 동적 범위의 서로 다른 부분에서 데이터의 분산, 그리고 더 일반적으로 분포의 형태가 매우 다릅니다. 우리는 <strong>이분산성(heteroskedasticity)</strong>이라고 불리는 이러한 현상을 고려해야 합니다.</p></li>
<li><p>데이터는 음수가 아닌 정수이며, 그 분포는 대칭적이지 않습니다 — 따라서 정규 분포나 로그-정규 분포 모델은 적합도가 낮을 수 있습니다.</p></li>
<li><p>우리는 체계적인 샘플링 편향을 이해하고 이를 보정해야 합니다. 혼란스럽게도 이를 흔히 <strong>정규화(normalization)</strong>라고 부릅니다. 예로는 실험의 전체 시퀀싱 깊이(두 라이브러리에서 한 유전자의 실제 풍부도가 같더라도, 시퀀싱된 전체 리드 수에 따라 해당 유전자에 대해 서로 다른 리드 수를 예상함), 또는 서로 다른 샘플링 확률(생물학적 샘플 내에서 두 유전자의 실제 풍부도가 같더라도 길이, GC 함량, 2차 구조, 결합 파트너와 같은 생물물리학적 특성이 다르면 서로 다른 리드 수를 예상함) 등이 있습니다.</p></li>
<li><p>우리는 샘플링의 확률적 특성뿐만 아니라 다른 확률적 실험 변동의 원인들도 이해해야 합니다. 생물학적 샘플 수가 많은 연구의 경우 이는 대개 간단하며, 재표본 추출이나 순열 기반 방법에 의존할 수도 있습니다. 그러나 설계된 실험(designed experiments)의 경우 표본 크기가 제한적인 경향이 있습니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="실험(experiments)과 연구(studies) 사이에는 중요한 개념적 및 실무적 차이가 있습니다 – 13장을 참조하십시오."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>실험(experiments)과 연구(studies) 사이에는 중요한 개념적 및 실무적 차이가 있습니다 – 13장을 참조하십시오.</figcaption>
</figure>
</div>
<p>실험(experiments)과 연구(studies) 사이에는 중요한 개념적 및 실무적 차이가 있습니다 — <a href="13-chap.html">13장</a>을 참조하십시오.</p>
<p>예를 들어, pasilla 데이터에는 <em>처리되지 않은</em> 군에서 4개의 반복(replicates)이, <em>처리된</em> 군에서 3개의 반복이 있습니다. 이는 재표본 추출이나 순열 기반 방법이 충분한 검정력을 갖지 못함을 의미합니다. 진행하기 위해 우리는 분포에 대한 가정을 해야 합니다. 본질적으로 그러한 가정들이 하는 일은 소수의 분포 매개변수로부터 분포의 꼬리 부분에 있는 드문 사건의 확률 — 즉, 비정상적으로 높거나 낮은 카운트 — 을 계산할 수 있게 해주는 것입니다.</p>
<ul>
<li>하지만 그것만으로도 부족한 경우가 많은데, 특히 <strong>분산(dispersion)</strong> 매개변수4의 추정은 작은 표본 크기에서 어렵습니다. 이 경우, 비슷한 위치에 있는 유전자들은 비슷한 분산을 가진다는 것과 같은 추가적인 가정을 해야 합니다. 이를 유전자 간 정보 공유(sharing of information across genes)라고 하며, 8.10.1절에서 다시 다룰 것입니다.</li>
</ul>
<p>4 분포는 다양한 방식으로 매개변수화될 수 있습니다. 종종 매개변수들은 위치(location)의 척도와 분산(dispersion)의 척도에 대응합니다. 친숙한 위치의 척도는 평균이고, 친숙한 분산의 척도는 분산(또는 표준 편차)이지만, 일부 분포의 경우 다른 척도들이 사용되기도 합니다.</p>
</section>
<section id="rna-seq-유전자-구조-스플라이싱-이소형은-어떠한가요" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="rna-seq-유전자-구조-스플라이싱-이소형은-어떠한가요"><span class="header-section-number">10.2.2</span> 8.3.2 RNA-Seq: 유전자 구조, 스플라이싱, 이소형은 어떠한가요?</h3>
<p>진핵생물의 유전자는 복잡합니다: 대부분의 유전자는 여러 개의 엑손으로 구성되며, mRNA는 스플라이싱(splicing)이라는 과정을 통해 엑손들이 연결되어 만들어집니다. 대안적 스플라이싱(alternative splicing)과 전사 시작 및 종료 지점의 다양한 선택은 동일한 유전자 좌위(locus)로부터 여러 개의 대안적 이소형(alternative isoforms) 생성을 가능하게 합니다. 고처리량 시퀀싱을 사용하여 전사체의 이소형 구조를 탐지하는 것이 가능합니다. 특정 이소형에 특징적인 단편들로부터 이소형 특이적 풍부도를 탐지하는 것도 가능합니다. 전체 길이 이소형의 비교적 짧은 단편들만을 제공하는 현재의 RNA-Seq 데이터로는 전체 길이 이소형 구조와 풍부도를 조립하고 분리해내는 것이 어려운 경향이 있습니다 (<a href="16-chap.html#ref-SteijgerBertone:2013">Steijger et al.&nbsp;2013</a>). 이 때문에 국소적인 판단(예: 개별 엑손의 포함 또는 제외)만을 내리는 좀 더 겸손한 목표를 가진 절차들이 공식화되었으며 (<a href="16-chap.html#ref-Reyes:GnomeResearch:2012">Anders, Reyes, and Huber 2012</a>), 이들이 더 강건(robust)할 수 있습니다. 미래의 기술들은 전체 길이 전사체의 서열을 분석할 것으로 기대할 수 있습니다.</p>
</section>
</section>
<section id="카운트-데이터-모델링" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="카운트-데이터-모델링"><span class="header-section-number">10.3</span> 8.4 카운트 데이터 모델링</h2>
<section id="분산dispersion" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="분산dispersion"><span class="header-section-number">10.3.1</span> 8.4.1 분산(Dispersion)</h3>
<p>유전자 1에 해당하는 단편 \(n_1\)개, 유전자 2에 해당하는 단편 \(n_2\)개 등을 포함하며 전체 라이브러리 크기가 \(n = n_1+n_2+\)인 시퀀싱 라이브러리를 생각해 봅시다. 우리는 라이브러리를 시퀀싱하여 무작위로 샘플링된 \(r\)개 단편의 정체를 결정합니다. 이 숫자들의 크기 정도를 살펴보면 반가운 단순화가 가능해집니다:</p>
<ul>
<li><p>유전자의 수는 수만 개입니다.</p></li>
<li><p>\(n\)의 값은 준비에 사용된 세포의 양에 따라 달라지지만, 벌크(bulk) RNA-Seq의 경우 수십억 또는 수조 개에 달할 것입니다.</p></li>
<li><p>리드 수 \(r\)은 보통 수천만 개이며, 따라서 \(n\)보다 훨씬 작습니다.</p></li>
</ul>
<p>이로부터 우리는 주어진 리드가 \(i\)번째 유전자에 매핑될 확률이 \(p_i=n_i/n\)이며, 이것이 다른 모든 리드에 대한 결과와 거의 독립적이라는 결론을 내릴 수 있습니다. 따라서 우리는 \(i\)번째 유전자에 대한 리드 수를 포아송 분포로 모델링할 수 있으며, 이때 포아송 프로세스의 _비율(rate)_은 \(i\)번째 유전자에 대한 단편의 초기 비율인 \(p_i\)와 \(r\)의 곱, 즉 \(_i=rp_i\)가 됩니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="원칙적으로 우리는 여기서 비복원 추출과 다항 분포를 고려해야 합니다: i번째 유전자에 대한 리드를 샘플링할 확률은 동일한 유전자와 다른 유전자들이 이미 몇 번 샘플링되었는지에 달려 있습니다. 그러나 이러한 의존성은 무시할 수 있을 정도로 작아서 무시할 것입니다. 이는 n이 r보다 훨씬 크고, 유전자의 수가 많으며, 각 n_i가 n에 비해 작기 때문입니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>원칙적으로 우리는 여기서 비복원 추출과 다항 분포를 고려해야 합니다: i번째 유전자에 대한 리드를 샘플링할 확률은 동일한 유전자와 다른 유전자들이 이미 몇 번 샘플링되었는지에 달려 있습니다. 그러나 이러한 의존성은 무시할 수 있을 정도로 작아서 무시할 것입니다. 이는 n이 r보다 훨씬 크고, 유전자의 수가 많으며, 각 n_i가 n에 비해 작기 때문입니다.</figcaption>
</figure>
</div>
<p>원칙적으로 우리는 여기서 <strong>비복원 추출(sampling without replacement)</strong>과 다항 분포를 고려해야 합니다: \(i\)번째 유전자에 대한 리드를 샘플링할 확률은 동일한 유전자와 다른 유전자들이 이미 몇 번 샘플링되었는지에 달려 있습니다. 그러나 이러한 의존성은 무시할 수 있을 정도로 작아서 무시할 것입니다. 이는 \(n\)이 \(r\)보다 훨씬 크고, 유전자의 수가 많으며, 각 \(n_i\)가 \(n\)에 비해 작기 때문입니다.</p>
<p>실제로 우리는 대개 단일 라이브러리 내의 리드 카운트를 모델링하는 데 관심이 있는 것이 아니라, 라이브러리 간의 카운트를 비교하는 데 관심이 있습니다. 즉, 우리는 서로 다른 생물학적 조건 사이에서 — 예를 들어 약물 처리를 한 세포주와 하지 않은 동일한 세포주 사이에서 — 보이는 차이가 “우연히” 예상되는 것보다 큰지, 즉 생물학적 반복 사이에서도 예상할 수 있는 것보다 큰지 알고 싶어 합니다. 경험적으로 반복 실험들은 포아송 분포가 예측하는 것보다 더 많이 변하는 것으로 나타납니다. 직관적으로 일어나는 일은 \(p_i\)와 따라서 \(_i\)가 생물학적 반복 사이에서도 변한다는 것입니다. 아마도 세포가 자란 온도가 약간 달랐거나, 첨가된 약물의 양이 몇 퍼센트 차이 났거나, 배양 시간이 약간 더 길었을 수 있습니다. 이를 설명하기 위해 우리는 그 위에 또 다른 모델링 층을 추가해야 합니다. 우리는 이미 <a href="04-chap.html">4장</a>에서 계층 모델과 혼합물을 보았습니다. <strong>감마-포아송</strong>(일명 음이항) 분포가 우리의 모델링 요구에 적합하다는 것이 밝혀졌습니다. 평균과… 모두를 나타내는 단일 \(\) 대신… variance –, this distribution has two parameters. In principle, these can be different for each gene, and we will come back to the question of how to estimate them from the data.</p>
</section>
<section id="normalization" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="normalization"><span class="header-section-number">10.3.2</span> 8.4.2 Normalization</h3>
<p>Often, there are systematic biases that have affected the data generation and are worth taking into account. Unfortunately, the term <strong>normalization</strong> is commonly used for that aspect of the analysis, even though it is misleading: it has nothing to do with the normal distribution, norms in a vector space, or normal vectors. Rather, what we aim for is identifying the nature and estimating the magnitude of systematic biases, and take them into account in our model-based analysis of the data.</p>
<p>The most important systematic bias stems from variations in the total number of reads in each sample. If we have more reads for one library than in another, then we might assume that, everything else being equal, the counts are proportional to each other with some proportionality factor \(s\). Naively, we could propose that a decent estimate of \(s\) for each sample is simply given by the sum of the counts of all genes. However, it turns out that we can do better. To understand this, a toy example helps.</p>
<p><a href="08-chap_files/figure-html/fig-countdata- normalization-1.png" title="Figure 8.1: Size factor estimation. The points correspond to hypothetical genes whose counts in two samples are indicated by their x- and y-coordinates. The lines indicate two different ways of size factor estimation explained in the text."><img src="08-chap_files/figure-html/fig-countdata- normalization-1.png" class="img-fluid"></a></p>
<p>Figure 8.1: Size factor estimation. The points correspond to hypothetical genes whose counts in two samples are indicated by their \(x\)- and \(y\)-coordinates. The lines indicate two different ways of size factor estimation explained in the text.</p>
<p>Consider a dataset with 5 genes and two samples as displayed in Figure 8.1. If we estimate \(s\) for each of the two samples by its sum of counts, then the slope of the blue line represents their ratio. According to this, gene C is down-regulated in sample 2 compared to sample 1, while the other genes are all somewhat up-regulated. If we now instead estimate \(s\) such that their ratios correspond to the red line, then we will still conclude that gene C is down-regulated, while the other genes are unchanged. The second version is more parsimonious and is often preferred by scientists. The slope of the red line can be obtained by robust regression. This is what the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> method does.</p>
<p>__</p>
<p>Question 8.1</p>
<p>For the example dataset <code>count</code> of Section 8.3, how does the output of <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> ’s <code>estimateSizeFactorsForMatrix</code> compare to what you get by simply taking the column sums?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>See Figure 8.2, produced by the code below. In this case, there is not much difference, the results are nearly proportional.</p>
<pre><code>library("tibble")
library("ggplot2")
library("DESeq2")
ggplot(tibble(
  `size factor` = estimateSizeFactorsForMatrix(counts),
  `sum` = colSums(counts)), aes(x = `size factor`, y = `sum`)) +
  geom_point()__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-sfvssum-1.png &quot;Figure 8.2: Size factors versus sums for the pasilla data.&quot;"><img src="08-chap_files/figure-html/fig-countdata- sfvssum-1.png" class="img-fluid"></a></p>
<p>Figure 8.2: Size factors versus sums for the pasilla data.</p>
<p>__</p>
<p>Task</p>
<p>Locate the R sources for this book and have a look at the code that produces Figure 8.1.</p>
<p>__</p>
<p>Question 8.2</p>
<p>Plot the mean-variance relationship for the biological replicates in the pasilla dataset.</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>See Figure 8.3, produced by the following code.</p>
<pre><code>library("matrixStats")
sf = estimateSizeFactorsForMatrix(counts)
ncounts  = counts / matrix(sf,
   byrow = TRUE, ncol = ncol(counts), nrow = nrow(counts))
uncounts = ncounts[, grep("^untreated", colnames(ncounts)),
                     drop = FALSE]
ggplot(tibble(
        mean = rowMeans(uncounts),
        var  = rowVars( uncounts)),
     aes(x = log(mean), y = log(var))) +
  geom_hex() + coord_fixed() + theme(legend.position = "none") +
  geom_abline(slope = 1:2, color = c("forestgreen", "red"))__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-varmean-1.png &quot;Figure 8.3: Variance versus mean for the (size factor adjusted) counts data. The axes are logarithmic. Also shown are lines through the origin with slopes 1 (green) and 2 (red).&quot;"><img src="08-chap_files/figure-html/fig-countdata- varmean-1.png" class="img-fluid"></a></p>
<p>Figure 8.3: Variance versus mean for the (size factor adjusted) <code>counts</code> data. The axes are logarithmic. Also shown are lines through the origin with slopes 1 (green) and 2 (red).</p>
<p>The green line (slope 1) is what we expect if the variance (\(v\)) equals the mean (\(m\)), as is the case for a Poisson-distributed random variable: \(v=m\). We see that this approximately fits the data in the lower range. The red line (slope 2) corresponds to the quadratic mean-variance relationship \(v=m^2\); lines parallel to it (not shown) would represent \(v = cm^2\) for various values of \(c\). We can see that in the upper range of the data, the quadratic relationship approximately fits the data, for some value of \(c&lt;1\).</p>
</section>
</section>
<section id="a-basic-analysis" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="a-basic-analysis"><span class="header-section-number">10.4</span> 8.5 A basic analysis</h2>
<section id="example-dataset-the-pasilla-data" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="example-dataset-the-pasilla-data"><span class="header-section-number">10.4.1</span> 8.5.1 Example dataset: the pasilla data</h3>
<p>Let’s return to the <strong><a href="https://bioconductor.org/packages/pasilla/">pasilla</a></strong> data from Section 8.3. These data are from an experiment on <em>Drosophila melanogaster</em> cell cultures that investigated the effect of RNAi knock-down of the splicing factor <em>pasilla</em> (<a href="16-chap.html#ref- Brooks2010">Brooks et al.&nbsp;2011</a>) on the cells’ transcriptome. There were two experimental conditions, termed <em>untreated</em> and <em>treated</em> in the header of the count table that we loaded. They correspond to negative control and to siRNA against <em>pasilla</em>. The experimental metadata of the 7 samples in this dataset are provided in a spreadsheet-like table, which we load.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="In the code shown here, we load the file pasilla_sample_annotation.csv that comes with the pasilla package. We locate it with the function system.file. When you work with your own data, you will need to prepare an analogous file, or directly a dataframe like pasillaSampleAnno."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>In the code shown here, we load the file pasilla_sample_annotation.csv that comes with the pasilla package. We locate it with the function system.file. When you work with your own data, you will need to prepare an analogous file, or directly a dataframe like pasillaSampleAnno.</figcaption>
</figure>
</div>
<p>In the code shown here, we load the file <code>pasilla_sample_annotation.csv</code> that comes with the <strong><a href="https://bioconductor.org/packages/pasilla/">pasilla</a></strong> package. We locate it with the function <code>system.file</code>. When you work with your own data, you will need to prepare an analogous file, or directly a dataframe like <code>pasillaSampleAnno</code>.</p>
<pre><code>annotationFile = system.file("extdata",
  "pasilla_sample_annotation.csv",
  package = "pasilla", mustWork = TRUE)
pasillaSampleAnno = readr::read_csv(annotationFile)
pasillaSampleAnno __


# A tibble: 7 × 6
  file    condition type  `number of lanes` total number of read…¹ `exon counts`
  &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                          &lt;dbl&gt;
1 treate… treated   sing…                 5 35158667                    15679615
2 treate… treated   pair…                 2 12242535 (x2)               15620018
3 treate… treated   pair…                 2 12443664 (x2)               12733865
4 untrea… untreated sing…                 2 17812866                    14924838
5 untrea… untreated sing…                 6 34284521                    20764558
6 untrea… untreated pair…                 2 10542625 (x2)               10283129
7 untrea… untreated pair…                 2 12214974 (x2)               11653031
# ℹ abbreviated name: ¹​`total number of reads`</code></pre>
<p>여기서 보듯이, 전체 데이터 세트는 두 개의 배치(batch)로 생성되었습니다. 첫 번째 배치는 단일 리드(single-read) 시퀀싱을 거친 3개의 시퀀싱 라이브러리로 구성되었고, 두 번째 배치는 쌍말단(paired-end) 시퀀싱이 사용된 4개의 라이브러리로 구성되었습니다. 종종 그렇듯이, 우리는 약간의 데이터 가공(wrangling)이 필요합니다: <code>type</code> 열의 하이픈(-)을 언더스코어(_)로 바꿉니다. 왜냐하면 <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong>에서는 요인 수준(factor levels)에 산술 연산자를 사용하는 것을 권장하지 않기 때문입니다. 그리고 <code>type</code>과 <code>condition</code> 열을 요인(factors)으로 변환하면서, 우리가 선호하는 수준의 순서를 명시적으로 지정합니다(기본값은 알파벳순입니다).</p>
<pre><code>library("dplyr")
pasillaSampleAnno = mutate(pasillaSampleAnno,
condition = factor(condition, levels = c("untreated", "treated")),
type = factor(sub("-.*", "", type), levels = c("single", "paired")))__</code></pre>
<p>우리는 설계(design)가 관심 요인인 <code>condition</code>과 “성가신 요인(nuisance factor)”인 <code>type</code> 사이에서 대략적으로 균형을 이루고 있음에 주목합니다:</p>
<pre><code>with(pasillaSampleAnno,
       table(condition, type))__


           type
condition   single paired
  untreated      2      2
  treated        1      2</code></pre>
<p><strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong>는 작업하는 데이터 세트를 저장하기 위해 <em>DESeqDataSet</em> 이라 불리는 특수 데이터 컨테이너를 사용합니다. 이러한 특수 컨테이너 — 또는 R 용어로 <em>클래스(classes)</em> — 의 사용은 관련 데이터를 함께 묶어두는 데 도움이 되기 때문에 Bioconductor 프로젝트의 공통적인 원칙입니다. 이러한 방식은 _matrix_나 dataframe과 같은 기본 R 데이터 유형만을 사용하는 것에 비해 사용자가 클래스를 이해하기 위해 초기에 약간 더 많은 시간을 투자해야 하지만, 데이터의 관련 부분들 사이의 동기화 손실로 인한 버그를 피하는 데 도움이 됩니다. 또한 기본 용어로 항상 표현한다면 상당히 장황해질 수 있는 일반적인 연산들의 추상화와 캡슐화를 가능하게 합니다5. _DESeqDataSet_은 Bioconductor의 <em>SummarizedExperiment</em> 클래스의 확장입니다. <em>SummarizedExperiment</em> 클래스는 다른 많은 패키지에서도 사용되므로, 이를 다루는 법을 익히면 상당히 다양한 도구들을 사용할 수 있게 될 것입니다.</p>
<p>5 또 다른 장점은 클래스가 <em>유효성(validity)</em> 메서드를 포함할 수 있다는 것인데, 이는 데이터가 항상 특정 기대치(예: 카운트는 양의 정수여야 함, 카운트 행렬의 열이 샘플 어노테이션 데이터 프레임의 행과 일치해야 함 등)를 충족하는지 확인해 줍니다.</p>
<p>6 아래 코드에서 <code>counts</code> 객체의 열 이름과 <code>pasillaSampleAnno</code> 데이터 프레임의 <code>file</code> 열을 일치시키기 위해 추가적인 작업이 필요함에 주목하세요. 특히 <code>file</code> 열에서 왠지 모르게 사용된 <code>"fb"</code>를 제거해야 합니다. 이러한 데이터 가공은 매우 흔한 일입니다. 데이터를 <em>DESeqDataSet</em> 객체에 저장하는 이유 중 하나는 일단 저장하고 나면 더 이상 그런 걱정을 할 필요가 없기 때문입니다.</p>
<p>우리는 생성자 함수 <code>DESeqDataSetFromMatrix</code>를 사용하여 카운트 데이터 행렬 <code>counts</code>와 샘플 어노테이션 데이터 프레임 <code>pasillaSampleAnno</code>로부터 _DESeqDataSet_을 만듭니다6.</p>
<pre><code>mt = match(colnames(counts), sub("fb$", "", pasillaSampleAnno$file))
stopifnot(!any(is.na(mt)))

pasilla = DESeqDataSetFromMatrix(
  countData = counts,
  colData   = pasillaSampleAnno[mt, ],
  design    = ~ condition)
class(pasilla)__


[1] "DESeqDataSet"
attr(,"package")
[1] "DESeq2"


is(pasilla, "SummarizedExperiment")__


[1] TRUE</code></pre>
<p><em>SummarizedExperiment</em> 클래스 — 따라서 <em>DESeqDataSet</em> — 는 카운트 행렬 행(rows)의 어노테이션을 저장하기 위한 기능도 포함하고 있습니다. 지금은 <code>counts</code> 표의 행 이름에 있는 유전자 식별자로 만족하겠습니다.</p>
<p>__</p>
<p>질문 8.3</p>
<p>우리는 어떻게 <em>SummarizedExperiment</em> 객체의 행 메타데이터에 접근할 수 있을까요? 즉, 어떻게 읽어내고, 어떻게 변경할 수 있을까요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p><em>SummarizedExperiment</em> 클래스와 <code>rowData</code> 및 <code>rowData&lt;-</code> 메서드의 매뉴얼 페이지를 확인해 보세요.</p>
</section>
<section id="deseq2-방법" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="deseq2-방법"><span class="header-section-number">10.4.2</span> 8.5.2 <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> 방법</h3>
<p>이러한 준비를 마친 후, 우리는 이제 곧바로 차등 발현 분석으로 뛰어들 준비가 되었습니다. 우리의 목표는 처리된 세포와 처리되지 않은 세포 사이에서 풍부도가 차이 나는 유전자를 식별하는 것입니다. 이를 위해 우리는 <a href="06-chap.html#sec-testing-ttest">6.5절</a>에서 접했던 \(t\)-검정과 개념적으로 유사하지만 수학적으로는 좀 더 복잡한 검정을 적용할 것입니다. 이러한 세부 사항은 일단 미뤄두고 8.7절에서 다시 다룰 것입니다. 일련의 표준 분석 단계들이 <code>DESeq</code>라는 단일 함수로 묶여 있습니다.</p>
<pre><code>pasilla = DESeq(pasilla)__</code></pre>
<p><code>DESeq</code> 함수는 단순히 <code>estimateSizeFactors</code>(8.4.2절에서 논의한 정규화를 위해), <code>estimateDispersions</code>(분산 추정) 및 <code>nbinomWaldTest</code>(차등 풍부도에 대한 가설 검정) 함수를 순서대로 호출하는 래퍼(wrapper)입니다. 검정은 요인 <code>condition</code>의 두 수준인 <code>untreated</code>와 <code>treated</code> 사이에서 이루어지는데, 이는 우리가 <code>design=~condition</code> 인수를 통해 <code>pasilla</code> 객체를 구성할 때 지정한 것이기 때문입니다. 그들의 거동을 수정하거나 사용자 정의 단계를 삽입하고 싶다면 언제든지 이 세 함수를 개별적으로 호출할 수 있습니다. 결과를 살펴봅시다.</p>
<pre><code>res = results(pasilla)
res[order(res$padj), ] |&gt; head()__


log2 fold change (MLE): condition treated vs untreated 
Wald test p-value: condition treated vs untreated 
DataFrame with 6 rows and 6 columns
             baseMean log2FoldChange     lfcSE      stat       pvalue
            &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;    &lt;numeric&gt;
FBgn0039155   730.596       -4.61901 0.1687068  -27.3789 4.88599e-165
FBgn0025111  1501.411        2.89986 0.1269205   22.8479 1.53430e-115
FBgn0029167  3706.117       -2.19700 0.0969888  -22.6521 1.33042e-113
FBgn0003360  4343.035       -3.17967 0.1435264  -22.1539 9.56283e-109
FBgn0035085   638.233       -2.56041 0.1372952  -18.6490  1.28772e-77
FBgn0039827   261.916       -4.16252 0.2325888  -17.8965  1.25663e-71
                    padj
               &lt;numeric&gt;
FBgn0039155 4.06661e-161
FBgn0025111 6.38497e-112
FBgn0029167 3.69104e-110
FBgn0003360 1.98979e-105
FBgn0035085  2.14354e-74
FBgn0039827  1.74316e-68</code></pre>
</section>
<section id="결과-탐색하기" class="level3" data-number="10.4.3">
<h3 data-number="10.4.3" class="anchored" data-anchor-id="결과-탐색하기"><span class="header-section-number">10.4.3</span> 8.5.3 결과 탐색하기</h3>
<p>차등 발현 분석 후의 첫 번째 단계는 다음의 서너 가지 기본 플롯을 시각화하는 것입니다:</p>
<ul>
<li><p>p-값의 히스토그램 (그림 8.4),</p></li>
<li><p>MA 플롯 (그림 8.5), 그리고</p></li>
<li><p>서열화 플롯(ordination plot) (그림 8.6).</p></li>
<li><p>추가로, 히트맵 (그림 8.7)도 유익할 수 있습니다.</p></li>
</ul>
<p>이들은 필수적인 데이터 품질 평가 척도입니다 — <a href="13-chap.html#sec-design-quality">13.6절</a>에서 제공된 품질 평가 및 제어에 대한 일반적인 조언도 여기에서 똑같이 적용됩니다.</p>
<p>p-값 히스토그램은 직관적입니다 (그림 8.4).</p>
<pre><code>ggplot(as(res, "data.frame"), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-hist1-1.png" title="그림 8.4: 차등 발현 분석의 p-값 히스토그램."><img src="08-chap_files/figure-html/fig-countdata- hist1-1.png" class="img-fluid"></a></p>
<p>그림 8.4: 차등 발현 분석의 p-값 히스토그램.</p>
<p>분포는 두 가지 주요 성분을 보여줍니다: 0과 1 사이의 값을 갖는 균등한 배경(background)과, 왼쪽의 작은 p-값들의 정점입니다. 균등한 배경은 차등 발현되지 않는 유전자들에 해당합니다. 대개 이것이 유전자의 대다수입니다. 왼쪽의 정점은 차등 발현되는 유전자들에 해당합니다7. 우리가 이미 <a href="06-chap.html">6장</a>에서 보았듯이, 배경의 수준과 정점의 높이 사이의 비율은 가장 왼쪽 빈(bin)에 있는 유전자들을 차등 발현된 것으로 판정할 때 수반될 허위 발견율(FDR)에 대한 대략적인 지표를 제공합니다. 우리의 경우, 가장 왼쪽 빈은 0과 0.01 사이의 모든 p-값을 포함하며 이는 993개 유전자에 해당합니다. 배경 수준은 약 100이므로, 가장 왼쪽 빈의 모든 유전자를 판정하는 것과 관련된 FDR은 약 10%가 될 것입니다.</p>
<p>7 여기서 보여주는 데이터의 경우, 히스토그램은 중간이나 오른쪽에 몇 개의 고립된 정점들도 포함하고 있습니다. 이들은 카운트가 적은 유전자들로부터 유래하며 데이터의 이산성을 반영합니다.</p>
<p>때때로 배경 분포가 균등하지 않고 오른쪽으로 갈수록 증가하는 기울어진 형태를 보이는 경우가 있습니다. 이는 대개 배치 효과의 징후입니다. 연습 문제 8.1에서 이를 더 탐구해 볼 수 있습니다.</p>
<p>MA 플롯을 생성하기 위해 우리는 <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> 패키지의 <code>plotMA</code> 함수를 사용할 수 있습니다 (그림 8.5).</p>
<pre><code>plotMA(pasilla, ylim = c( -2, 2))__</code></pre>
<p><a href="08-chap_files/figure- html/fig-countdata-MA-1.png" title="그림 8.5: MA 플롯: 크기 인자(size-factor)로 정규화된 카운트의 평균 대 폴드 변화(fold change). 두 축 모두 로그 스케일이 사용되었습니다. 기본적으로 조정된 p-값이 0.1보다 작으면 점들은 빨간색으로 표시됩니다. y축 범위를 벗어나는 점들은 삼각형으로 표시됩니다."><img src="08-chap_files/figure-html/fig-countdata-MA-1.png" class="img-fluid"></a></p>
<p>그림 8.5: <a href="https://en.wikipedia.org/wiki/MA_plot">MA 플롯</a>: 크기 인자(size-factor)로 정규화된 카운트의 평균 대 폴드 변화(fold change). 두 축 모두 로그 스케일이 사용되었습니다. 기본적으로 조정된 p-값이 0.1보다 작으면 점들은 빨간색으로 표시됩니다. \(y\)축 범위를 벗어나는 점들은 삼각형으로 표시됩니다.</p>
<p><a href="07-chap.html">7장</a>에서 보았던 것과 유사한 PCA 플롯을 생성하기 위해 우리는 <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong>의 <code>plotPCA</code> 함수를 사용할 수 있습니다 (그림 8.6).</p>
<pre><code>pas_rlog = rlogTransformation(pasilla)
plotPCA(pas_rlog, intgroup=c("condition", "type")) + coord_fixed()__</code></pre>
<p><a href="08-chap_files/figure- html/fig-countdata-PCA-1.png" title="그림 8.6: PCA 플롯. 7개의 샘플이 처음 두 주성분에 의해 확장된 2D 평면에 표시되어 있습니다."><img src="08-chap_files/figure-html/fig-countdata-PCA-1.png" class="img-fluid"></a></p>
<p>그림 8.6: PCA 플롯. 7개의 샘플이 처음 두 주성분에 의해 확장된 2D 평면에 표시되어 있습니다.</p>
<p>이전 장에서 보았듯이, 이 유형의 플롯은 실험 공변량의 전체적인 효과를 시각화하거나 배치 효과를 탐지하는 데 유용합니다. 여기서 첫 번째 주축인 PC1은 주로 관심 있는 실험 공변량(untreated / treated)과 일치하며, 두 번째 축은 대략 시퀀싱 프로토콜(single / paired)과 일치합니다.</p>
<p>우리는 데이터 변환의 일종인 <strong>정규화 로그(regularized logarithm)</strong> 또는 <strong>rlog</strong>를 사용했는데, 이에 대해서는 8.10.2절에서 더 자세히 살펴볼 것입니다.</p>
<p>__</p>
<p>질문 8.4</p>
<p>PCA 플롯의 축들이 항상 알려진 실험 공변량과 일치해야 하나요?</p>
<p>히트맵은 카운트 테이블을 포함한 행렬 형태의 데이터 세트에 대한 개요를 빠르게 얻을 수 있는 강력한 방법이 될 수 있습니다. 아래에서 rlog 변환된 데이터로부터 히트맵을 만드는 방법을 볼 수 있습니다. <code>counts(pasilla)</code>만큼 큰 행렬의 경우 전체를 플롯하는 것은 실용적이지 않으므로, 평균 발현량이 가장 높은 상위 30개 유전자의 하위 행렬을 플롯합니다.</p>
<pre><code>library("pheatmap")
select = order(rowMeans(assay(pas_rlog)), decreasing = TRUE)[1:30]
pheatmap( assay(pas_rlog)[select, ],
     scale = "row",
     annotation_col = as.data.frame(
        colData(pas_rlog)[, c("condition", "type")] ))__</code></pre>
<p><a href="08-chap_files/figure- html/fig-figHeatmap-1-1.png" title="그림 8.7: 상위 30개 유전자의 정규화 로그 변환된 데이터 히트맵."><img src="08-chap_files/figure-html/fig-figHeatmap-1-1.png" class="img-fluid"></a></p>
<p>그림 8.7: 상위 30개 유전자의 정규화 로그 변환된 데이터 히트맵.</p>
<p>그림 8.7에서 <code>pheatmap</code>은 비지도 군집화(unsupervised clustering)를 통한 덴드로그램에 따라 행과 열을 정렬했습니다. 열의 군집화 결과는… (samples) is dominated by the <code>type</code> factor. This highlights that our differential expression analysis above was probably too naive, and that we should adjust for this strong “nuisance” factor when we are interested in testing for differentially expressed genes between conditions. We will do this in Section 8.9.</p>
<p>__</p>
<p>Task</p>
<p>Produce a plot similar to Figure 8.7, but selecting the 30 most highly variable genes instead. What is different? How do the genes with very high mean and those with very high variance relate? How does their data look?</p>
</section>
<section id="exporting-the-results" class="level3" data-number="10.4.4">
<h3 data-number="10.4.4" class="anchored" data-anchor-id="exporting-the-results"><span class="header-section-number">10.4.4</span> 8.5.4 Exporting the results</h3>
<p>An HTML report of the results with plots and sortable/filterable columns can be exported using the <strong><a href="https://bioconductor.org/packages/ReportingTools/">ReportingTools</a></strong> package on a <em>DESeqDataSet</em> that has been processed by the <code>DESeq</code> function. For a code example, see the <em>RNA-Seq differential expression</em> vignette of the <strong><a href="https://bioconductor.org/packages/ReportingTools/">ReportingTools</a></strong> package or the manual page for the <code>publish</code> method for the <em>DESeqDataSet</em> class.</p>
<p>A CSV file of the results can be exported using <code>write.csv</code> (or its counterpart from the <strong><a href="https://cran.r-project.org/web/packages/readr/">readr</a></strong> package).</p>
<pre><code>write.csv(as.data.frame(res), file = "treated_vs_untreated.csv")__</code></pre>
</section>
</section>
<section id="critique-of-default-choices-and-possible-modifications" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="critique-of-default-choices-and-possible-modifications"><span class="header-section-number">10.5</span> 8.6 Critique of default choices and possible modifications</h2>
<section id="the-few-changes-assumption" class="level3" data-number="10.5.1">
<h3 data-number="10.5.1" class="anchored" data-anchor-id="the-few-changes-assumption"><span class="header-section-number">10.5.1</span> 8.6.1 The few changes assumption</h3>
<p>Underlying the default normalization and the dispersion estimation in <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> (and many other differential expression methods) is that most genes are not differentially expressed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="For the normalization, although not for the dispersion estimation, one can slightly relax this assumption: it is still valid if many genes are changing, but in a way that is balanced between up- and downward directions."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>For the normalization, although not for the dispersion estimation, one can slightly relax this assumption: it is still valid if many genes are changing, but in a way that is balanced between up- and downward directions.</figcaption>
</figure>
</div>
<p>For the normalization, although not for the dispersion estimation, one can slightly relax this assumption: it is still valid if many genes are changing, but in a way that is balanced between up- and downward directions.</p>
<p>This assumption is often reasonable (well-designed experiments usually ask specific questions, so that not everything changes all at once), but what should we do if it does not hold? Instead of applying these operations on the data from all genes, we will then need to identify a subset of (“negative control”) genes for which we believe the assumption is tenable, either because of prior biological knowledge, or because we explicitly controlled their abundance as external “spiked in” features.</p>
<p>__</p>
<p>Task</p>
<p>Run the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> workflow with size factors and dispersion parameters estimated only from a predefined subset of genes.</p>
</section>
<section id="point-like-null-hypothesis" class="level3" data-number="10.5.2">
<h3 data-number="10.5.2" class="anchored" data-anchor-id="point-like-null-hypothesis"><span class="header-section-number">10.5.2</span> 8.6.2 Point-like null hypothesis</h3>
<p>As a default, the <code>DESeq</code> function tests against the null hypothesis that each gene has the same abundance across conditions; this is a simple and pragmatic choice. Indeed, if the sample size is limited, what is statistically significant also tends to be strong enough to be biologically interesting. But as sample size increases, statistical significance in these tests may be present without much biological relevance. For instance, many genes may be slightly perturbed by downstream, indirect effects. We can modify the test to use a more permissive, interval-based null hypothesis; we will further explore this in Section 8.10.4.</p>
</section>
</section>
<section id="multi-factor-designs-and-linear-models" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="multi-factor-designs-and-linear-models"><span class="header-section-number">10.6</span> 8.7 Multi-factor designs and linear models</h2>
<section id="what-is-a-multifactorial-design" class="level3" data-number="10.6.1">
<h3 data-number="10.6.1" class="anchored" data-anchor-id="what-is-a-multifactorial-design"><span class="header-section-number">10.6.1</span> 8.7.1 What is a multifactorial design?</h3>
<p>Let’s assume that in addition to the siRNA knockdown of the pasilla gene, we also want to test the effect of a certain drug. We could then envisage an experiment in which the experimenter treats the cells either with negative control, with the siRNA against pasilla, with the drug, or with both. To analyse this experiment, we can use the notation</p>
<p>\[ y = _0 + x_1 _1 + x_2 <em>2 + x_1x_2</em>{12}. \]</p>
</section>
</section>
<section id="차등-풍부도differential-abundance" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="차등-풍부도differential-abundance"><span class="header-section-number">10.7</span> 8.6 차등 풍부도(Differential abundance)</h2>
<p>우리의 주요 목표는 서로 다른 생물학적 조건(예: 약물 처리 대 대조군) 사이에서 통계적으로 유의미한 방식으로 풍부도가 변하는 유전자를 찾는 것입니다. 이를 위해 우리는 각 유전자에 대해 다음 가설들을 검정합니다:</p>
<p><strong>귀무 가설 \(H_0\):</strong> 유전자의 풍부도가 두 조건 사이에서 동일하다.</p>
<p><strong>대립 가설 \(H_1\):</strong> 두 조건 사이에서 풍부도가 다르다.</p>
<p>이것은 우리가 <a href="06-chap.html">6장</a>에서 논의한 가설 검정 프레임워크와 정확히 일치합니다. 유일한 차이점은 우리가 수천 개의 유전자에 대해 이 검정을 동시에 수행한다는 것이며, 따라서 다중 검정(multiple testing) 보정이 필요하다는 점입니다.</p>
</section>
<section id="선형-모델" class="level2" data-number="10.8">
<h2 data-number="10.8" class="anchored" data-anchor-id="선형-모델"><span class="header-section-number">10.8</span> 8.7 선형 모델</h2>
<p>여러 실험적 요인들이 동시에 작용하는 더 복잡한 실험 설계를 분석하기 위해, 우리는 선형 모델(linear models)이라는 매우 강력한 프레임워크를 사용합니다.</p>
<section id="요인-설계-및-상호작용" class="level3" data-number="10.8.1">
<h3 data-number="10.8.1" class="anchored" data-anchor-id="요인-설계-및-상호작용"><span class="header-section-number">10.8.1</span> 8.7.1 요인 설계 및 상호작용</h3>
<p>두 가지 실험적 요인이 있는 실험을 생각해 봅시다: siRNA를 이용한 유전자 넉다운과 약물 처리입니다. 우리는 네 가지 가능한 조건을 가집니다:</p>
<ol type="1">
<li><p>처리되지 않음 (negative control)</p></li>
<li><p>siRNA만 처리됨</p></li>
<li><p>약물만 처리됨</p></li>
<li><p>siRNA와 약물 모두 처리됨</p></li>
</ol>
<p>이러한 실험의 결과를 다음과 같은 선형 방정식으로 모델링할 수 있습니다:</p>
<p>\[ y = _0 + x_1 _1 + x_2 <em>2 + x_1 x_2 </em>{12} + . \]</p>
<p>이 방정식은 다음과 같이 해석될 수 있습니다. 좌변인 \(y\)는 관심 있는 실험 측정값입니다. 우리의 경우, 이는 적절하게 변환된 유전자의 발현 수준입니다(이에 대해서는 8.8.3절에서 논의할 것입니다). RNA-Seq 실험에는 수많은 유전자가 있으므로, 각 유전자에 대해 하나씩 식 8.1과 같은 수많은 방정식을 갖게 될 것입니다. 계수 \(_0\)는 대조군에서의 측정 기본 수준이며, 종종 <strong>절편(intercept)</strong>이라고 불립니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="때때로 식 8.1은 \beta_0와 곱해지는 추가 항 x_0를 포함하여 쓰여지기도 하는데, 이때 x_0는 항상 1로 이해됩니다. 이렇게 하면 절편을 별개의 사례로 다루는 대신 다른 \beta들과 함께 일관되게 처리할 수 있어 이후의 표기법과 장부 관리가 더 쉬워집니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>때때로 식 8.1은 _0와 곱해지는 추가 항 x_0를 포함하여 쓰여지기도 하는데, 이때 x_0는 항상 1로 이해됩니다. 이렇게 하면 절편을 별개의 사례로 다루는 대신 다른 함께 일관되게 처리할 수 있어 이후의 표기법과 장부 관리가 더 쉬워집니다.</figcaption>
</figure>
</div>
<p>때때로 식 8.1은 \(_0\)와 곱해지는 추가 항 \(x_0\)를 포함하여 쓰여지기도 하는데, 이때 \(x_0=1\)은 항상 성립하는 것으로 이해됩니다. 이렇게 하면 절편을 별개의 사례로 다루는 대신 다른 \(\)들과 함께 일관되게 처리할 수 있어 이후의 표기법과 장부 관리가 더 쉬워진다는 점이 밝혀졌습니다.</p>
<p>설계 요인 \(x_1\)과 \(x_2\)는 이진 지시 변수(binary indicator variables)입니다: siRNA가 형질감염(transfected)되었으면 \(x_1\)은 1, 아니면 0의 값을 가지며, 유사하게 \(x_2\)는 약물이 투여되었는지 여부를 나타냅니다. siRNA만 사용된 실험에서는 \(x_1=1\)이고 \(x_2=0\)이므로, 식 8.1의 세 번째와 네 번째 항은 사라집니다. 그러면 방정식은 \(y=_0+_1\)로 단순화됩니다. 이는 \(_1\)이 처리군과 대조군 사이의 차이를 나타냄을 의미합니다. 만약 우리의 측정값이 로그 스케일이라면,</p>
<p>\[ <span class="math display">\[\begin{align} \beta_1 = y-\beta_0
&amp;=\log_2(\text{발현}_{\text{처리군}})
-\log_2(\text{발현}_{\text{대조군}})\\\ &amp;=\log_2\frac
{\text{발현}_{\text{처리군}}} {\text{발현}_{\text{대조군}}}
\end{align}\]</span> \]</p>
<p>은 siRNA 처리에 의한 로그 폴드 변화(logarithmic fold change)입니다. 정확히 같은 방식으로, \(_2\)는 약물 처리에 의한 로그 폴드 변화입니다. 세포에 siRNA와 약물을 모두 처리하면 어떻게 될까요? 그 경우 \(x_1=x_2=1\)이며, 식 8.1은 다음과 같이 다시 쓰여질 수 있습니다.</p>
<p>\[ _{12} = y - (_0 + _1 + _2). \]</p>
<p>이는 \(_{12}\)가 관찰된 결과인 \(y\)와, 기본 수준에 siRNA 단독 효과 \(_1\) 및 약물 단독 효과 \(_2\)를 더하여 얻은 개별 처리들로부터 예상되는 결과 사이의 차이임을 의미합니다.</p>
<p>우리는 \(_{12}\)를 siRNA와 약물의 <em>상호작용(interaction)</em> 효과라고 부릅니다. 이는 물리적 상호작용과는 무관하며, 이 용어는 이 두 가지 서로 다른 실험 요인의 효과가 단순히 더해지는 것이 아니라 더 복잡한 방식으로 결합됨을 나타냅니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="덧셈은 로그 스케일에서 이루어지며, 이는 원래 스케일에서의 곱셈에 해당함에 유의하세요."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>덧셈은 로그 스케일에서 이루어지며, 이는 원래 스케일에서의 곱셈에 해당함에 유의하세요.</figcaption>
</figure>
</div>
<p>덧셈은 로그 스케일에서 이루어지며, 이는 원래 스케일에서의 곱셈에 해당함에 유의하세요.</p>
<p>예를 들어, 만약 약물의 타겟과 siRNA의 타겟이 동등하여 세포에 동일한 효과를 준다면, 생물학적으로 \(_1=<em>2\)일 것으로 예상합니다. 또한 우리는 그들의 조합이 추가적인 효과를 주지 않을 것으로 예상하므로, \(</em>{12}=-_1\)이 됩니다. 반면에, 약물의 타겟과 siRNA의 타겟이 서로 완충 작용을 할 수 있는 평행한 경로에 있다면, \(_1\)과 \(<em>2\)는 둘 다 비교적 작겠지만 결합된 효과는 시너지 작용을 하여 \(</em>{12}\)가 클 것으로 예상할 것입니다.</p>
<p>우리가 항상 상호작용에 관심을 갖는 것은 아닙니다. 많은 실험들이 여러 요인을 가지고 설계되지만 각각의 개별 효과에 가장 큰 관심을 가집니다. 그 경우, 조합 처리는 실험 설계에 포함되지 않을 수 있으며, 분석에 사용할 모델은 식 8.1에서 가장 오른쪽 항을 제거한 버전입니다.</p>
<p>우리는 실험 설계를 _설계 행렬(design matrix)_로 간결하게 인코딩할 수 있습니다. 예를 들어, 위에서 설명한 조합 실험의 경우 설계 행렬은 다음과 같습니다.</p>
<p>\[ ]</p>
<p>설계 행렬의 열들은 실험 요인들에 대응하고, 행들은 서로 다른 실험 조건들(우리의 경우 4가지)을 나타냅니다. 만약 조합 처리가 수행되지 않는다면, 설계 행렬은 8.4의 처음 세 행으로만 축소됩니다.</p>
</section>
<section id="노이즈와-반복-실험replicates은-어떠한가요" class="level3" data-number="10.8.2">
<h3 data-number="10.8.2" class="anchored" data-anchor-id="노이즈와-반복-실험replicates은-어떠한가요"><span class="header-section-number">10.8.2</span> 8.7.2 노이즈와 반복 실험(Replicates)은 어떠한가요?</h3>
<p>식 8.1은 관측된 데이터를 서로 다른 실험 변수들에 의해 발생한 효과들로 개념적으로 분해하는 방법을 제공합니다. 만약 우리의 데이터(\(y\)들)가 절대적으로 정확하다면, 우리는 \(x\)들로 표현되는 네 가지 가능한 실험 조건 각각에 대해 하나씩 선형 방정식 시스템을 세우고 \(\)들을 풀 수 있을 것입니다.</p>
<p>물론, 우리는 대개 노이즈의 영향을 받는 실제 데이터를 분석하고자 합니다. 그러면 노이즈 수준을 추정하고 추정된 \(\)들의 불확실성을 평가하기 위해 반복 실험이 필요합니다. 그래야만 조건 사이에서 관찰된 변화가 단지 실험적 또는 자연적 변동에 의해 발생하는 것보다 유의미하게 큰지 경험적으로 평가할 수 있습니다. 우리는 방정식을 약간 확장해야 합니다.</p>
<p>\[ y_{j} = x_{j0} ; <em>0 + x</em>{j1} ; <em>1 + x</em>{j2} ; <em>2 + x</em>{j1},x_{j2};_{12} + _j. \]</p>
<p>우리는 인덱스 \(j\)와 새로운 항 \(<em>j\)를 추가했습니다. 인덱스 \(j\)는 이제 우리의 개별 반복 실험들을 명시적으로 셉니다; 예를 들어, 네 가지 조건 각각에 대해 세 번의 반복 실험을 수행한다면 \(j\)는 1부터 12까지 셉니다. 설계 행렬은 이제 12개의 행을 가지며, \(x</em>{jk}\)는 행렬의 \(j\)번째 행과 \(k\)번째 열의 값입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="\beta_0가 절편이므로 모든 j에 대해 x_{j0}=1임을 기억하세요."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption><em>0가 절편이므로 모든 j에 대해 x</em>{j0}=1임을 기억하세요.</figcaption>
</figure>
</div>
<p>\(<em>0\)가 절편이므로 모든 \(j\)에 대해 \(x</em>{j0}=1\)임을 기억하세요.</p>
<p>우리가 <strong>잔차(residuals)</strong>라고 부르는 추가 항 \(_j\)는 반복 실험들 사이의 차이를 흡수하기 위해 존재합니다. 그러나 한 가지 추가적인 모델링 구성 요소가 필요합니다: 12개의 방정식 시스템 8.5는 추가 정보 없이는 과소 결정(underdetermined)될 것인데, 왜냐하면 이제 방정식의 수(12개, 각 \(j\)에 대해 하나씩)보다 변수의 수(12개의 입실론과 4개의 베타)가 더 많기 때문입니다. 이를 해결하기 위해 우리는 \(_j\)가 작을 것을 요구합니다. 이를 극복하기 위해 널리 쓰이는 한 가지 방법은 — 다른 방법들도 만나게 되겠지만 — 잔차 제곱합을 최소화하는 것입니다.</p>
<p>\[ _j _j^2 . \]</p>
<p>이 요구 조건이 충족되면, \(\)들은 각 실험 요인의 <em>평균적</em> 효과를 나타내고, 잔차 \(_j\)는 반복 실험들 사이의 평균 주변의 실험적 변동을 반영하게 됩니다. <strong>최소제곱법 적합(least sum of squares fitting)</strong>이라 불리는 이 접근 방식은 간단한 행렬 대수로 달성될 수 있기 때문에 수학적으로 편리합니다. 이것이 R 함수 <code>lm</code>이 하는 일입니다.</p>
<p>__</p>
<p>질문 8.5</p>
<p>식 8.5를 쓰는 대안적인 방법은 다음과 같습니다.</p>
<p>\[ y_{j} = <em>k x</em>{jk} ; _k + _j. \]</p>
<p>이것이 어떻게 식 8.5와 매핑될 수 있을까요? 즉, 상호작용 항 \(x_{j1}x_{j2}_{12}\)는 어떻게 된 것인가요?</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>이것은 정말 사소한 표기법의 문제입니다: 합은 \(k=0,…,3\)에 대해 확장되며, \(k=0,1,2\)에 대한 항들은 우리가 이미 알고 있는 것과 정확히 같습니다. 우리는 \(<em>{12}\) 대신 \(</em>{3}\)라고 쓰고, \(x_{j3}\)는 \(x_{j1}x_{j2}\)로 정의됩니다. 일반적인 표기법 8.7은 선형 모델을 구현하는 컴퓨터 소프트웨어와 수학적 증명에서 사용하기에 실용적입니다. 또한 선형 모델의 “과학적 내용”이 그 설계 행렬에 응축되어 있음을 강조합니다.</p>
<p>__</p>
<p>태스크</p>
<p>목적 함수 8.6이 성립하도록 식 8.5를 데이터에 적합시켰다면, 적합 잔차 \(_j\)의 평균이 0임을 보이세요.</p>
</section>
<section id="분산-분석analysis-of-variance" class="level3" data-number="10.8.3">
<h3 data-number="10.8.3" class="anchored" data-anchor-id="분산-분석analysis-of-variance"><span class="header-section-number">10.8.3</span> 8.7.3 분산 분석(Analysis of variance)</h3>
<p>8.5와 같은 모델을 <strong>선형 모델(linear model)</strong>이라고 부르며, 종종 기준 8.6이 데이터를 적합시키는 데 사용됨을 암시합니다. 이 접근 방식은 우아하고 강력하지만, 초보자가 그 모든 측면을 이해하는 데는 시간이 좀 걸릴 수 있습니다. 각기 다른 실험 조건에 대해 단순히 반복 실험들의 평균을 취하고 이 값들을 조건들 사이에서 비교하는 것에 비해 어떤 이점이 있을까요? 단순한 경우에 후자의 접근 방식은 직관적이고 효과적일 수 있습니다. 그러나 서로 다른 그룹에서 반복 실험의 수가 모두 같지 않거나, 하나 이상의 \(x\) 변수가 연속형 값을 가질 때 한계에 부딪히게 됩니다. 이러한 경우, 결국 데이터에 8.5와 같은 것을 적합시키는 것으로 귀결될 것입니다. 8.5를 생각하는 유용한 방법은 <strong>분산 분석(analysis of variance)</strong>, 약어로 ANOVA라는 용어에 담겨 있습니다. 사실 식 8.5가 하는 일은 우리가 실험 과정에서 관찰한 \(y\)의 가변성을 기초적인 성분들로 분해하는 것입니다: 기본 수준 값 \(_0\), 첫 번째 변수의 효과에 의해 발생하는 가변성 \(_1\), 두 번째 변수의 효과에 의해 발생하는 가변성 \(<em>2\), 상호작용의 효과에 의해 발생하는 가변성 \(</em>{12}\), 그리고 설명되지 않는 가변성입니다. 이들 중 마지막 것을 우리는 흔히 _노이즈(noise)_라고 부르고, 다른 것들은 _체계적 가변성(systematic variability)_이라고 부릅니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="노이즈와 체계적 가변성의 구분은 보는 사람의 관점에 달려 있으며, 현실이 아니라 우리의 모델에 달려 있습니다."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>노이즈와 체계적 가변성의 구분은 보는 사람의 관점에 달려 있으며, 현실이 아니라 우리의 모델에 달려 있습니다.</figcaption>
</figure>
</div>
<p>노이즈와 체계적 가변성의 구분은 보는 사람의 관점에 달려 있으며, 현실이 아니라 우리의 모델에 달려 있습니다.</p>
</section>
<section id="강건성robustness" class="level3" data-number="10.8.4">
<h3 data-number="10.8.4" class="anchored" data-anchor-id="강건성robustness"><span class="header-section-number">10.8.4</span> 8.7.4 강건성(Robustness)</h3>
<p>합 8.6은 데이터의 이상치(outliers)에 민감합니다. 이상치를 가진 단 하나의 측정값 \(y_{j}\)가 \(\) 추정치를 다른 반복 실험들에 의해 함축된 값들로부터 멀리 끌어당길 수 있습니다. 이는 최소제곱법에 기반한 방법들이 낮은 <strong>붕괴점(breakdown point)</strong>을 갖는다는 잘 알려진 사실입니다: 단 하나의 데이터 포인트만 이상치여도 전체 통계 결과가 강력하게 영향을 받을 수 있습니다. 예를 들어, \(n\)개 숫자 세트의 평균은 \(\)의 붕괴점을 갖는데, 이는 숫자들 중 단 하나만 바꿈으로써 평균을 임의로 바꿀 수 있음을 의미합니다. 반면에 중앙값(median)은 훨씬 더 높은 붕괴점을 갖습니다. 숫자 하나를 바꾸는 것은 종종 아무런 영향을 주지 않으며, 영향이 있더라도 그 효과는 순위의 중간에 있는 데이터 포인트들의 범위(즉, \(\) 순위에 인접한 것들)로 제한됩니다. 중앙값을 임의로 높게 바꾸려면 관측치의 절반을 바꾸어야 합니다. 우리는 중앙값을 <strong>강건(robust)</strong>하다고 부르며, 그 붕괴점은 \(\)입니다. 숫자 세트 \(y_1, y_2, …\)의 중앙값이 합 \(_j|y_j-_0|\)을 최소화한다는 점을 기억하세요.</p>
<p>이상치에 대해 더 높은 수준의 강건성을 달성하기 위해, 최소화의 목적 함수로 제곱합 8.6 대신 다른 선택지들이 사용될 수 있습니다. 그중에는 다음과 같은 것들이 있습니다:</p>
<p>\[ <span class="math display">\[\begin{align} R &amp;= \sum_j |\varepsilon_j| &amp; \text{최소 절대 편차 (Least absolute deviations)} \\\ R &amp;= \sum_j \rho_s(\varepsilon_j) &amp; \text{M-추정 (M-estimation)} \\\ R &amp;= Q_{\theta}\left( \\{\varepsilon_1^2, \varepsilon_2^2,... \\} \right) &amp; \text{LTS, LQS} \\\ R &amp;= \sum_j w_j \varepsilon_j^2 &amp; \text{일반화 가중 회귀 (general weighted regression)} \end{align}\]</span> \]</p>
<p>여기서 \(R\)은 최소화되어야 할 양입니다. 식 8.8의 첫 번째 선택지는 <strong>최소 절대 편차(least absolute deviations)</strong> 회귀라고 불립니다. 이는 중앙값의 일반화로 볼 수 있습니다. 개념적으로는 단순하고 언뜻 보기에 매력적이지만, 제곱합보다 최소화하기가 더 어렵고, 특히 데이터가 제한적이거나 모델에 잘 맞지 않을 때 덜 안정적이고 덜 효율적일 수 있습니다8. 식 8.8의 두 번째 선택지인 <strong>M-추정(M-estimation)</strong>은 제한된 범위의 \(\)에 대해서는 이차 함수(quadratic function)처럼 보이지만, 절대값 \(||\)이 스케일 매개변수 \(s\)보다 큰 경우에는 기울기가 더 작아지거나, 평평해지거나, 심지어 다시 0으로 떨어지는 페널티 함수 \(_s\)를 사용합니다 (최소제곱 회귀는 \(_s()=^2\)인 특수한 경우입니다). 이 이면의 의도는 이상치, 즉 큰 잔차를 가진 데이터 포인트의 효과를 낮게 가중하는 것입니다 (<a href="16-chap.html#ref-Huber:AMS:1964">Huber 1964</a>). \(s\)의 선택이 이루어져야 하며 이것이 무엇을 이상치로 부를지 결정합니다. 심지어 0 근처에서 \(_s\)가 이차 함수여야 한다는 요구 조건을 버릴 수도 있으며(그의 이계 도함수가 양수이기만 하다면), 문헌에서는 다양한 \(_s\) 함수 선택지가 제안되었습니다. 그 목표는 데이터가 모델에 잘 맞을 때와 그곳에서 추정기에 바람직한 통계적 속성(예: 편향과 효율성)을 부여하면서도, 그렇지 않은 데이터 포인트의 영향력을 제한하거나 무효화하고 계산을 다루기 쉽게 유지하는 것입니다.</p>
<p>8 <a href="https://en.wikipedia.org/wiki/Least_absolute_deviations">위키백과 문서</a>에서 개요를 제공합니다.</p>
<p>__</p>
<p>질문 8.6</p>
<p>M-추정기를 위해 Huber (<a href="16-chap.html#ref-Huber:AMS:1964">1964</a>)가 제안한 함수 \(_s()\)의 그래프를 그려보세요.</p>
<p>__</p>
<p>해결책</p>
<p>__</p>
<p>Huber의 논문은 75페이지에서 다음과 같이 정의합니다:</p>
<p>\[ _s() = \{ ]</p>
<p>아래 코드로 생성된 그래프는 그림 8.8에 나와 있습니다.</p>
<pre><code>rho = function(x, s)
  ifelse(abs(x) &lt; s, x^2 / 2,  s * abs(x) - s^2 / 2)

df = tibble(
  x        = seq(-7, 7, length.out = 100),
  parabola = x ^ 2 / 2,
  Huber    = rho(x, s = 2))

ggplot(reshape2::melt(df, id.vars = "x"),
  aes(x = x, y = value, col = variable)) + geom_line()__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-mestimator-1.png &quot;그림 8.8: s=2를 선택했을 때의 \rho_s(\varepsilon) 그래프.&quot;"><img src="08-chap_files/figure-html/fig-countdata- mestimator-1.png" class="img-fluid"></a></p>
<p>그림 8.8: \(s=2\)를 선택했을 때의 \(_s()\) 그래프.</p>
<p>Choice three in 8.8 generalises the least sum of squares method in yet another way. In <strong>least quantile of squares</strong> (LQS) regression, the the sum over the squared residuals is replaced with a quantile, for instance, \(Q_{50}\), the median, or \(Q_{90}\), the 90%-quantile (<a href="16-chap.html#ref-Rousseeuw:1987">Peter J. Rousseeuw 1987</a>). In a variation thereof, <strong>least trimmed sum of squares</strong> (LTS) regression, a sum of squared residuals is used, but the sum extends not over all residuals, but only over the fraction \(0\) of smallest residuals. The motivation in either case is that outlying data points lead to large residuals, and as long as they are rare, they do not affect the quantile or the trimmed sum.</p>
<p>However, there is a price: while the least sum of squares optimization 8.6 can be done through straightforward linear algebra, more complicated iterative optimization algorithms are needed for M-estimation, LQS and LTS regression.</p>
<p>The final approach in 8.8 represents an even more complex way of weighting down outliers. It assumes that we have some way of deciding what weight \(w_j\) we want to give to each observation, presumably down-weighting outliers. For instance, in Section 8.10.3, we will encounter the approach used by the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> package, in which the leverage of each data point on the estimated \(\)s is assessed using a measure called Cook’s distance. For those data whose Cook’s distance is deemed too large, the weight \(w_j\) is set to zero, whereas the other data points get \(w_j=1\). In effect, this means that the outlying data points are discarded and that ordinary regression is performed on the others. The extra computational effort of carrying the weights along is negligible, and the optimization is still straightforward linear algebra.</p>
<p>All of these approaches to outlier robustness introduce a degree of subjectiveness and rely on sufficient replication. The subjectiveness is reflected by the parameter choices that need to be made: \(s\) in 8.8 (2), \(\) in 8.8 (3), the weights in 8.8 (4). One scientist’s outlier may be the Nobel prize of another. On the other hand, outlier removal is no remedy for sloppy experiments and no justification for wishful thinking.</p>
<p>__</p>
<p>Task</p>
<p>Search the documentation of R and CRAN packages for implementations of the above robust regression methods. A good place to start is the <a href="https://cran.r-project.org/web/views/Robust.html">CRAN task view on robust statistical methods</a>.</p>
</section>
</section>
<section id="generalized-linear-models" class="level2" data-number="10.9">
<h2 data-number="10.9" class="anchored" data-anchor-id="generalized-linear-models"><span class="header-section-number">10.9</span> 8.8 Generalized linear models</h2>
<p>We need to explore two more theoretical concepts before we can proceed to our next application example. Equations of the form 8.5 model the expected value of the outcome variable, \(y\), as a linear function of the design matrix, and they are fit to data according to the least sum of squares criterion 8.6; or a robust variant thereof. We now want to generalize these assumptions.</p>
<section id="modeling-the-data-on-a-transformed-scale" class="level3" data-number="10.9.1">
<h3 data-number="10.9.1" class="anchored" data-anchor-id="modeling-the-data-on-a-transformed-scale"><span class="header-section-number">10.9.1</span> 8.8.1 Modeling the data on a transformed scale</h3>
<p>We already saw that it can be fruitful to consider the data not on the scale that we obtained them, but after some transformation, for instance, the logarithm. This idea can be generalized, since depending on the context, other transformations are useful. For instance, the linear model 8.5 would not directly be useful for modeling outcomes that are bounded within an interval, say, \([0,1]\) as an indicator of disease risk. In a linear model, the values of \(y\) cover, in principle, the whole real axis. However, if we transform the expression on the right hand with a sigmoid function, for instance, \(f(y) = 1/(1+e^{-y})\), then the range of this function9, is bounded between 0 and 1 and can be used to model such an outcome.</p>
<p>9 It is called the logistic function (<a href="16-chap.html#ref- Verhulst:1845">Verhulst 1845</a>), and the associated regression model is called <strong>logistic regression</strong>.</p>
</section>
<section id="other-error-distributions" class="level3" data-number="10.9.2">
<h3 data-number="10.9.2" class="anchored" data-anchor-id="other-error-distributions"><span class="header-section-number">10.9.2</span> 8.8.2 Other error distributions</h3>
<p>The other generalization regards the minimization criterion 8.6. In fact, this criterion can be derived from a specific probabilistic model and the <strong>maximum likelihood</strong> principle (we already encountered this in <a href="02-chap.html">Chapter 2</a>). To see this, consider the probabilistic model</p>
<p>\[ p(_j) = (-), \]</p>
<p>that is, we believe that the residuals follow a normal distribution with mean 0 and standard deviation \(\). Then it is plausible to demand from a good model (i.e., from a good set of \(\)s) that these probabilities are large. Formally,</p>
<p>\[ _j p(_j) . \]</p>
<p>__</p>
<p>Question 8.7</p>
<p>Show that the maximizing the likelihood 8.10 is equivalent to minimizing the sum of squared residuals 8.6.</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>Insert 8.9 into 8.10 and take the logarithm.</p>
<p>Let’s revise some core concepts: the left hand side of Equation 8.10, i.e., the product of the probabilities of the residuals, is a function of both the model parameters \(_1, _2, …\) and the data \(y_1, y_2, …\); call it \(f(,y)\). If we think of the model parameters \(\) as given and fixed, then the collapsed function \(f(y)\) simply indicates the probability of the data. We could use it, for instance, to simulate data. If, on the other hand, we consider the data as given, then \(f()\) is a function of the model parameters, and it is called the <em>likelihood</em>. The second view is the one we take when we optimise 8.6 (and thus 8.10), and hence the \(\)s obtained this way are what is called <em>maximum-likelihood estimates</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/devil.png" title="It is good to remember that, while we can use the normal distribution as a convenient argument to motivate least sum of squares regression through the maximum likelihood principle, the data do not have to be distributed according to the normal for least sum of squares regression to provide a useful result. In fact, least sum of squares fitting often provides useful estimates for the \betas even when the data are non-normal, although that depends on the specific circumstances."><img src="imgs/devil.png" class="img-fluid figure-img"></a></p>
<figcaption>It is good to remember that, while we can use the normal distribution as a convenient argument to motivate least sum of squares regression through the maximum likelihood principle, the data do not have to be distributed according to the normal for least sum of squares regression to provide a useful result. In fact, least sum of squares fitting often provides useful estimates for the \betas even when the data are non-normal, although that depends on the specific circumstances.</figcaption>
</figure>
</div>
<p>It is good to remember that, while we can use the normal distribution as a convenient argument to motivate least sum of squares regression through the maximum likelihood principle, the data do not have to be distributed according to the normal for least sum of squares regression to provide a useful result. In fact, least sum of squares fitting often provides useful estimates for the \(\)s even when the data are non-normal, although that depends on the specific circumstances.</p>
<p>The generalization that we can now make is to use a different probabilistic model. We can use the densities of other distributions than the normal instead of Equation 8.9. For instance, to be able to deal with count data, we will use the gamma-Poisson distribution.</p>
</section>
<section id="a-generalized-linear-model-for-count-data" class="level3" data-number="10.9.3">
<h3 data-number="10.9.3" class="anchored" data-anchor-id="a-generalized-linear-model-for-count-data"><span class="header-section-number">10.9.3</span> 8.8.3 A generalized linear model for count data</h3>
<p>The differential expression analysis in <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> uses a generalized linear model of the form:</p>
<p>\[ <span class="math display">\[\begin{align} K_{ij} &amp; \sim \text{GP}(\mu_{ij}, \alpha_i) \\\ \mu_{ij} &amp;=
s_j\, q_{ij} \\\ \log_2(q_{ij}) &amp;= \sum_k x_{jk} \beta_{ik}. \end{align}\]</span> \]</p>
<p>Let us unpack this step by step. The counts \(K_{ij}\) for gene \(i\), sample \(j\) are modeled using a gamma-Poisson (GP) distribution with two parameters, the mean \(<em>{ij}\) and the dispersion \(<em>i\). By default, the dispersion is different for each gene \(i\), but the same across all samples, therefore it has no index \(j\). The second line in Equation 8.11 states that the mean is composed of a sample-specific size factor \(s_j\)10 and \(q</em>{ij}\), which is proportional to the true expected concentration of fragments for gene \(i\) in sample \(j\). The value of \(q</em>{ij}\) is given by the linear model in the third line via the <em>link function</em> , \(<em>2\). The design matrix \((x</em>{jk})\) is the same for all genes (and therefore does not depend on \(i\)). Its rows \(j\) correspond to the samples, its columns \(k\) to the experimental factors. In the simplest case, for a pairwise comparison, the design matrix has only two columns, one of them everywhere filled with 1 (corresponding to \(<em>0\) of Section 8.7.1) and the other one containing 0 or 1 depending on whether the sample belongs to one or the other group. The coefficients \(</em>{ik}\) give the \(_2\) fold changes for gene \(i\) for each column of the design matrix \(X\).</p>
<p>10 The model can be generalized to use sample- <strong>and</strong> gene-dependent normalization factors \(s_{ij}\). This is explained in the documentation of the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> package.</p>
</section>
</section>
<section id="two-factor-analysis-of-the-pasilla-data" class="level2" data-number="10.10">
<h2 data-number="10.10" class="anchored" data-anchor-id="two-factor-analysis-of-the-pasilla-data"><span class="header-section-number">10.10</span> 8.9 Two-factor analysis of the pasilla data</h2>
<p>Besides the treatment with siRNA, which we have already considered in Section 8.5, the <strong><a href="https://bioconductor.org/packages/pasilla/">pasilla</a></strong> data have another covariate, <code>type</code>, which indicates the type of sequencing that was performed.</p>
<p>We saw in the exploratory data analysis (EDA) plots in Section 8.5.3 that the latter had a considerable systematic effect on the data. Our basic analysis of Section 8.5 did not take this account, but we will do so now. This should help us get a more correct picture of which differences in the data are attributable to the treatment, and which are confounded – or masked – by the sequencing type.</p>
<pre><code>pasillaTwoFactor = pasilla
design(pasillaTwoFactor) = formula(~ type + condition)
pasillaTwoFactor = DESeq(pasillaTwoFactor)__</code></pre>
<p>Of the two variables <code>type</code> and <code>condition</code>, the one of primary interest is <code>condition</code>, and in <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> , the convention is to put it at the end of the formula. This convention has no effect on the model fitting, but it helps simplify some of the subsequent results reporting. Again, we access the results using the <code>results</code> function, which returns a dataframe with the statistics of each gene.</p>
<pre><code>res2 = results(pasillaTwoFactor)
head(res2, n = 3)__


log2 fold change (MLE): condition treated vs untreated 
Wald test p-value: condition treated vs untreated 
DataFrame with 3 rows and 6 columns
             baseMean log2FoldChange     lfcSE       stat    pvalue      padj
            &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt;  &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;
FBgn0000003  0.171569      0.6745518  3.871091  0.1742537  0.861666        NA
FBgn0000008 95.144079     -0.0406731  0.222215 -0.1830351  0.854770  0.951975
FBgn0000014  1.056572     -0.0849880  2.111821 -0.0402439  0.967899        NA</code></pre>
<p>It is also possible to retrieve the \(_2\) fold changes, p-values and adjusted p-values associated with the <code>type</code> variable. The function <code>results</code> takes an argument <code>contrast</code> that lets users specify the name of the variable, the level that corresponds to the numerator of the fold change and the level that corresponds to the denominator of the fold change.</p>
<pre><code>resType = results(pasillaTwoFactor,
  contrast = c("type", "single", "paired"))
head(resType, n = 3)__


log2 fold change (MLE): type single vs paired 
Wald test p-value: type single vs paired 
DataFrame with 3 rows and 6 columns
             baseMean log2FoldChange     lfcSE      stat    pvalue      padj
            &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;
FBgn0000003  0.171569      -1.611546  3.871083 -0.416304  0.677188        NA
FBgn0000008 95.144079      -0.262255  0.220686 -1.188362  0.234691  0.543822
FBgn0000014  1.056572       3.290586  2.087243  1.576522  0.114905        NA</code></pre>
<p>So what did we gain from this analysis that took into account <code>type</code> as a nuisance factor (sometimes also called, more politely, a <em>blocking factor</em>), compared to the simple comparison between two groups of Section 8.5? Let us plot the p-values from both analyses against each other.</p>
<pre><code>trsf = function(x) ifelse(is.na(x), 0, (-log10(x)) ^ (1/6))
ggplot(tibble(pOne = res$pvalue,
              pTwo = res2$pvalue),
    aes(x = trsf(pOne), y = trsf(pTwo))) +
    geom_hex(bins = 75) + coord_fixed() +
    xlab("Single factor analysis (condition)") +
    ylab("Two factor analysis (type + condition)") +
    geom_abline(col = "orange")__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-scpres1res2-1.png &quot;Figure 8.9: Comparison of p-values from the models with a single factor (condition) and with two factors (type + condition). The axes correspond to (-\log_{10}p)^{\frac{1}{6}}, an arbitrarily chosen monotonically decreasing transformation that compresses the dynamic range of the p-values for the purpose of visualization. We can see a trend for the joint distribution to lie above the bisector, indicating that the small p-values in the two-factor analysis are generally smaller than those in the one-factor analysis.&quot;"><img src="08-chap_files/figure-html/fig-countdata- scpres1res2-1.png" class="img-fluid"></a></p>
<p>Figure 8.9: Comparison of p-values from the models with a single factor (condition) and with two factors (type + condition). The axes correspond to \((-_{10}p)^{}\), an arbitrarily chosen monotonically decreasing transformation that compresses the dynamic range of the p-values for the purpose of visualization. We can see a trend for the joint distribution to lie above the bisector, indicating that the small p-values in the two-factor analysis are generally smaller than those in the one-factor analysis.</p>
<p>As we can see in Figure 8.9, the p-values in the two-factor analysis are similar to those from the one-factor analysis, but are generally smaller. The more sophisticated analysis has led to an, albeit modest, increase in power. We can also see this by counting the number of genes that pass a certain significance threshold in each case:</p>
<pre><code>compareRes = table(
   `simple analysis` = res$padj &lt; 0.1,
   `two factor` = res2$padj &lt; 0.1 )
addmargins( compareRes )__


               two factor
simple analysis FALSE TRUE  Sum
          FALSE  6973  289 7262
          TRUE     25 1036 1061
          Sum    6998 1325 8323</code></pre>
<p>The two-factor analysis found 1325 genes differentially expressed at an FDR threshold of 10%, while the one-factor analysis found 1061. The two-factor analysis has increased detection power. In general, the gain can be even much larger, or also smaller, depending on the data. The proper choice of the model requires informed adaptation to the experimental design and data quality.</p>
<p>__</p>
<p>Question 8.8</p>
<p><em>Why</em> do we detect fewer significant genes when we do not take into account the <code>type</code> variable? More generally, what does this mean about the benefit of taking into account (or not) blocking factors?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>Without modeling the blocking factor, the variability in the data that is due to it has to be absorbed by the \(\)s. This means that they are generally larger than in the model with the blocking factor. The higher level of noise leads to higher uncertainty in the \(\)-estimates. On the other hand, the model with the blocking factor has more parameters that need to be estimated. In statistical parlance, the fit has fewer “degrees of freedom”. Both of these effects are counteracting, and which of them prevails, and which of the modeling choices yields more or fewer significant results depends on the data.</p>
<p>__</p>
<p>Question 8.9</p>
<p>What is confounding? Can <em>not</em> taking into account a blocking factor also lead to the detection of <em>more</em> genes?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>Yes. Imagine the variables <code>condition</code> and <code>type</code> were not as nicely balanced as they are, but partially or fully confounded. In that case, differences in the data due to <code>type</code> could be attributed to <code>condition</code> if a model is fit that does not make it possible to absorb them in the <code>type</code>-effect. Scientifically, such an experiment (and analysis) can be quite an embarrassment.</p>
<p>__</p>
<p>Question 8.10</p>
<p>Consider a paired experimenal design, say, 10 different cell lines each with and without drug treatment. How should this be analyzed?</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>If we just did a simple two-group comparison (treated versus untreated) many of the treatment effects would probably go under in the strong cell line to cell line variation. However, we can set up a <em>paired</em> analysis simply by adding cell line identity as a blocking factor. (Cell line is then really an R <em>factor</em> with 10 different levels, rather than just a 0 vs 1 indicator variable as with the variables that we looked at so far; R’s linear modeling facilities, and also <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> , have no problem dealing with that.)</p>
<p>__</p>
<p>Question 8.11</p>
<p>What can you do if you suspect there are “hidden” factors that affect your data, but they are not documented? (Sometimes, such undocumented covariates are also called <strong>batch effects</strong>.)</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>There are methods that try to identify blocking factors in an unsupervised fashion, see e.g., Leek and Storey (<a href="16-chap.html#ref-LeekStorey:2007">2007</a>; <a href="16-chap.html#ref-Stegle:2010">Stegle et al.&nbsp;2010</a>).</p>
</section>
<section id="further-statistical-concepts" class="level2" data-number="10.11">
<h2 data-number="10.11" class="anchored" data-anchor-id="further-statistical-concepts"><span class="header-section-number">10.11</span> 8.10 Further statistical concepts</h2>
<section id="sharing-of-dispersion-information-across-genes" class="level3" data-number="10.11.1">
<h3 data-number="10.11.1" class="anchored" data-anchor-id="sharing-of-dispersion-information-across-genes"><span class="header-section-number">10.11.1</span> 8.10.1 Sharing of dispersion information across genes</h3>
<p>We already saw an explanation of Bayesian (or empirical Bayes) analysis in <a href="06-chap.html#fig-testing-sunexplode">Figure 6.16</a>. The idea is to use additional information to improve our estimates (information that we either known a priori, or have from analysis of other, but similar data). This idea is particularly useful if the data per se are relatively noisy. <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> uses an empirical Bayes approach for the estimation of the dispersion parameters (the \(\)s in the third line of Equation 8.11) and, optionally, the logarithmic fold changes (the \(\)s). The priors are, in both cases, taken from the distributions of the maximum-likelihood estimates (MLEs) across all genes. It turns out that both of these distributions are uni-modal; in the case of the \(\)s, with a peak at around 0, in the case of the \(\), at a particular value, the typical dispersion. The empirical Bayes machinery then shrinks each per-gene MLE towards that peak, by an amount that depends on the sharpness of the empirical prior distribution and the precision of the ML estimate (the better the latter, the less shrinkage will be done). The mathematics are explained in (<a href="16-chap.html#ref-LoveDESeq2">Michael I. Love, Huber, and Anders 2014</a>), and Figure 8.10 visualizes the approach for the \(\)s.</p>
<p>__</p>
<p>Task</p>
<p>Advanced: check the R code that produces Figure 8.10.</p>
<p>[<img src="08-chap_files/figure-html/fig-countdata- posterior-1.png" class="img-fluid">](08-chap_files/figure-html/fig-countdata-posterior-1.png “Figure&nbsp;8.10&nbsp;(a):”)</p>
<ol type="a">
<li></li>
</ol>
<p>[<img src="08-chap_files/figure-html/fig-countdata- posterior-2.png" class="img-fluid">](08-chap_files/figure-html/fig-countdata-posterior-2.png “Figure&nbsp;8.10&nbsp;(b):”)</p>
<ol start="2" type="a">
<li></li>
</ol>
<p>Figure 8.10: Shrinkage estimation of logarithmic fold change estimates by use of an empirical prior in <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong>. Two genes with similar mean count and MLE logarithmic fold change are highlighted in green and blue. The normalized counts for these genes (a) reveal low dispersion for the gene in blue and high dispersion for the gene in green. In (b), the density plots are shown of the normalized likelihoods (solid lines) and of the posteriors (dashed lines) for the green and blue gene. In addition, the solid black line shows the prior estimated from the MLEs of all genes. Due to the higher dispersion of the green gene, its likelihood is wider and less sharp (indicating less information), and the prior has more influence on its posterior than in the case of the blue gene.</p>
</section>
<section id="count-data-transformations" class="level3" data-number="10.11.2">
<h3 data-number="10.11.2" class="anchored" data-anchor-id="count-data-transformations"><span class="header-section-number">10.11.2</span> 8.10.2 Count data transformations</h3>
<p>For testing for differential expression we operate on raw counts and use discrete distributions. For other downstream analyses – e.g., for visualization or clustering – it might however be useful to work with transformed versions of the count data.</p>
<p>Maybe the most obvious choice of transformation is the logarithm. However, since count values for a gene can become zero, some advocate the use of <strong>pseudocounts</strong> , i.e., transformations of the form</p>
<p>\[ y = _2(n + 1)y = _2(n + n_0), \]</p>
<p>where \(n\) represents the count values and \(n_0\) is a somehow chosen positive constant.</p>
<p>Let’s look at two alternative approaches that offer more theoretical justification, and a rational way of choosing the parameter equivalent to \(n_0\) above. One method incorporates priors on the sample differences, and the other uses the concept of variance-stabilizing transformations.</p>
<section id="variance-stabilizing-transformation" class="level4" data-number="10.11.2.1">
<h4 data-number="10.11.2.1" class="anchored" data-anchor-id="variance-stabilizing-transformation"><span class="header-section-number">10.11.2.1</span> Variance-stabilizing transformation</h4>
<p>We already explored <strong>variance-stabilizing transformations</strong> in <a href="04-chap.html#sec-mixtures-vst">Section 4.4.4</a>. There we computed a piece-wise linear transformation for a discrete set of random variables (<a href="04-chap.html#fig-pcwlin-1">Figure 4.26</a>) and also saw how to use calculus to derive a smooth variance-stabilizing transformation for a gamma-Poisson mixture. These computations are implemented in the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> package (<a href="16-chap.html#ref-Anders:2010:GB">Anders and Huber 2010</a>):</p>
<pre><code>vsp = varianceStabilizingTransformation(pasilla)__</code></pre>
<p>Let us explore the effect of this on the data, using the first sample as an example, and comparing it to the \(_2\) transformation; the plot is shown in Figure 8.11 and is made with the following:</p>
<pre><code>j = 1
ggplot(
  tibble(
    counts = rep(assay(pasilla)[, j], 2),
    transformed = c(
      assay(vsp)[, j],
      log2(assay(pasilla)[, j])
      ),
    transformation = rep(c("VST", "log2"), each = nrow(pasilla))
  ),
  aes(x = counts, y = transformed, col = transformation)) +
  geom_line() + xlim(c(0, 600)) + ylim(c(0, 9))__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-plotvst-1.png &quot;Figure 8.11: Graph of variance-stabilizing transformation for the data of one of the samples, and for comparison also of the \log_2 transformation. The variance-stabilizing transformation has finite values and finite slope even for counts close to zero, whereas the slope of \log_2 becomes very steep for small counts and is undefined for counts of zero. For large counts, the two transformation are essentially the same.&quot;"><img src="08-chap_files/figure-html/fig-countdata- plotvst-1.png" class="img-fluid"></a></p>
<p>Figure 8.11: Graph of variance-stabilizing transformation for the data of one of the samples, and for comparison also of the \(_2\) transformation. The variance-stabilizing transformation has finite values and finite slope even for counts close to zero, whereas the slope of \(_2\) becomes very steep for small counts and is undefined for counts of zero. For large counts, the two transformation are essentially the same.</p>
</section>
<section id="regularized-logarithm-rlog-transformation" class="level4" data-number="10.11.2.2">
<h4 data-number="10.11.2.2" class="anchored" data-anchor-id="regularized-logarithm-rlog-transformation"><span class="header-section-number">10.11.2.2</span> Regularized logarithm (rlog) transformation</h4>
<p>There is a second way to come up with a data transformation. It is conceptually distinct from variance stabilization. Instead, it builds upon the shrinkage estimation that we already explored in Section 8.10.1. It works by transforming the original count data to a \(<em>2\)-like scale by fitting a “trivial” model with a separate term for each sample and a prior distribution on the coefficients which is estimated from the data. The fitting employs the same regularization as what we discussed in Section 8.10.1. The transformed data \(q</em>{ij}\) are defined by the third line of Equation 8.11, where the design matrix \((x_{jk})\) is of size \(K (K+1)\) – here \(K\) is the number of samples– and has the form</p>
<p>\[ X=(]</p>
<p>Without priors, this design matrix would lead to a non-unique solution, however the addition of a prior on non-intercept \(\)s allows for a unique solution to be found.</p>
<p>In <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> , this functionality is implemented in the function <code>rlogTransformation</code>. It turns out in practice that the rlog transformation is also approximately variance- stabilizing, but in contrast to the variance-stabilizing transformation of Section 8.10.2 it deals better with data in which the size factors of the different samples are very distinct.</p>
<p>__</p>
<p>Question 8.12</p>
<p>Plot mean against standard deviation between replicates for the shifted logarithm 8.12, the regularized log transformation and the variance- stabilizing transformation.</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>See Figure 8.12.</p>
<pre><code>library("vsn")
rlp = rlogTransformation(pasilla)

msd = function(x)
  meanSdPlot(x, plot = FALSE)$gg + ylim(c(0, 1)) +
     theme(legend.position = "none")

gridExtra::grid.arrange(
  msd(log2(counts(pasilla, normalized = TRUE) + 1)) +
    ylab("sd(log2)"),
  msd(assay(vsp)) + ylab("sd(vst)"),
  msd(assay(rlp)) + ylab("sd(rlog)"),
  ncol = 3
)__</code></pre>
<p><a href="08-chap_files/figure-html/fig-countdata-meansd-1.png &quot;Figure 8.12: Per-gene standard deviation (sd, taken across samples) against the rank of the mean, for the shifted logarithm \log_2(n+1), the variance- stabilizing transformation (vst) and the rlog. Note that for the leftmost \approx 2,500 genes, the counts are all zero, and hence their standard deviation is zero. The mean-sd dependence becomes more interesting for genes with non-zero counts. Note also the high value of the standard deviation for genes that are weakly detected (but not with all zero counts) when the shifted logarithm is used, and compare to the relatively flat shape of the mean-sd relationship for the variance-stabilizing transformation.&quot;"><img src="08-chap_files/figure-html/fig-countdata- meansd-1.png" class="img-fluid"></a></p>
<p>Figure 8.12: Per-gene standard deviation (sd, taken across samples) against the rank of the mean, for the shifted logarithm \(_2(n+1)\), the variance-stabilizing transformation (vst) and the rlog. Note that for the leftmost \(\) 2,500 genes, the counts are all zero, and hence their standard deviation is zero. The mean-sd dependence becomes more interesting for genes with non-zero counts. Note also the high value of the standard deviation for genes that are weakly detected (but not with all zero counts) when the shifted logarithm is used, and compare to the relatively flat shape of the mean-sd relationship for the variance-stabilizing transformation.</p>
</section>
</section>
<section id="dealing-with-outliers" class="level3" data-number="10.11.3">
<h3 data-number="10.11.3" class="anchored" data-anchor-id="dealing-with-outliers"><span class="header-section-number">10.11.3</span> 8.10.3 Dealing with outliers</h3>
<p>The data sometimes contain isolated instances of very large counts that are apparently unrelated to the experimental or study design, and which may be considered outliers. There are many reasons why outliers can arise, including rare technical or experimental artifacts, read mapping problems in the case of genetically differing samples, and genuine, but rare biological events. In many cases, users appear primarily interested in genes that show a consistent behaviour, and this is the reason why by default, genes that are affected by such outliers are set aside by <code>DESeq</code>. The function calculates, for every gene and for every sample, a diagnostic test for outliers called <strong>Cook’s distance</strong>(<a href="16-chap.html#ref-Cook1977Detection">Cook 1977</a>). Cook’s distance is a measure of how much a single sample is influencing the fitted coefficients for a gene, and a large value of Cook’s distance is intended to indicate an outlier count. <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> automatically flags genes with Cook’s distance above a cutoff and sets their p-values and adjusted p-values to <code>NA</code>.</p>
<p>The default cutoff depends on the sample size and number of parameters to be estimated; <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> uses the \(99%\) quantile of the \(F(p,m-p)\) distribution (with \(p\) the number of parameters including the intercept and \(m\) number of samples).</p>
<p>__</p>
<p>Question 8.13</p>
<p>Check the documentation to see how the default cutoff can be changed, and how the outlier removal functionality can be disabled altogether. How can the computed Cook’s distances be accessed?</p>
<p>With many degrees of freedom – i.e., many more samples than number of parameters to be estimated – it might be undesirable to remove entire genes from the analysis just because their data include a single count outlier. An alternate strategy is to replace the outlier counts with the trimmed mean over all samples, adjusted by the size factor for that sample. This approach is conservative: it will not lead to false positives, as it replaces the outlier value with the value predicted by the null hypothesis.</p>
</section>
<section id="tests-of-_2-fold-change-above-or-below-a-threshold" class="level3" data-number="10.11.4">
<h3 data-number="10.11.4" class="anchored" data-anchor-id="tests-of-_2-fold-change-above-or-below-a-threshold"><span class="header-section-number">10.11.4</span> 8.10.4 Tests of \(_2\) fold change above or below a threshold</h3>
<p>Let’s come back to the point we raised in Section 8.6: how to build into the tests our requirement that we want to detect effects that have a strong enough size, as opposed to ones that are statistically significant, but very small. Two arguments to the <code>results</code> function allow for threshold-based Wald tests: <code>lfcThreshold</code>, which takes a numeric of a non-negative threshold value, and <code>altHypothesis</code>, which specifies the kind of test. It can take one of the following four values, where \(\) is the \(_2\) fold change specified by the <code>name</code> argument, and \(\) represents <code>lfcThreshold</code>:</p>
<ul>
<li><p><code>greater</code>: \(&gt; \)</p></li>
<li><p><code>less</code>: \(&lt; (-)\)</p></li>
<li><p><code>greaterAbs</code>: \(|| &gt; \) (two-tailed test)</p></li>
<li><p><code>lessAbs</code>: \(|| &lt; \) (p-values are the maximum of the upper and lower tests)</p></li>
</ul>
<p>These are demonstrated in the following code and visually by MA-plots in Figure 8.13. (Note that the <code>plotMA</code> method, which is defined in the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> package, uses base graphics.)</p>
<pre><code>par(mfrow = c(4, 1), mar = c(2, 2, 1, 1))
myMA = function(h, v, theta = 0.5) {
  plotMA(pasilla, lfcThreshold = theta, altHypothesis = h,
         ylim = c(-2.5, 2.5))
  abline(h = v * theta, col = "dodgerblue", lwd = 2)
}
myMA("greaterAbs", c(-1, 1))
myMA("lessAbs",    c(-1, 1))
myMA("greater",          1)
myMA("less",         -1   )__</code></pre>
<p>[<img src="08-chap_files/figure-html/fig-countdata- lfcThresh-1.png" class="img-fluid">](08-chap_files/figure-html/fig-countdata-lfcThresh-1.png “Figure&nbsp;8.13: MA-plots of tests of \log_2 fold change with respect to a threshold value. From top to bottom, the tests are for altHypothesis =”greaterAbs”, “lessAbs”, “greater”, and “less”.”)</p>
<p>Figure 8.13: MA-plots of tests of \(_2\) fold change with respect to a threshold value. From top to bottom, the tests are for <code>altHypothesis = "greaterAbs"</code>, <code>"lessAbs"</code>, <code>"greater"</code>, and <code>"less"</code>.</p>
<p>To produce the results tables instead of MA plots, the same arguments as to <code>plotMA</code> (except <code>ylim</code>) would be provided to the <code>results</code> function.</p>
</section>
</section>
<section id="summary-of-this-chapter" class="level2" data-number="10.12">
<h2 data-number="10.12" class="anchored" data-anchor-id="summary-of-this-chapter"><span class="header-section-number">10.12</span> 8.11 Summary of this chapter</h2>
<p>We have seen how to analyze count tables from high-throughput sequencing (and analagous data types) for differential abundance. We built upon the powerful and elegant framework of linear models. In this framework, we can analyze a basic two-groups comparison as well as more complex multifactorial designs, or experiments with covariates that have more than two levels or are continuous. In ordinary linear models, the sampling distribution of the data around the expected value is assumed to be independent and normal, with zero mean and the same variances. For count data, the distributions are discrete and tend to be skewed (asymmetric) with highly different variances across the dynamic range. We therefore employed a generalization of ordinary linear models, called generalized linear models (GLMs), and in particular considered gamma-Poisson distributed data with dispersion parameters that we needed to estimate from the data.</p>
<p>Since the sampling depth is typically different for different sequencing runs (replicates), we need to estimate the effect of this variable parameter and take it into account in our model. We did this through the size factors \(s_i\). Often this part of the analysis is called <em>normalization</em> (the term is not particularly descriptive, but unfortunately it is now well-settled in the literature).</p>
<p>For designed experiments, the number of replicates is (and should be) usually too small to estimate the dispersion parameter (and perhaps even the model coefficients) from the data for each gene alone. Therefore we use shrinkage or empirical Bayes techniques, which promise large gains in precision for relatively small costs of bias.</p>
<p>While GLMs let us model the data on their original scale, sometimes it is useful to transform the data to a scale where the data are more homoskedastic and fill out the range more uniformly – for instance, for plotting the data, or for subjecting them to general purpose clustering, dimension reduction or learning methods. To this end, we saw the variance stabilizing transformation.</p>
<p>A major, and quite valid critique of differential expression testing such as exercised here is that the null hypothesis – the effect size is exactly zero – is almost never true, and therefore our approach does not provide consistent estimates of what the differentially expressed gene are. In practice, this may be overcome by considering effect size as well as statistical significance. Moreover, we saw how to use “banded” null hypotheses.</p>
</section>
<section id="further-reading" class="level2" data-number="10.13">
<h2 data-number="10.13" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">10.13</span> 8.12 Further reading</h2>
<ul>
<li><p>The <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> method is explained in the paper by Michael I. Love, Huber, and Anders (<a href="16-chap.html#ref-LoveDESeq2">2014</a>), and practical aspects of the software in the package vignette. See also the <strong><a href="https://bioconductor.org/packages/edgeR/">edgeR</a></strong> package and paper (<a href="16-chap.html#ref-edgeR:Robinson:2009">Robinson, McCarthy, and Smyth 2009</a>) for a related approach.</p></li>
<li><p>A classic textbook on robust regression and outlier detection is the book by Peter J. Rousseeuw and Leroy (<a href="16-chap.html#ref-Rousseeuw:RobustBook:1987">1987</a>). For more recent developments the <a href="https://cran.r-project.org/web/views/Robust.html">CRAN task view on Robust Statistical Methods</a> is a good starting point.</p></li>
<li><p>The Bioconductor RNA-Seq workflow at <a href="https://www.bioconductor.org/help/workflows/rnaseqGene" class="uri">https://www.bioconductor.org/help/workflows/rnaseqGene</a> (<a href="16-chap.html#ref-BiocRNASeqWorkflow">Michael I. Love et al.&nbsp;2015</a>) covers a number of issues related specifically to RNA-Seq that we have sidestepped here.</p></li>
<li><p>An extension of the generalized linear model that we saw to detecting alternative exon usage from RNA-Seq data is presented in the <strong><a href="https://bioconductor.org/packages/DEXSeq/">DEXSeq</a></strong> paper (<a href="16-chap.html#ref-Reyes:GnomeResearch:2012">Anders, Reyes, and Huber 2012</a>), and applications of these ideas to biological discovery were described by Reyes et al.&nbsp;(<a href="16-chap.html#ref-Reyes:PNAS:2013">2013</a>) and Reyes and Huber (<a href="16-chap.html#ref-Reyes:NAR:2017">2017</a>).</p></li>
<li><p>For some sequencing-based assays, such as RIP-Seq, CLIP-Seq, the biological analysis goal boils down to testing whether the ratio of <em>input</em> and <em>immunoprecipitate</em> (IP) has changed between conditions. Mike Love’s post on the Bioconductor forum provides a clear and quick how-to: <a href="https://support.bioconductor.org/p/61509" class="uri">https://support.bioconductor.org/p/61509</a>.</p></li>
</ul>
</section>
<section id="exercises" class="level2" data-number="10.14">
<h2 data-number="10.14" class="anchored" data-anchor-id="exercises"><span class="header-section-number">10.14</span> 8.13 Exercises</h2>
<p>__</p>
<p>Exercise 8.1</p>
<p><strong>Depletion of small p-values.</strong> Consider the following simple generative model for a histogram of p-values that shows a depletion of small p-values. In Figure 8.14, p-values are shown from a differential expression analysis (in this case, simple \(t\)-tests) in the absence of an association with the tested two-level categorical variable <code>groups</code>. While the histogram is approximately uniform for <code>x1</code>, small p-values are depleted for <code>x2</code>. This is because the batch (encoded by the eponymous variable), which is orthogonal to <code>groups</code> and balanced, introduces additional variability that inflates the denominator of the test statistic.</p>
<pre><code>library("magrittr")
ng = 10000
ns = 12
x1 = x2 = matrix(rnorm(ns * ng), ncol = ns, nrow= ng)
group = factor(letters[1 + seq_len(ns) %% 2])  %T&gt;% print __


 [1] b a b a b a b a b a b a
Levels: a b


batch = factor(ifelse(seq_len(ns) &lt;= ns/2, "B1", "B2")) %T&gt;% print __


 [1] B1 B1 B1 B1 B1 B1 B2 B2 B2 B2 B2 B2
Levels: B1 B2


table(group, batch)__


     batch
group B1 B2
    a  3  3
    b  3  3


x2[, batch=="B2"] = x2[, batch=="B2"] + 2 * rnorm(ng)
pvals = rbind(
  cbind(type = "x1", genefilter::rowttests(x1, fac = group)),
  cbind(type = "x2", genefilter::rowttests(x2, fac = group)))
ggplot(pvals, aes(x = p.value)) + 
  geom_histogram(binwidth = 0.02, boundary = 0) +
  facet_grid(type ~ .)__</code></pre>
<p>Replace the \(t\)-test by a linear model, first, one with only <code>group</code> as a factor, second, one with <code>group + batch</code> (in R’s formula language). Show that the histogram of p-values for the coefficient of <code>group</code> is uniform in both cases, <code>x1</code> and <code>x2</code>.</p>
<p><a href="08-chap_files/figure-html/fig-countdata-exbatch-1.png &quot;Figure 8.14: p-values for the tests performed on x1 and x2 (see code).&quot;"><img src="08-chap_files/figure-html/fig-countdata- exbatch-1.png" class="img-fluid"></a></p>
<p>Figure 8.14: p-values for the tests performed on <code>x1</code> and <code>x2</code> (see code).</p>
<p>__</p>
<p>Exercise 8.2</p>
<p><strong>edgeR.</strong> Do the analyses of Section 8.5 with the <strong><a href="https://bioconductor.org/packages/edgeR/">edgeR</a></strong> package and compare the results: make a scatterplot of the \(_{10}\) p-values, pick some genes where there are large differences, and visualize the raw data to see what is going on. Based on this can you explain the differences?</p>
<p>__</p>
<p>Exercise 8.3</p>
<p><strong>Robustness.</strong> Write a <strong><a href="https://cran.r-project.org/web/packages/shiny/">shiny</a></strong> app that performs linear regression on an example \((x, y)\) dataset (for instance, from the <code>mtcars</code> data) and displays the data as well as the fitted line. Add a widget that lets you move one of the points in \(x\)- and/or \(y\)- direction in a wide range (extending a few times outside the original data range). Add a radio buttons widget that lets you choose between <code>lm</code>, <code>rlm</code> and <code>lqs</code> with its different choices of <code>method</code> (the latter two are in the <strong><a href="https://cran.r-project.org/web/packages/MASS/">MASS</a></strong> package). Bonus: add functions from the <strong><a href="https://cran.r-project.org/web/packages/robustbase/">robustbase</a></strong> package.</p>
<p>__</p>
<p>Solution</p>
<p>__</p>
<p>Code for the file <code>ui.R</code> in the app:</p>
<pre><code>library("shiny")
shinyUI(fluidPage(
  titlePanel("Breakdown"),
  sidebarLayout(
    sidebarPanel(     # select oulier shift
      sliderInput("shift", "Outlier:", min = 0, max = 100, value = 0),
      radioButtons("method", "Method:",
                   c("Non-robust least squares" = "lm",
                     "M-estimation" = "rlm"))
    ),
    mainPanel(       # show fit
      plotOutput("regPlot")
    )
  )
))__</code></pre>
<p>Code for the file <code>server.R</code> in the app:</p>
<pre><code>library("shiny")
library("ggplot2")
library("MASS")
shinyServer(function(input, output) {
  output$regPlot = renderPlot({
    whpt = 15
    mtcars_new = mtcars
    mtcars_new$mpg[whpt] = mtcars_new$mpg[whpt] + input$shift
    reg = switch(input$method,
      lm = lm(mpg ~ disp, data = mtcars_new),
      rlm = rlm(mpg ~ disp, data = mtcars_new),
      stop("Unimplemented method:", input$method)
    )
    ggplot(mtcars_new, aes(x = disp, y = mpg)) + geom_point() +
      geom_abline(intercept = reg$coefficients["(Intercept)"],
                  slope = reg$coefficients["disp"], col = "blue")
  })
})__</code></pre>
<p>물론 더 많은 기능을 추가할 수 있습니다.</p>
<p>Anders, Simon, and Wolfgang Huber. 2010. “Differential Expression Analysis for Sequence Count Data.” <em>Genome Biology</em> 11: R106. <a href="http://genomebiology.com/2010/11/10/R106" class="uri">http://genomebiology.com/2010/11/10/R106</a>.</p>
<p>Anders, Simon, Alejandro Reyes, and Wolfgang Huber. 2012. “Detecting differential usage of exons from RNA-Seq data.” <em>Genome Research</em> 22 (10): 2008–17.</p>
<p>Brooks, Angela N, Li Yang, Michael O Duff, Kasper D Hansen, Jung W Park, Sandrine Dudoit, Steven E Brenner, and Brenton R Graveley. 2011. “Conservation of an RNA Regulatory Map Between Drosophila and Mammals.” <em>Genome Research</em> , 193–202. <a href="https://doi.org/10.1101/gr.108662.110" class="uri">https://doi.org/10.1101/gr.108662.110</a>.</p>
<p>Cook, R. Dennis. 1977. “Detection of Influential Observation in Linear Regression.” <em>Technometrics</em>.</p>
<p>Huber, Peter J. 1964. “Robust Estimation of a Location Parameter.” <em>The Annals of Mathematical Statistics</em> 35: 73–101.</p>
<p>Leek, Jeffrey T., and John D. Storey. 2007. “Capturing heterogeneity in gene expression studies by surrogate variable analysis.” <em>PLoS Genetics</em> 3 (9): 1724–35.</p>
<p>Love, Michael I., Simon Anders, Vladislav Kim, and Wolfgang Huber. 2015. “RNA- Seq Workflow: Gene-Level Exploratory Analysis and Differential Expression.” <em>F1000Research</em> 4 (1070). <a href="https://doi.org/10.12688/f1000research.7035.1" class="uri">https://doi.org/10.12688/f1000research.7035.1</a>.</p>
<p>Love, Michael I, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.” <em>Gnome Biology</em> 15 (12): 1–21.</p>
<p>Ozsolak, Fatih, and Patrice M Milos. 2011. “RNA sequencing: advances, challenges and opportunities.” <em>Nature Reviews Genetics</em> 12: 87–98.</p>
<p>Reyes, Alejandro, Simon Anders, Robert J. Weatheritt, Toby J. Gibson, Lars M. Steinmetz, and Wolfgang Huber. 2013. “Drift and Conservation of Differential Exon Usage Across Tissues in Primate Species.” <em>Proceedings of the National Academy of Sciences</em> 110 (38): 15377–82. <a href="https://doi.org/10.1073/pnas.1307202110" class="uri">https://doi.org/10.1073/pnas.1307202110</a>.</p>
<p>Reyes, Alejandro, and Wolfgang Huber. 2017. “Alternative Start and Termination Sites of Transcription Drive Most Transcript Isoform Differences Across Human Tissues.” <em>Nucleic Acids Research</em> 46 (2): 582–92. <a href="https://doi.org/10.1093/nar/gkx1165" class="uri">https://doi.org/10.1093/nar/gkx1165</a>.</p>
<p>Robinson, M. D., D. J. McCarthy, and G. K. Smyth. 2009. “edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.” <em>Bioinformatics</em> 26 (1): 139–40. <a href="https://doi.org/10.1093/bioinformatics/btp616" class="uri">https://doi.org/10.1093/bioinformatics/btp616</a>.</p>
<p>Rousseeuw, Peter J. 1987. “Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis.” <em>Journal of Computational and Applied Mathematics</em> 20: 53–65.</p>
<p>Rousseeuw, Peter J., and Annick M. Leroy. 1987. <em>Robust Regression and Outlier Detection</em>. Wiley. <a href="https://doi.org/10.1002/0471725382" class="uri">https://doi.org/10.1002/0471725382</a>.</p>
<p>Stegle, O., L. Parts, R. Durbin, and J. Winn. 2010. “A Bayesian framework to account for some complex non-genetic factors in gene expression levels greatly increases power in eQTL studies.” <em>PLoS Computational Biology</em> 6 (5): e1000770.</p>
<p>Steijger, T., J. F. Abril, P. G. Engstrom, F. Kokocinski, T. J. Hubbard, R. Guigo, J. Harrow, et al.&nbsp;2013. “Assessment of transcript reconstruction methods for RNA-seq.” <em>Nature Methods</em> 10 (12): 1177–84.</p>
<p>Verhulst, Pierre-François. 1845. “Recherches mathématiques Sur La Loi d’accroissement de La Population.” <em>Nouveaux Mémoires de l’Académie Royale Des Sciences Et Belles-Lettres de Bruxelles</em> 18: 1–42.</p>
<p>Page built at 01:33 on 2025-09-01 using R version 4.5.1 (2025-06-13)</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./07-chap.html" class="pagination-link" aria-label="7.1 이 장의 목표">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">7.1 이 장의 목표</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./09-chap.html" class="pagination-link" aria-label="9.1 이 장의 목표">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">9.1 이 장의 목표</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>