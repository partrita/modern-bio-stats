[![](imgs/xkcdmulttest-newspapertitle.png)](imgs/xkcdmulttest-
newspapertitle.png)

가설 검정(Hypothesis testing)은 과학의 핵심적인 도구 중 하나입니다. 이는 유한한 데이터 표본을 바탕으로 결론을 내리거나 결정을 내리는 방법입니다. 예를 들어, 질병에 대한 새로운 치료법은 대개 임상 시험을 바탕으로 승인됩니다. 임상 시험은 해당 치료법이 다른 가용한 선택지에 비해 더 나은 효능을 보이는지, 그리고 부작용과의 상충 관계(trade-off)가 수용 가능한지를 결정하는 것을 목표로 합니다. 이러한 시험은 비용이 많이 들고 오랜 시간이 걸릴 수 있습니다. 따라서 모집할 수 있는 환자 수는 제한적이며, 우리는 관찰된 제한된 환자 반응 표본을 바탕으로 추론을 해야 합니다. 환자의 반응은 치료뿐만 아니라 우리가 통제할 수 없는 많은 다른 요인들에 의존하기 때문에 데이터에는 노이즈가 섞여 있습니다. 신뢰할 수 있는 결론을 내리기 위해서는 표본 크기가 충분히 커야 합니다. 반면, 소중한 자원이나 시간을 낭비하지 않도록 표본 크기가 너무 커서도 안 됩니다. 예를 들어, 약값을 필요 이상으로 비싸게 만들거나 새로운 약의 혜택을 볼 수 있는 환자들에게 접근 기회를 박탈해서는 안 되기 때문입니다. 가설 검정의 메커니즘은 오늘날 훨씬 더 널리 사용되고 있긴 하지만, 주로 이러한 응용 분야를 염두에 두고 개발되었습니다.

생물학적 데이터 분석(및 다른 많은 분야1)에서 가설 검정은 수천 또는 수백만 개의 가능한 가설들을 스크리닝하여 후속 연구를 진행할 가치가 있는 가설을 찾는 데 적용됩니다. 예를 들어, 연구자들은 유전적 변이와 표현형 간의 연관성이나, 유전자 발현 수준과 질병 간의 연관성을 스크리닝합니다. 여기서 "가치 있는" 것은 종종 "통계적으로 유의미한" 것으로 해석되지만, 이 두 개념이 분명히 같은 것은 아닙니다. 통계적 유의성은 흥미로운 것을 찾기 위한 데이터 기반 의사결정의 필요조건이긴 하지만, 충분조건은 아니라고 말하는 것이 타당할 것입니다. 어쨌든, 이러한 대규모 연관성 스크리닝은 다중 가설 검정(multiple hypothesis testing)과 밀접하게 관련되어 있습니다.

1 신용카드 사기 탐지, 이메일 스팸 탐지, \\(...\\)

## 6.1 이 장의 목표

이 장에서 우리는 다음을 수행할 것입니다:

  * 가설 검정의 통계적 메커니즘, 용어, 목적, 그리고 강점과 한계에 익숙해집니다.

  * 다중 검정(multiple testing)이 무엇을 의미하는지 이해합니다.

  * 다중 검정이 문제가 아니라, 오히려 단일 검정의 많은 한계를 극복할 수 있게 해주는 기회임을 확인합니다.

  * 허위 발견율(false discovery rate, FDR)을 이해합니다.

  * 진단 플롯(diagnostic plots)을 만드는 방법을 배웁니다.

  * 분석의 검정력(power)을 높이기 위해 가설 가중치(hypothesis weighting)를 사용합니다.

### 6.1.1 쏟아지는 데이터 속에서 정보 찾기

[![](imgs/active-substance-discovery-robot-screening-robot.jpg)](imgs/active-
substance-discovery-robot-screening-robot.jpg "그림 6.1: 현대 생물학의 고처리량 데이터는 수백만 개의 가설 검정을 통해 연관성을 스크리닝합니다. (출처: 바이엘)")

그림 6.1: 현대 생물학의 고처리량 데이터는 수백만 개의 가설 검정을 통해 연관성을 스크리닝합니다. ([출처: 바이엘](https://www.research.bayer.com/en/automated-search-for-active-ingredients-with-robots.aspx))

만약 통계적 검정(불확실성을 동반한 의사결정)이 단 한 번의 결정을 내릴 때도 어려운 과제처럼 느껴진다면, 마음을 단단히 먹으십시오: 유전체학이나 더 일반적으로 "빅데이터" 분야에서는 이를 한 번이 아니라 수천 번 또는 수백만 번 수행해야 합니다. [2장](02-chap.html)에서 우리는 에피토프 검출의 예와 단 한 곳이 아닌 여러 위치를 고려할 때의 어려움을 보았습니다. 유사하게, 전유전체 시퀀싱(whole genome sequencing)에서는 손에 든 DNA 시퀀싱 데이터와 참조 서열(또는 다른 시퀀싱 데이터 세트) 간의 차이에 대한 증거를 찾기 위해 게놈의 모든 위치를 스캔합니다. 인간 데이터를 보고 있다면 이는 약 60억 번의 검정에 해당합니다! 유전자 또는 화학 화합물 스크리닝에서는 대조군과 비교하여 각 시약이 어세이(assay)에서 효과를 나타내는지 테스트하는데, 이 역시 수만 번에서 수백만 번의 검정이 이루어집니다. [8장](08-chap.html)에서 우리는 측정된 수천 개의 유전자 각각에 대해 가설 검정을 적용하여 RNA-Seq 데이터의 차등 발현을 분석할 것입니다.

### 6.1.2 검정 대 분류

우리가 연구하고 있는 세포가 상태 A에 있는지 B에 있는지 결정하기 위해 마커 분자의 농도를 측정했다고 가정해 봅시다. 먼저, 사전 가정이 없으며 데이터를 사용하여 두 결과 중 하나를 다소 대칭적으로 선택하고 싶다고 가정해 보겠습니다. 이것은 _분류(classification)_ 작업입니다. 분류에 대해서는 [12장](12-chap.html)에서 다룰 것입니다. 이 장에서는 비대칭적인 경우를 고려합니다: 우리가 이미 알고 있는 것(_사전_ 지식)에 기초하여 세포 상태 A가 지배적이며 "기본(default)" 상태입니다. 충분히 강력한 증거가 있을 때만 B라고 판정할 것입니다. 아마도 B는 드물고, 특이하며, 흥미로운 것이어서 이를 발견하면 더 연구하기 위해 자원을 투입할 것입니다. 반면 A는 흥미롭지 않으며 추가 후속 조치가 필요하지 않습니다. 이러한 경우에 가설 검정의 메커니즘이 우리에게 필요합니다.

형식적으로 가설 검정과 분류 사이에는 많은 유사점이 있습니다. 두 경우 모두 데이터를 사용하여 여러 가능한 결정 중 하나를 선택하는 것을 목표로 합니다. 그 구분이 모호할 수 있으며, 가설 검정을 분류의 특수한 사례로 생각하는 것도 가능합니다. 그러나 이 두 접근 방식은 서로 다른 목적과 기저의 가정을 지향합니다. 통계적 의사결정 문제에 직면했을 때 어떤 접근 방식이 더 적절한지 확인하는 것이 유용할 수 있습니다.

### 6.1.3 허위 발견율인가, p-값인가?

[![](06-chap_files/figure-html/fig-testing-
FDRvspstatic1-1.png)](06-chap_files/figure-html/fig-testing-
FDRvspstatic1-1.png "그림 6.2: 이진(예/아니오) 결정 내리기. 여기서는 x축을 따라 표시된 어떤 연속형 점수 x를 바탕으로 두 가지 가능한 결정을 \"양성(positive)\"과 \"음성(negative)\"으로 부릅니다. 파란색으로 음영 처리된 곡선은 클래스 중 하나(음성)에 대한 x의 분포 밀도를 보여주고, 빨간색으로 음영 처리된 곡선은 다른 클래스(양성)에 대한 것을 보여줍니다. 두 분포는 뚜렷이 구분되지만(빨간색 값들이 일반적으로 더 낮음), 일부 중첩되는 영역이 있습니다. 검은색 수직 막대는 결정 경계의 선택을 나타내며, 이는 색상 키로 강조된 네 가지 가능한 결과를 가져옵니다.")

그림 6.2: 이진(예/아니오) 결정 내리기. 여기서는 \(x\)축을 따라 표시된 어떤 연속형 점수 \\(x\\)를 바탕으로 두 가지 가능한 결정을 "양성(positive)"과 "음성(negative)"으로 부릅니다. 파란색으로 음영 처리된 곡선은 클래스 중 하나(음성)에 대한 \\(x\\)의 분포 밀도를 보여주고, 빨간색으로 음영 처리된 곡선은 다른 클래스(양성)에 대한 것을 보여줍니다. 두 분포는 뚜렷이 구분되지만(빨간색 값들이 일반적으로 더 낮음), 일부 중첩되는 영역이 있습니다. 검은색 수직 막대는 결정 경계의 선택을 나타내며, 이는 색상 키로 강조된 네 가지 가능한 결과를 가져옵니다.

[![](06-chap_files/figure-html/fig-testing-
FDRvspstatic2-1.png)](06-chap_files/figure-html/fig-testing-
FDRvspstatic2-1.png "그림 6.3: 그림 6.2와 유사하지만, 이제 결과로 나오는 파란색 분포가 균등 분포(uniform distribution)가 되도록 비선형적이고 엄격하게 증가하는 변환 함수 p=f(x)를 사용하여 x를 원래 범위에서 [0,1] 범위로 변환했습니다. 그러한 함수는 항상 존재합니다: 그것은 x의 누적 분포 함수입니다(이는 3.6.7절에서 보았습니다). 우리는 그 결과를 p-값(p-value)이라고 부릅니다. 식 6.2의 FDR 정의는 그림 6.2와 여기 모두에 동일하게 적용됩니다.")

그림 6.3: 그림 6.2와 유사하지만, 이제 결과로 나오는 파란색 분포가 균등 분포(uniform distribution)가 되도록 비선형적이고 엄격하게 증가하는 변환 함수 \\(p=f(x)\\)를 사용하여 \\(x\\)를 원래 범위에서 \\([0,1]\\) 범위로 변환했습니다. 그러한 함수는 항상 존재합니다: 그것은 \\(x\\)의 누적 분포 함수입니다(이는 [3.6.7절](03-chap.html#sec-graphics-ecdf)에서 보았습니다). 우리는 그 결과를 **p-값(p-value)**이라고 부릅니다. 식 6.2의 FDR 정의는 그림 6.2와 여기 모두에 동일하게 적용됩니다.

[![](06-chap_files/figure-html/fig-testing-
FDRvspanim-1.gif)](06-chap_files/figure-html/fig-testing-FDRvspanim-1.gif
"그림 6.4: 이 애니메이션은 의사 결정을 위해 (그림 6.2에서처럼) 일반적인 점수 x를 사용하는 것과 (그림 6.3에서처럼) 공식적인 가설 검정에서 얻은 p-값을 사용하는 것 사이의 유사성을 강조합니다. 우리는 6.10절과 그림 6.17에서 두 그룹 모델(two-group model)의 관점에서 이러한 개념들로 다시 돌아올 것입니다.")

그림 6.4: 이 애니메이션은 의사 결정을 위해 (그림 6.2에서처럼) 일반적인 점수 \\(x\\)를 사용하는 것과 (그림 6.3에서처럼) 공식적인 가설 검정에서 얻은 p-값을 사용하는 것 사이의 유사성을 강조합니다. 우리는 6.10절과 그림 6.17에서 두 그룹 모델(two-group model)의 관점에서 이러한 개념들로 다시 돌아올 것입니다.

가설 검정은 전통적으로 p-값을 가장 먼저 가르쳐왔으며, 이를 근원적이고 기본적인 개념으로 소개해 왔습니다. 다중 검정과 허위 발견율은 그 후에 파생된 추가적인 아이디어로 제시되었습니다. 그렇게 하는 데에는 수학적, 실무적으로 타당한 이유가 있으며, 이 장의 나머지 부분도 이러한 전통을 따릅니다. 그러나 이 서론 섹션에서 우리는 허위 발견율이 사실 더 직관적인 개념이며, 실무에서도 더 유용한 경향이 있다는 점을 지적하고 싶습니다. p-값은 좀 더 추상적인 것이며, 종종 그것을 가지고 무엇을 해야 할지 명확하지 않아서 의사결정에 p-값을 사용하려는 사람들을 계속 혼란스럽게 합니다. 그래서 여기서는 교육적인 관점에서 순서를 뒤집어 허위 발견율에 대해 먼저 배워보고자 합니다. 그러면 p-값은 허위 발견율에 접근할 수 없을 때 의지해야 하는 차선책(second-best) 정도로 생각할 수 있습니다.

이진 결정 문제를 나타내는 그림 6.2를 고려해 봅시다. 요약 통계량 \\(x\\)가 특히 작을 때, 즉 수직 검은색 막대의 왼쪽에 떨어질 때마다 이를 _발견(discovery)_이라고 부른다고 합시다2. 그러면 _허위 발견율_3(FDR)은 단순히 모든 발견 중 잘못된 발견의 비율입니다. 즉:

2 이는 "일반성을 잃지 않고" 하는 말입니다: \(x\)축을 뒤집어서 높은 점수를 가진 것을 발견이라고 부를 수도 있습니다.

3 이는 다소 비공식적인 정의입니다. 더 정확한 정의는 예를 들어 ([Storey 2003](16-chap.html#ref-Storey:AnnStat:2003); [Efron 2010](16-chap.html#ref-Efron2010)) 및 6.10절을 참조하십시오.

\\[ \text{FDR}=\frac{\text{연한 파란색으로 표시된 영역}}{\text{수직 막대 왼쪽 영역의 합(연한 파란색 + 짙은 빨간색)}}. \tag{6.1}\\]

FDR은 결정 임계값(수직 막대)의 위치뿐만 아니라 두 분포의 형태와 위치, 그리고 그들의 상대적인 크기에도 의존합니다. 그림 6.2와 6.3에서 전체 파란색 영역은 전체 빨간색 영역보다 두 배 더 큰데, 이는 (이 예제에서) 파란색 클래스가 빨간색 클래스보다 두 배 더 흔하다(또는 사전적으로 두 배 더 가능성이 높다)는 사실을 반영합니다.

이 정의에는 p-값의 개념이나 계산이 필요하지 않다는 점에 주목하세요. 이는 임의로 정의된 어떤 점수 \\(x\\)에 대해서도 작동합니다. 그러나 다음 세 가지에 대한 지식이 필요합니다:

  1. 파란색 클래스에서의 \\(x\\)의 분포(파란색 곡선),

  2. 빨간색 클래스에서의 \\(x\\)의 분포(빨간색 곡선),

  3. 파란색 클래스와 빨간색 클래스의 상대적 크기.

만약 이들을 안다면, 기본적으로 이 시점에서 작업은 끝난 것입니다. 또는 그림 6.2를 다변량 \\(x\\)로 확장하는 문제를 다루는 [12장](12-chap.html)의 비지도 분류로 넘어갈 수 있습니다.

하지만 매우 자주 우리는 이 모든 것을 알지 못하며, 이것이 바로 가설 검정의 영역입니다. 특히, 두 클래스 중 하나(예를 들어 파란색 클래스)가 다른 클래스보다 더 쉽고, 제1원리나 시뮬레이션을 통해 그 분포를 알아낼 수 있다고 가정해 봅시다. 우리는 그 사실을 사용하여 점수 \\(x\\)를 0과 1 사이의 표준화된 범위(그림 6.2—6.4 참조)로 변환하는데, 이를 _p-값_이라고 부릅니다. 그리고 그 클래스에 _귀무 가설(null hypothesis)_이라는 멋진 이름을 붙입니다. 이것이 위의 목록에서 1번을 해결합니다. 우리는 2번을 아는 데 집착하지 않으며(그리고 빨간색 클래스에 _대립 가설(alternative hypothesis)_이라는 또 다른 멋진 이름을 붙입니다), 3번에 대해서는 귀무 가설이 대립 가설보다 훨씬 더 흔하다(또는 가능성이 높다)는 보수적인 상한선을 사용하고 귀무 가설이 참이라는 조건 하에서 계산을 수행할 수 있습니다. 이것이 가설 검정에 대한 전통적인 접근 방식입니다.

따라서 직관적인 FDR(식 6.2)에 기초하여 의사결정을 내리는 대신, 우리는 다음 수치에 기초합니다.

\\[ \text{p-value}=\frac{\text{연한 파란색으로 표시된 영역}}{\text{전체 파란색 영역}}. \tag{6.2}\\]

다시 말해, p-값은 다소 복잡한 질문(그리고 어쩌면 잘못된 질문)에 대한 정확하고 종종 상대적으로 계산하기 쉬운 답입니다. FDR은 올바른 질문에 답하지만, 우리가 종종 가지고 있지 않은 훨씬 더 많은 입력을 필요로 합니다.

### 6.1.4 다중 검정의 기회

다중 검정에 대한 좋은 소식이 있습니다: 비록 우리가 위 목록의 2번과 3번 항목을 개별 검정에 대해 명시적으로 알지 못하더라도(그리고 어쩌면 1번에 대해서조차 확신이 없더라도 ([Efron 2010](16-chap.html#ref-Efron2010))), 우리는 다중성(multiplicity)으로부터 이 정보를 추론할 수 있고, 따라서 p-값을 FDR 추정치로 변환할 수 있을지 모릅니다!

따라서 다중 검정은 우리의 추론을 더 좋게 만들고 우리의 과업을 더 단순하게 만드는 경향이 있습니다. 데이터가 아주 많기 때문에 우리는 추상적인 가정에만 의존할 필요가 없습니다. 검정의 요구 사항이 실제로 데이터에 의해 충족되는지 경험적으로 확인할 수 있습니다. 이 모든 것이 믿을 수 없을 정도로 도움이 될 수 있으며, 우리는 이를 다중성 _덕분에_ 얻게 됩니다. 그러므로 우리는 다중 검정을 "문제"나 "부담"이 아니라 기회로 생각해야 합니다!

## 6.2 예시: 동전 던지기

이제 단일 검정부터 시작하여 가설 검정에 대해 깊이 파고들어 봅시다. 메커니즘을 제대로 이해하기 위해 가장 간단한 예제 중 하나를 사용합니다: 어떤 동전이 공정한지4 확인하기 위해 동전을 던진다고 가정해 봅시다. 동전을 100번 던지고 매번 앞면이 나왔는지 뒷면이 나왔는지 기록합니다. 그러면 다음과 같은 기록을 갖게 될 것입니다:

4 동전 던지기가 본질적으로 중요해서가 아니라, (생물학에서 모델 시스템을 사용하는 것처럼) 쉬운 "모델 시스템"이기 때문에 살펴보는 것입니다: 모든 것을 쉽게 계산할 수 있고, 동전 던지기가 무엇인지 이해하는 데 많은 도메인 지식이 필요하지 않습니다. 모든 중요한 개념들이 등장하며, 우리는 이를 더 많은 추가 세부 사항과 함께 다른 응용 분야에 적용할 수 있습니다.

HHTTHTHTT…

이를 R에서 시뮬레이션할 수 있습니다. 편향된 동전을 던진다고 가정하고, `probHead`를 1/2이 아닌 값으로 설정해 보겠습니다:

    
    
    set.seed(0xdada)
    numFlips = 100
    probHead = 0.6
    coinFlips = sample(c("H", "T"), size = numFlips,
      replace = TRUE, prob = c(probHead, 1 - probHead))
    head(coinFlips)__
    
    
    [1] "T" "T" "H" "T" "H" "H"

이제 동전이 공정하다면 앞면이 절반 정도 나올 것으로 기대할 것입니다. 확인해 봅시다.

    
    
    table(coinFlips)__
    
    
    coinFlips
     H  T 
    59 41 

결과가 50/50과는 다릅니다. 친구에게 동전이 공정한지 알려주지 않고 이 데이터를 보여주었다고 가정해 봅시다. 그 친구의 사전 가정, 즉 귀무 가설은 동전이 대체로 공정하다는 것입니다. 이 데이터가 동전이 공정하지 않다고 결론 내리기에 충분히 강력할까요? 친구는 무작위 표집에 따른 차이가 발생할 수 있다는 것을 알고 있습니다. 이를 결정하기 위해 공정한 동전에 대한5 우리의 검정 통계량(100번의 동전 던지기에서 나타난 앞면의 총 횟수)의 표집 분포를 살펴봅시다. [1장](01-chap.html)에서 보았듯이, 동전을 독립적으로 \\(n\\)번 던졌을 때 앞면의 횟수 \\(k\\)는 다음과 같습니다.

5 공정하다는 것이 무엇을 의미하는지 아직 제대로 정의하지 않았습니다 – 앞면과 뒷면이 나올 확률이 같고, 각 동전 던지기의 결과가 이전 결과에 의존하지 않는다는 것이 합리적인 정의일 것입니다. 더 복잡한 응용 분야의 경우,...
nailing down the most suitable null hypothesis can take some thought.

\\[ P(K=k\,|\,n, p) = \left(\begin{array}{c}n\\\k\end{array}\right)
p^k\;(1-p)^{n-k}, \tag{6.3}\\]

where \\(p\\) is the probability of heads (0.5 if we assume a fair coin). We
read the left hand side of the above equation as “the probability that the
observed value for \\(K\\) is \\(k\\), given the values of \\(n\\) and
\\(p\\)”. Statisticians like to make a difference between all the possible
values of a statistic and the one that was observed6, and we use the upper
case \\(K\\) for the possible values (so \\(K\\) can be anything between 0 and
100), and the lower case \\(k\\) for the observed value.

6 In other words, \\(K\\) is the abstract random variable in our probabilistic
model, whereas \\(k\\) is its realization, that is, a specific data point.

We plot Equation 6.3 in Figure 6.5; for good measure, we also mark the
observed value `numHeads` with a vertical blue line.

    
    
    library("dplyr")
    k = 0:numFlips
    numHeads = sum(coinFlips == "H")
    binomDensity = tibble(k = k,
         p = dbinom(k, size = numFlips, prob = 0.5))__
    
    
    library("ggplot2")
    ggplot(binomDensity) +
      geom_bar(aes(x = k, y = p), stat = "identity") +
      geom_vline(xintercept = numHeads, col = "blue")__

[![](06-chap_files/figure-html/fig-testing-
dbinom-1.png)](06-chap_files/figure-html/fig-testing-dbinom-1.png "Figure 6.5:
The binomial distribution for the parameters n=100 and p=0.5, according to
Equation eq-testing-dbinom.")

Figure 6.5: The binomial distribution for the parameters \\(n=100\\) and
\\(p=0.5\\), according to Equation 6.3.

Suppose we didn’t know about Equation 6.3. We can still use Monte Carlo
simulation to give us something to compare with:

    
    
    numSimulations = 10000
    outcome = replicate(numSimulations, {
      coinFlips = sample(c("H", "T"), size = numFlips,
                         replace = TRUE, prob = c(0.5, 0.5))
      sum(coinFlips == "H")
    })
    ggplot(tibble(outcome)) + xlim(-0.5, 100.5) +
      geom_histogram(aes(x = outcome), binwidth = 1, center = 50) +
      geom_vline(xintercept = numHeads, col = "blue")__

[![](06-chap_files/figure-html/fig-rbinom-1.png)](06-chap_files/figure-
html/fig-rbinom-1.png "Figure 6.6: An approximation of the binomial
distribution from 10000 simulations \(same parameters as Figure fig-testing-
dbinom\).")

Figure 6.6: An approximation of the binomial distribution from \\(10000\\)
simulations (same parameters as Figure 6.5).

As expected, the most likely number of heads is 50, that is, half the number
of coin flips. But we see that other numbers near 50 are also quite likely.
How do we quantify whether the observed value, 59, is among those values that
we are likely to see from a fair coin, or whether its deviation from the
expected value is already large enough for us to conclude with enough
confidence that the coin is biased? We divide the set of all possible \\(k\\)
(0 to 100) in two complementary subsets, the **rejection region** and the
region of no rejection. Our choice here7 is to fill up the rejection region
with as many \\(k\\) as possible while keeping their total probability,
assuming the null hypothesis, below some threshold \\(\alpha\\) (say, 0.05).

7 More on this in Section 6.3.1.

In the code below, we use the function `arrange` from the
**[dplyr](https://cran.r-project.org/web/packages/dplyr/)** package to sort
the p-values from lowest to highest, then pass the result to `mutate`, which
adds another dataframe column `reject` that is defined by computing the
cumulative sum (`cumsum`) of the p-values and thresholding it against `alpha`.
The logical vector `reject` therefore marks with `TRUE` a set of `k`s whose
total probability is less than `alpha`. These are marked in Figure 6.7, and we
can see that our rejection region is not contiguous – it comprises both the
very large and the very small values of `k`.

    
    
    library("dplyr")
    alpha = 0.05
    binomDensity = arrange(binomDensity, p) |>
            mutate(reject = (cumsum(p) <= alpha))
    
    ggplot(binomDensity) +
      geom_bar(aes(x = k, y = p, col = reject), stat = "identity") +
      scale_colour_manual(
        values = c(`TRUE` = "red", `FALSE` = "darkgrey")) +
      geom_vline(xintercept = numHeads, col = "blue") +
      theme(legend.position = "none")__

[![](06-chap_files/figure-html/fig-testing-
findrej-1.png)](06-chap_files/figure-html/fig-testing-findrej-1.png
"Figure 6.7: As Figure fig-testing-dbinom, with rejection region \(red\) that
has been chosen such that it contains the maximum number of bins whose total
area is at most \\alpha=0.05.")

Figure 6.7: As Figure 6.5, with rejection region (red) that has been chosen
such that it contains the maximum number of bins whose total area is at most
\\(\alpha=0.05\\).

The explicit summation over the probabilities is clumsy, we did it here for
pedagogic value. For one-dimensional distributions, R provides not only
functions for the densities (e.g., `dbinom`) but also for the cumulative
distribution functions (`pbinom`), which are more precise and faster than
`cumsum` over the probabilities. These should be used in practice.

__

Task

Do the computations for the rejection region and produce a plot like Figure
6.7 without using `dbinom` and `cumsum`, and with using `pbinom` instead.

We see in Figure 6.7 that the observed value, 59, lies in the grey shaded
area, so we would _not_ reject the null hypothesis of a fair coin from these
data at a significance level of \\(\alpha=0.05\\).

__

Question 6.1

Does the fact that we don’t reject the null hypothesis mean that the coin is
fair?

__

Question 6.2

Would we have a better chance of detecting that the coin is not fair if we did
more coin tosses? How many?

__

Question 6.3

If we repeated the whole procedure and again tossed the coin 100 times, might
we _then_ reject the null hypothesis?

__

Question 6.4

The rejection region in Figure 6.7 is asymmetric – its left part ends with
\\(k=40\\), while its right part starts with \\(k=61\\). Why is that? Which
other ways of defining the rejection region might be useful?

We have just gone through the steps of a binomial test. In fact, this is such
a frequent activity in R that it has been wrapped into a single function, and
we can compare its output to our results.

    
    
    binom.test(x = numHeads, n = numFlips, p = 0.5)__
    
    
        Exact binomial test
    
    data:  numHeads and numFlips
    number of successes = 59, number of trials = 100, p-value = 0.08863
    alternative hypothesis: true probability of success is not equal to 0.5
    95 percent confidence interval:
     0.4871442 0.6873800
    sample estimates:
    probability of success 
                      0.59 

## 6.3 가설 검정의 5단계

가설 검정의 일반적인 원칙을 요약해 보겠습니다:

  1. 관심 있는 효과를 결정하고, 적절한 실험이나 연구를 설계하며, 데이터 요약 함수와 **검정 통계량(test statistic)**을 선택합니다.

  2. **귀무 가설(null hypothesis)**을 설정합니다. 이는 귀무 가설이 참이라는 가정하에 검정 통계량의 가능한 결과와 그 확률인 **귀무 분포(null distribution)**를 계산할 수 있게 해주는, 단순하고 계산 가능한 현실 모델입니다.

  3. **기각역(rejection region)**을 결정합니다. 즉, 전체 확률이 매우 작은8 가능한 결과들의 하위 집합을 선택합니다.

  4. 실험을 수행하고 데이터를 수집합니다9. 검정 통계량을 계산합니다.

  5. 결정을 내립니다: 검정 통계량이 기각역에 있으면 귀무 가설을 기각합니다10.

8 이에 대한 자세한 내용은 6.3.1절을 참조하십시오.

9 또는 다른 누군가가 이미 수행했다면 그들의 데이터를 다운로드하십시오.

10 즉, 그것이 참일 가능성이 낮다고 결론 내립니다.

이 이상적인 워크플로에서 우리는 데이터를 보기 전인 1~3단계에서 모든 중요한 결정을 내린다는 점에 주목하십시오. 서론(그림 [1](00-chap.html#fig-Fisher) 및 [2](00-chap.html#fig-iterative))에서 이미 언급했듯이, 이는 종종 현실적이지 않습니다. 우리는 6.6절에서 이 문제로 다시 돌아올 것입니다.

위의 예에서 사용한 귀무 가설에도 이상화가 있었습니다: 우리는 공정한 동전이 정확히 0.5의 확률을 가져야 하며(예를 들어 0.500001이 아니라), 던지기 사이에 절대적으로 의존성이 없어야 한다고 가정했습니다. 공기 저항, 동전이 떨어지는 재료의 탄성 등 발생 가능한 효과에 대해서는 걱정하지 않았습니다. 이는 귀무 가설이 이항 분포를 통해 계산 가능하다는 이점을 주었습니다. 여기서 이러한 이상화는 그리 논란의 여지가 없어 보일 수 있지만, 다른 상황에서는 귀무 가설이 얼마나 다루기 쉬운가와 얼마나 현실적인가 사이의 상충 관계(trade-off)가 더 클 수 있습니다. 문제는 귀무 가설이 처음부터 너무 이상화되어 있다면, 그것을 기각하는 것이 그리 흥미롭지 않다는 것입니다. 결과가 오도될 수 있으며, 확실히 우리는 시간을 낭비하고 있는 것입니다.

우리 예에서의 검정 통계량은 앞면의 총 횟수였습니다. 만약 우리가 뒷면이 연속으로 50번 나오고, 그 다음 앞면이 연속으로 50번 나오는 것을 관찰했다고 가정해 봅시다. 우리의 검정 통계량은 결과의 순서를 무시하므로, 우리는 이것이 완벽하게 공정한 동전이라고 결론 내릴 것입니다. 그러나 만약 우리가 뒷면이 두 번 연속으로 나오는 횟수와 같은 다른 검정 통계량을 사용했다면, 이 동전에 뭔가 이상한 점이 있다는 것을 알아챘을지도 모릅니다.

__

질문 6.5

이 다른 검정 통계량의 귀무 분포는 무엇일까요?

__

질문 6.6

그 통계량에 기반한 검정이 일반적으로 더 선호될까요?

__

해결책

__

아니요, 동전 던지기 사이의 그러한 상관관계를 감지하는 데는 더 큰 검정력을 갖지만, 결과의 편향(bias)을 감지하는 데는 검정력이 더 _낮습니다_.

우리가 방금 한 일은 두 가지 서로 다른 종류의 **대립 가설(alternative hypotheses)**을 살펴본 것입니다. 첫 번째 종류의 대립 가설은 연속적인 동전 던지기가 여전히 서로 독립적이지만 앞면의 확률이 0.5가 아니라는 것이었습니다. 두 번째는 앞면의 전체 확률은 여전히 0.5일 수 있지만 연속적인 동전 던지기가 상관관계가 있다는 것이었습니다.

__

질문 6.7

[1장](01-chap.html)의 충분 통계량(sufficient statistics) 개념을 상기해 보세요. 앞면의 총 횟수는 이항 분포에 대한 충분 통계량인가요? 왜 그것이 첫 번째 종류의 대립 가설에 대해서는 좋은 검정 통계량이 될 수 있지만, 두 번째 종류에 대해서는 그렇지 않을까요?

그러므로 우리는 일반적으로 여러 가지 가능한 검정 통계량 선택지가 있음을 기억합시다 (원칙적으로는 데이터의 어떤 수치적 요약도 될 수 있습니다). 좋은 검정력11을 가진 검정을 얻기 위해서는 올바른 선택을 하는 것이 중요합니다. 올바른 선택이 무엇인지는 우리가 어떤 종류의 대립 가설을 예상하느냐에 달려 있습니다. 이를 미리 아는 것이 항상 쉬운 것은 아닙니다.

11 [1.4.1절](01-chap.html#sec-generative-SimulatingForPower) 및 6.4절을 참조하십시오.

12 가정이 _정확히_ 참일 필요는 없습니다 – 이론의 예측이 진실에 대한 수용 가능한 근사치라면 충분합니다.

일단 검정 통계량을 선택했다면 그것의 귀무 분포를 계산해야 합니다. 이는 종이와 연필로 할 수도 있고 컴퓨터 시뮬레이션으로 할 수도 있습니다. 종이와 연필을 이용한 해결책은 모수적(parametric)이며 (식 6.3과 같은) 닫힌 형태의 수학적 표현으로 이어지는데, 이는 귀무 가설의 모델 매개변수(\\(n, p\\) 등) 범위에 대해 유효하다는 장점이 있습니다. 또한 특정 매개변수 세트에 대해 빠르게 계산될 수 있습니다. 하지만 항상 동전 던지기 예제처럼 쉬운 것은 아닙니다. 때로는 종이와 연필을 이용한 해결책을 계산하는 것이 불가능할 정도로 어려울 때도 있습니다. 다른 경우에는 단순화 가정이 필요할 수 있습니다. 한 예로 (이 장의 뒷부분에서 살펴볼) \\(t\\)-통계량에 대한 귀무 분포가 있습니다. 데이터가 독립적이고 정규 분포를 따른다고 가정하면 이를 계산할 수 있는데, 그 결과를 \\(t\\)-분포라고 부릅니다. 이러한 모델링 가정은 현실적일 수도 있고 그렇지 않을 수도 있습니다. 귀무 분포를 시뮬레이션하는 것은 잠재적으로 더 정확하고 현실적이며 아마도 더 직관적인 접근 방식을 제공합니다. 시뮬레이션의 단점은 시간이 꽤 오래 걸릴 수 있고, 매개변수 변화가 결과에 어떤 영향을 미치는지 체계적으로 이해하기 위해 추가적인 작업이 필요하다는 점입니다. 일반적으로 모수적 이론이 적용될 때는 이를 사용하는 것이 더 우아합니다12. 의심스러울 때는 시뮬레이션을 하거나, 둘 다 하십시오.

### 6.3.1 기각역

여러분의 검정에 적합한 기각역을 어떻게 선택할까요? 먼저, 그 크기는 얼마여야 할까요? 그것은 여러분이 선택한 **유의 수준(significance level)** 또는 위양성률(false positive rate) \\(\alpha\\)이며, 이는 귀무 가설이 참이더라도 검정 통계량이 이 영역에 떨어질 전체 확률입니다13.

13 어떤 시점에 어떤 사람들이 특정 질문 세트에 대해 \\(\alpha=0.05\\)를 "작다"고 공모했습니다. 하지만 이 숫자에는 특별한 것이 없으며, 어떤 경우에도 결정 임계값에 대한 최선의 선택은 문맥에 따라 크게 달라질 수 있습니다 ([Wasserstein and Lazar 2016](16-chap.html#ref-Wasserstein2016:ASA); [Altman and Krzywinski 2017](16-chap.html#ref-Altman:PoS:2017)).

크기가 주어졌을 때, 다음 질문은 형태에 관한 것입니다. 주어진 크기에 대해 대개 여러 가지 가능한 형태가 존재합니다. 대립 가설이 참일 때 검정 통계량이 기각역에 떨어질 확률이 가능한 한 커야 한다는 요구 조건은 타당합니다. 다시 말해, 우리는 우리의 검정이 높은 **검정력(power)**, 즉 진양성률(true positive rate)을 갖기를 원합니다.

그림 6.7의 기각역을 계산하는 코드에서 사용한 기준은 그 영역이 가능한 한 많은 `k`를 포함하도록 하는 것이었습니다. 이는 대립 분포에 대한 정보가 전혀 없는 상황에서는 어떤 `k`도 다른 `k`만큼이나 좋기 때문에, 그들의 총 개수를 최대화하는 것입니다.

이것의 결과로 그림 6.7에서 기각역은 분포의 두 꼬리(tails) 사이로 나뉩니다. 이는 우리가 불공정한 동전이 앞면이나 뒷면 어느 쪽으로든 편향될 수 있다고 예상하기 때문입니다. 만약 우리가 알고 있다면, 예를 들어 편향이 앞면 쪽일 것이라고 생각한다면 기각역을 적절한 쪽(예: 오른쪽 꼬리)에 모두 집중시킬 것입니다. 이러한 선택은 각각 _양측(two-sided)_ 및 _단측(one-sided)_ 검정이라고 불립니다. 보다 일반적으로, 대립 분포에 대한 가정이 있다면 이는 기각역 형태의 선택에 영향을 줄 수 있습니다.

## 6.4 오류의 유형

검정의 메커니즘을 설정했으므로, 우리가 얼마나 잘하고 있는지 평가할 수 있습니다. 표 6.1은 실제 상황(귀무 가설이 실제로 참인지 여부)과 데이터를 본 후 귀무 가설을 기각할지 여부에 대한 우리의 결정을 비교합니다.

검정 대 실제 | 귀무 가설이 참 | \\(...\\)이 거짓  
---|---|---  
**귀무 가설 기각** | 제1종 오류 (위양성) | 진양성  
**기각하지 않음** | 진음성 | 제2종 오류 (위음성)  
  
표 6.1: 통계적 검정에서의 오류 유형.

다른 유형의 오류를 증가시키는 대가로 두 가지 오류 유형 중 하나를 줄이는 것은 항상 가능합니다. 진짜 과제는 두 가지 사이에서 수용 가능한 상충 관계를 찾는 것입니다. 이것이 그림 6.2에 예시되어 있습니다. 우리는 임계값을 오른쪽으로 이동시켜 **위양성률(false positive rate, FPR)**을 항상 낮출 수 있습니다. 우리는 더 "보수적"이 될 수 있습니다. 하지만 이는 더 높은 **위음성률(false negative rate, FNR)**이라는 대가를 치러야 합니다. 유사하게, 임계값을 왼쪽으로 이동시켜 FNR을 낮출 수 있습니다. 하지만 이 역시 더 높은 FPR이라는 대가를 치러야 합니다. 용어에 대해 조금 설명하자면: FPR은 앞서 언급한 확률 \\(\alpha\\)와 같습니다. \\(1 - \alpha\\)는 검정의 **특이도(specificity)**라고도 불립니다. FNR은 때때로 \\(\beta\\)라고도 불리며, \\(1 - \beta\\)는 검정의 **검정력(power)**, **민감도(sensitivity)** 또는 **진양성률(true positive rate)**이라고 불립니다.

__

질문 6.8

6.3절의 끝에서 단측 및 양측 검정에 대해 배웠습니다. 왜 이러한 구분이 존재할까요? 왜 더 넓은 범위의 대립 가설에 민감한 양측 검정을 항상 사용하지 않을까요?

## 6.5 t-검정

많은 실험 측정값은 유기수(rational numbers)로 보고되며, 우리가 할 수 있는 가장 간단한 비교는 두 그룹 사이의 비교입니다. 예를 들어, 어떤 물질로 처리된 세포와 그렇지 않은 세포를 비교하는 것입니다. 이러한 상황을 위한 기본적인 검정이 \\(t\\)-검정입니다. 검정 통계량은 다음과 같이 정의됩니다.

\\[ t = c \; \frac{m_1-m_2}{s}, \tag{6.4}\\]

여기서 \\(m_1\\)과 \\(m_2\\)는 두 그룹 값들의 평균이고, \\(s\\)는 통합 표준 편차(pooled standard deviation)이며, \\(c\\)는 표본 크기, 즉 두 그룹의 관측치 수 \\(n_1\\)과 \\(n_2\\)에 의존하는 상수입니다. 공식으로는14,

14 모든 사람이 식 6.4는 기억하려고 노력해야 하지만, 많은 사람들은 필요할 때 식 6.5를 찾아보는 것으로 충분합니다.

\\[ \begin{align} m_g &= \frac{1}{n_g} \sum_{i=1}^{n_g} x_{g, i}
\quad\quad\quad g=1,2\\\ s^2 &= \frac{1}{n_1+n_2-2} \left( \sum_{i=1}^{n_1}
\left(x_{1,i} - m_1\right)^2 + \sum_{j=1}^{n_2} \left(x_{2,j} - m_2\right)^2
\right)\\\ c &= \sqrt{\frac{n_1n_2}{n_1+n_2}} \end{align} \tag{6.5}\\]

여기서 \\(x_{g, i}\\)는 \\(g\\)번째 그룹의 \\(i\\)번째 데이터 포인트입니다. R의 **datasets** 패키지에 있는 `PlantGrowth` 데이터를 사용하여 이를 시도해 봅시다.

    
    
    library("ggbeeswarm")
    data("PlantGrowth")
    ggplot(PlantGrowth, aes(y = weight, x = group, col = group)) +
      geom_beeswarm() + theme(legend.position = "none")
    tt = with(PlantGrowth, 
           t.test(weight[group =="ctrl"],
                  weight[group =="trt2"],
                  var.equal = TRUE))
    tt __
    
    
        Two Sample t-test
    
    data:  weight[group == "ctrl"] and weight[group == "trt2"]
    t = -2.134, df = 18, p-value = 0.04685
    alternative hypothesis: true difference in means is not equal to 0
    95 percent confidence interval:
     -0.980338117 -0.007661883
    sample estimates:
    mean of x mean of y 
        5.032     5.526 

[![](06-chap_files/figure-html/fig-testing-
plantgrowth-1.png)](06-chap_files/figure-html/fig-testing-plantgrowth-1.png
"그림 6.8: PlantGrowth 데이터.")

그림 6.8: `PlantGrowth` 데이터.

__

질문 6.9

`trt1`과의 비교에서는 무엇을 얻나요? `trt1` 대 `trt2`는요?

p-값을 계산하기 위해 `t.test` 함수는 \\(t\\)-통계량(식 6.4)에 대한 점근적 이론을 사용합니다. 이 이론은 두 그룹의 평균이 같다는 귀무 가설하에서 통계량이 알려진 수학적 분포인 자유도가 \\(n_1+n_2-2\\)인 \\(t\\)-분포를 따른다고 명시합니다. 이 이론은 추가적인 기술적 가정, 즉 데이터가 독립적이고 동일한 표준 편차를 가진 정규 분포에서 나온다는 가정을 사용합니다. 우리는 이러한 가정들에 대해 걱정할 수 있습니다. 분명히 이 가정들은 성립하지 않습니다: 무게는 항상 양수이지만, 정규 분포는 전체 실수 축에 걸쳐 있습니다. 문제는 이론적 가정으로부터의 이러한 이탈이 실제로 차이를 만드느냐 하는 것입니다. 우리는 이를 알아내기 위해 순열 검정(permutation test)을 사용할 수 있습니다(6.5.1절에서 순열 검정의 이면에 있는 아이디어를 좀 더 자세히 논의할 것입니다).

__

질문 6.10

위의 \\(t\\)-검정에 대해 동전 던지기의 그림 6.5 및 그림 6.6과 유사한 방식으로 이론적 및 시뮬레이션된 귀무 분포를 플롯해 보세요.

__

해결책

__

    
    
    plgr = dplyr::filter(PlantGrowth, group %in% c("ctrl", "trt2"))
    
    alpha  = 0.05
    xrange = 5 * c(-1, 1)
    deckel = function(x) ifelse(x < xrange[1], xrange[1], ifelse(x > xrange[2], xrange[2], x))
    
    sim_null = tibble(
      t = replicate(10000, t.test(weight ~ sample(group), var.equal = TRUE, data = plgr)$statistic)
    )
    sim_thresh = quantile(sim_null$t, c(alpha/2, 1-alpha/2))
    sim_null = mutate(sim_null, 
      t = deckel(t),        # 범위를 벗어난 데이터에 대한 경고 피하기
      reject = ifelse(t <= sim_thresh[1], "low", ifelse(t > sim_thresh[2], "high", "none"))
    ) 
    
    theo_thresh = qt(c(alpha/2, 1-alpha/2), df =  nrow(plgr) - 2)
    theo_null = tibble(
      t = seq(-5, 5, by = 0.05),
      density = dt (x = t, df = nrow(plgr)  - 2),
      reject = ifelse(t <= theo_thresh[1], "low", ifelse(t > theo_thresh[2], "high", "none"))
    )
    
    p1 = ggplot(sim_null, aes(x = t, col = reject, fill = reject)) +
           geom_bar(stat = "bin", breaks = seq(-5, 5, by = 0.2)) 
    p2 = ggplot(theo_null, aes(x = t, y = density, col = reject, fill = reject)) +
           geom_area() 
    
    for (p in list(p1, p2))
      print(p + 
            geom_vline(xintercept = tt$statistic, col = "#101010") +
            scale_colour_manual(values = c(low = "blue", high = "red", none = "darkgrey")) +
            scale_fill_manual(values = c(low = "blue", high = "red", none = "darkgrey")) + 
            xlim(xrange) + theme(legend.position = "none"))__

[![](06-chap_files/figure-html/fig-testing-tnull-1.png)](06-chap_files/figure-
html/fig-testing-tnull-1.png "Figure 6.9: ")

Figure 6.9

[![](06-chap_files/figure-html/fig-testing-tnull-2.png)](06-chap_files/figure-
html/fig-testing-tnull-2.png "Figure 6.10: ")

Figure 6.10

__

Question 6.11

Would the solution to the preceding question get simpler if we considered the
absolute value of \\(t\\) instead of \\(t\\) itself?

__

Solution

__

Yes, if we are not interested in the sign of the difference, we can directly
work on \\(\text{abs}(t)\\), and have only a single rejection region instead
of a lower and an upper one.

The \\(t\\)-test comes in multiple flavors, all of which can be chosen through
parameters of the `t.test` function. What we did above is called a two-sided
two-sample unpaired test with equal variance. _Two-sided_ refers to the fact
that we were open to reject the null hypothesis if the weight of the treated
plants was either larger or smaller than that of the untreated ones.

_Two-sample_ 15 indicates that we compared the means of two groups to each
other; another option is to compare the mean of one group against a given,
fixed number.

15 It can be confusing that the term _sample_ has a different meaning in
statistics than in biology. In biology, a sample is a single specimen on which
an assay is performed; in statistics, it is a set of measurements, e.g., the
\\(n_1\\)-tuple \\(\left(x_{1,1},...,x_{1,n_1}\right)\\) in Equation 6.5,
which can comprise several biological samples. In contexts where this double
meaning might create confusion, we refer to the data from a single biological
sample as an _observation_.

_Unpaired_ means that there was no direct 1:1 mapping between the measurements
in the two groups. If, on the other hand, the data had been measured on the
same plants before and after treatment, then a paired test would be more
appropriate, as it looks at the change of weight within each plant, rather
than their absolute weights.

_Equal variance_ refers to the way the statistic Equation 6.4 is calculated.
That expression is most appropriate if the variances within each group are
about the same. If they are very different, an alternative form (Welch’s
\\(t\\)-test) and associated asymptotic theory exist.

**The independence assumption**. Now let’s try something peculiar: duplicate
the data.

    
    
    with(rbind(PlantGrowth, PlantGrowth),
           t.test(weight[group == "ctrl"],
                  weight[group == "trt2"],
                  var.equal = TRUE))__
    
    
        Two Sample t-test
    
    data:  weight[group == "ctrl"] and weight[group == "trt2"]
    t = -3.1007, df = 38, p-value = 0.003629
    alternative hypothesis: true difference in means is not equal to 0
    95 percent confidence interval:
     -0.8165284 -0.1714716
    sample estimates:
    mean of x mean of y 
        5.032     5.526 

Note how the estimates of the group means (and thus, of the difference) are
unchanged, but the p-value is now much smaller! We can conclude two things
from this:

  * The power of the \\(t\\)-test depends on the sample size. Even if the underlying biological differences are the same, a dataset with more observations tends to give more significant results16.

  * The assumption of independence between the measurements is really important. Blatant duplication of the same data is an extreme form of dependence, but to some extent the same thing happens if you mix up different levels of replication. For instance, suppose you had data from 8 plants, but measured the same thing twice on each plant (technical replicates), then pretending that these are now 16 independent measurements is wrong.

16 You can also see this from the way the numbers \\(n_1\\) and \\(n_2\\)
appear in Equation 6.5.

### 6.5.1 Permutation tests

What happened above when we contrasted the outcome of the parametric
\\(t\\)-test with that of the permutation test applied to the
\\(t\\)-statistic? It’s important to realize that these are two different
tests, and the similarity of their outcomes is desirable, but coincidental. In
모수적 검정의 경우, \\(t\\)-통계량의 귀무 분포는 데이터의 가정된 귀무 분포(단위 공분산을 가진 \\((n_1+n_2)\\)차원 공간 \\(\mathbb{R}^{n_1+n_2}\\)에서의 다변량 정규 분포)로부터 도출되며 연속적입니다: 즉, \\(t\\)-분포입니다. 이와 대조적으로, 우리 검정 통계량의 순열 분포는 단일 데이터 인스턴스(\\(n_1+n_2\\)개의 관측치)로부터 관측치 레이블의 \\((n_1+n_2)!\\)개 순열17의 유한 집합으로부터 얻어지므로 이산적입니다. 여기서 우리가 가정하는 전부는 귀무 가설하에서 변수 \\(X_{1,1},...,X_{1,n_1},X_{2,1},...,X_{2,n_2}\\)가 교환 가능하다(exchangeable)는 것입니다. 논리적으로 이 가정은 모수적 검정의 가정에 의해 함축되지만, 더 약한 가정입니다. 순열 검정은 \\(t\\)-통계량을 사용하지만, \\(t\\)-분포(또는 정규 분포)는 사용하지 않습니다. 두 검정이 매우 유사한 결과를 주었다는 사실은 중심 극한 정리(Central Limit Theorem)의 결과입니다.

17 계산 시간을 절약하고 싶은 경우에는 무작위 하위 집합을 사용합니다.

## 6.6 P-값 해킹(P-value hacking)

동전 던지기 예제로 돌아가 봅시다. 우리는 동전이 공정하지 않다는 것을 "알고" 있었음에도 불구하고(6.2절에서 `probHead`를 0.6으로 선택했으므로), 5% 수준에서 귀무 가설(동전이 공정하다는 가설)을 기각하지 않았습니다. 이제 우리가 서로 다른 검정 통계량들을 살펴보기 시작한다고 가정해 봅시다. 아마도 3번 이상 연속으로 앞면이 나온 횟수라든지, 처음 50번의 던지기에서 앞면의 횟수 등등 말이죠. 그러다 보면 어느 시점에는 단지 우연히라도 작은 p-값이 나오는 검정을 발견하게 될 것입니다(결국 귀무 가설—공정한 동전—하에서 p-값이 0.05보다 작을 확률은 20분의 1입니다). 우리는 방금 **p-값 해킹(p-value hacking)**18이라 불리는 일을 저지른 것입니다 ([Head et al. 2015](16-chap.html#ref-Head:PLoSBiol:2015:pvaluehacking)). 무엇이 문제인지 아시겠지요: 우리 주장을 증명하려는 열의에 차서 데이터가 우리가 원하는 대로 해줄 때까지 데이터를 고문한 것입니다. 이와 관련된 전술로는 **가설 전환(hypothesis switching)** 또는 **HARKing**(결과가 알려진 후에 가설을 세우는 것)이 있습니다: 데이터 세트가 있고, 아마도 그것을 모으기 위해 많은 시간과 돈을 투자했으므로 결과가 필요합니다. 우리는 수많은 다양한 귀무 가설과 검정 통계량을 생각해 내고, 이를 테스트하고, 무언가 보고할 만한 것이 나올 때까지 반복합니다.

18 <http://fivethirtyeight.com/features/science-isnt-broken>

이러한 전술들은 6.3절에서 설명한 가설 검정의 규칙을 위반하는 것입니다. 거기서는 가설과 검정 방법을 먼저 선택하고 그 다음에 데이터를 수집하는 순차적인 절차를 제시했습니다. 그러나 [2장](02-chap.html)에서 보았듯이, 실제로는 그러한 전술이 유혹적일 수 있습니다. 생물학적 데이터의 경우 데이터를 "정규화"하고, 변환하고, 배치 효과(batch effects)를 보정하고, 이상치를 제거하는 등 너무나 많은 다양한 선택지가 존재합니다. 주제는 복잡하고 정답이 정해져 있지 않습니다. Wasserstein과 Lazar ([2016](16-chap.html#ref-Wasserstein2016:ASA))는 과학계에서 p-값이 어떻게 사용되는지에 대한 문제점들과 몇 가지 오해들에 대해 읽기 쉬운 짧은 요약을 제공했습니다. 그들은 또한 p-값이 어떻게 유익하게 사용될 수 있는지도 강조했습니다. 핵심 메시지는 다음과 같습니다: 여러분의 데이터, 어떤 분석을 시도했는지, 그리고 어떻게 수행했는지에 대해 완전히 투명하게 공개하십시오. 분석 코드를 제공하십시오. 그러한 맥락 정보가 있어야만 p-값은 유용할 수 있습니다.

**착각을 피하십시오**. 우리의 통계적 검정은 결코 귀무 가설이 참임을 증명하려는 시도가 아니라는 점을 명심하십시오 - 우리는 단순히 그것이 거짓이라는 증거가 있는지 없는지를 말하는 것뿐입니다. 만약 높은 p-값이 귀무 가설이 참이라는 것을 _나타내는_ 것이라면, 우리는 완전히 미친 귀무 가설을 세우고, 전혀 무관한 실험을 하고, 결론을 내릴 수 없는 소량의 데이터를 수집하여, 0과 1 사이의 랜덤한 숫자인 (따라서 우리의 임계값 \\(\alpha\\)보다 클 확률이 높은) p-값을 찾음으로써 우리의 가설을 증명해 버릴 수 있을 것입니다!

## 6.7 다중 검정(Multiple testing)

__

질문 6.12

[xkcd 만화 882](http://xkcd.com/882)를 찾아보세요. 왜 신문은 다른 색상들에 대한 결과는 보도하지 않았을까요?

만화에서 묘사된 곤경은 생물학의 고처리량 데이터에서도 발생합니다. 그것도 아주 강력하게 말이죠! 여러분은 단지 20가지 색상의 젤리빈뿐만 아니라, 예를 들어 두 조건 사이의 차등 발현을 위해 테스트된 20,000개의 유전자나, DNA 돌연변이가 일어났을지도 모르는 게놈 상의 60억 개의 위치를 다루게 될 것입니다. 그렇다면 우리는 이를 어떻게 처리해야 할까요? 통계적 검정 결과와 실제 상황을 연관시킨 표(표 6.1)를 다시 살펴봅시다. 이번에는 모든 것을 많은 가설의 관점에서 구성해 보겠습니다.

검정 대 실제 | 귀무 가설이 참 | \\(...\\)이 거짓 | 합계  
---|---|---|---  
**기각됨** | \\(V\\) | \\(S\\) | \\(R\\)  
**기각되지 않음** | \\(U\\) | \\(T\\) | \\(m-R\\)  
**합계** | \\(m_0\\) | \\(m-m_0\\) | \\(m\\)  
  
표 6.2: 다중 검정에서의 오류 유형. 문자는 각 유형의 오류가 발생한 횟수를 나타냅니다.

  * \\(m\\): 전체 검정(및 귀무 가설)의 수

  * \\(m_0\\): 참인 귀무 가설의 수

  * \\(m-m_0\\): 거짓인 귀무 가설의 수

  * \\(V\\): 위양성(false positives)의 수 (제1종 오류의 척도)

  * \\(T\\): 위음성(false negatives)의 수 (제2종 오류의 척도)

  * \\(S\\), \\(U\\): 진양성 및 진음성의 수

  * \\(R\\): 기각 횟수

이 장의 나머지 부분에서 우리는 제1종 및 제2종 오류를 관리하는 다양한 방법들을 살펴봅니다.

## 6.8 가족오류율(Family wise error rate)

**가족오류율(family wise error rate, FWER)**은 \\(V>0\\)일 확률, 즉 하나 이상의 위양성 오류를 저지를 확률입니다. 우리는 이를 위양성 오류를 전혀 저지르지 않을 확률의 여사건으로 계산할 수 있습니다19.

19 독립을 가정함.

\\[ \begin{align} P(V>0) &= 1 - P(\text{$m_0$개의 귀무 가설 중 어느 것도 기각되지 않음})
\\\ &= 1 - (1 - \alpha)^{m_0} \to 1 \quad\text{as } m_0\to\infty. \end{align}
\tag{6.6}\\]

어떤 고정된 \\(\alpha\\)에 대해, 이 확률은 \\(m_0\\)가 \\(1/\alpha\\)의 정도가 되자마자 무시할 수 없을 정도로 커지며, \\(m_0\\)가 커짐에 따라 1을 향해 갑니다. 이러한 관계는 방대한 잠재적 일치 데이터베이스를 검색하는 DNA 매칭과 같은 실험에서 심각한 결과를 초래할 수 있습니다. 예를 들어, 두 사람의 DNA 프로필이 무작위 오차에 의해 일치할 확률이 100만 분의 1이고, 여러분의 DNA를 80만 개의 프로필이 담긴 데이터베이스와 대조한다면, 데이터베이스 내에서 (즉, 여러분이 그 안에 없더라도) 무작위로 일치할 확률은 다음과 같습니다:

    
    
    1 - (1 - 1/1e6)^8e5 __
    
    
    [1] 0.5506712

상당히 높습니다. 그리고 데이터베이스에 몇 백만 개의 프로필이 더 포함된다면, 잘못된 일치는 사실상 피할 수 없습니다.

__

질문 6.13

\\(m_0\\)가 클 때 식 6.6의 확률이 실제로 1에 매우 가까워진다는 것을 증명해 보세요.

### 6.8.1 본페로니 방법(Bonferroni method)

FWER을 제어하고 싶다면 가설별 \\(\alpha\\)를 어떻게 선택해야 할까요? 위의 계산들은 \\(\alpha\\)와 \\(m_0\\)의 곱이 합리적인 어림값이 될 수 있음을 시사합니다. 대개 우리는 \\(m_0\\)를 모르지만, \\(m_0 \le m\\)이므로 \\(m_0\\)의 상한선인 \\(m\\)은 알고 있습니다. 본페로니 방법은 간단히 말해, 우리가 \\(\alpha_{\text{FWER}}\\) 수준에서 FWER 제어를 원한다면 가설별 임계값을 \\(\alpha = \alpha_{\text{FWER}}/m\\)으로 선택해야 한다는 것입니다. 예제를 통해 이를 확인해 봅시다.

    
    
    m = 10000
    ggplot(tibble(
      alpha = seq(0, 7e-6, length.out = 100),
      p     = 1 - (1 - alpha)^m),
      aes(x = alpha, y = p)) +  geom_line() +
      xlab(expression(alpha)) +
      ylab("Prob( no false rejection )") +
      geom_hline(yintercept = 0.05, col = "red")__

[![](06-chap_files/figure-html/fig-testing-
bonferroni-1.png)](06-chap_files/figure-html/fig-testing-bonferroni-1.png
"그림 6.11: 본페로니 방법. 플롯은 m=10000에 대해 \\alpha의 함수로서 식 6.6의 그래프를 보여줍니다.")

그림 6.11: 본페로니 방법. 플롯은 \\(m=10000\\)에 대해 \\(\alpha\\)의 함수로서 식 6.6의 그래프를 보여줍니다.

그림 6.11에서 검은색 선은 (0.05 값에 해당하는) 빨간색 선과 \\(\alpha=5.13\times 10^{-6}\\)에서 교차하는데, 이는 본페로니 방법에 의해 함축된 \\(0.05/m\\) 값보다 아주 약간 큽니다.

__

질문 6.14

왜 두 값이 정확히 같지 않을까요?

하지만 이 방법의 잠재적인 단점은 \\(m_0\\)가 크면 기각 임계값이 매우 작아진다는 것입니다. 이는 무언가를 감지할 기회를 가지려면 개별 검정의 검정력이 매우 높아야 함을 의미합니다. 종종 FWER 제어는 너무 엄격하여, 데이터를 생성하고 모으는 데 들인 시간과 비용을 비효율적으로 사용하게 만들 수 있습니다. 이제 우리는 제1종 오류를 제어하는 더 미묘한 방법들이 있다는 것을 보게 될 것입니다.

## 6.9 허위 발견율(False discovery rate)

데이터를 살펴봅시다. 합성 글루코코르티코이드인 덱사메타손(dexamethasone)을 처리하거나 처리하지 않은 4개의 1차 인간 기도 평활근 세포주의 유전자 발현 측정값(유전자 수준 카운트)이 포함된 RNA-Seq 데이터 세트 `airway`를 불러옵니다. 우리는 [8장](08-chap.html)에서 더 자세히 다룰 **[DESeq2](https://bioconductor.org/packages/DESeq2/)** 방법을 사용할 것입니다. 지금은 이 방법이 각 유전자에 대해 차등 발현 검정을 수행한다고만 말해두면 충분합니다. 개념적으로 검정되는 귀무 가설은 \\(t\\)-검정의 그것과 유사하지만, 카운트 데이터를 다루기 때문에 세부 사항은 약간 더 복잡합니다.

    
    
    library("DESeq2")
    library("airway")
    data("airway")
    aw   = DESeqDataSet(se = airway, design = ~ cell + dex)
    aw   = DESeq(aw)
    awde = as.data.frame(results(aw)) |> dplyr::filter(!is.na(pvalue))__

__

태스크

`awde`의 내용을 살펴보세요.

__

태스크

(선택 사항) 위의 코드 청크가 무엇을 하는지에 대한 더 많은 정보를 얻으려면 **[DESeq2](https://bioconductor.org/packages/DESeq2/)** 비네트 및/또는 [8장](08-chap.html)을 참고하십시오.

### 6.9.1 p-값 히스토그램

**p-값 히스토그램**은 다중 검정을 포함하는 모든 분석에서 중요한 무결성 검사(sanity check)입니다. 이는 두 가지 성분으로 구성된 혼합물입니다:

**null:** 귀무 가설이 참인 검정에서 얻은 p-값들.

**alt:** 귀무 가설이 거짓인 검정에서 얻은 p-값들. 이 두 성분의 상대적 크기는 참인 귀무 가설과 참인 대립 가설의 비율(즉, \\(m_0\\)와 \\(m\\))에 달려 있으며, 종종 히스토그램에서 시각적으로 추정할 수 있습니다. 분석의 통계적 검정력이 높다면 두 번째 성분("alt")은 대부분 작은 p-값들로 구성되며, 즉 히스토그램에서 0 근처의 정점으로 나타납니다. 일부 대립 가설에 대해 검정력이 높지 않다면 이 정점이 오른쪽으로 뻗어 나가는, 즉 "어깨(shoulder)" 모양을 가질 것으로 예상합니다. "null" 성분의 경우 (연속형 데이터와 검정 통계량에 대한 p-값의 정의에 따라) \\([0,1]\\)에서의 균등 분포를 예상합니다. airway 데이터에 대한 p-값 히스토그램을 그려봅시다.

    
    
    ggplot(awde, aes(x = pvalue)) +
      geom_histogram(binwidth = 0.025, boundary = 0)__

[![](06-chap_files/figure-html/fig-testing-
awpvhist-1.png)](06-chap_files/figure-html/fig-testing-awpvhist-1.png
"그림 6.12: airway 데이터에 대한 p-값 히스토그램.")

그림 6.12: `airway` 데이터에 대한 p-값 히스토그램.

그림 6.12에서 우리는 예상된 혼합물을 봅니다. 또한 null 성분이 정확히 평평(균등)하지 않음을 볼 수 있는데, 이는 데이터가 카운트(counts)이기 때문입니다. 카운트가 높을 때는 준연속(quasi-continuous)으로 보이지만, 카운트가 낮은 검정의 경우 데이터의 이산성(discreteness)과 그 결과로 나타나는 p-값이 히스토그램 오른쪽의 뾰족한 부분(spikes)으로 나타납니다.

이제 우리가 p-값이 \\(\alpha\\)보다 작은 모든 검정을 기각한다고 가정해 봅시다. 우리는 다음 코드로 생성된 그림 6.13과 같은 플롯을 통해 허위 발견 비율(false discovery proportion)의 추정치를 시각적으로 결정할 수 있습니다.

    
    
    alpha = binw = 0.025
    pi0 = 2 * mean(awde$pvalue > 0.5)
    ggplot(awde,
      aes(x = pvalue)) + geom_histogram(binwidth = binw, boundary = 0) +
      geom_hline(yintercept = pi0 * binw * nrow(awde), col = "blue") +
      geom_vline(xintercept = alpha, col = "red")__

[![](06-chap_files/figure-html/fig-testing-
awpvvisfdr-1.png)](06-chap_files/figure-html/fig-testing-awpvvisfdr-1.png
"그림 6.13: p-값 히스토그램을 통한 FDR의 시각적 추정.")

그림 6.13: p-값 히스토그램을 통한 FDR의 시각적 추정.

우리는 첫 번째 빈 \\([0, \alpha]\\)에 4772개의 p-값이 있음을 알 수 있는데, 이 중 약 945개는 null일 것으로 예상됩니다(파란색 선으로 표시됨). 따라서 우리는 잘못된 기각의 비율을 다음과 같이 추정할 수 있습니다.

    
    
    pi0 * alpha / mean(awde$pvalue <= alpha)__
    
    
    [1] 0.1980092

**허위 발견율(False discovery rate, FDR)**은 다음과 같이 정의됩니다.

\\[ \text{FDR} = \text{E}\\!\left [\frac{V}{\max(R, 1)}\right ], \tag{6.7}\\]

여기서 \\(R\\)과 \\(V\\)는 표 6.2에서와 같습니다. 분모의 식은 \\(R=0\\)인 경우에도 FDR이 잘 정의되도록 보장합니다(그 경우 함축적으로 \\(V=0\\)이 됨). 모든 귀무 가설이 참인 경우, 즉 \\(V=R\\)인 경우 FDR은 FWER과 동일해진다는 점에 유의하세요. \\(\text{E[ ]}\\)는 **기대값(expected value)**을 의미합니다. 즉, FDR은 수치가 아니라...
associated with a specific outcome of \\(V\\) and \\(R\\) for one particular
experiment. Rather, given our choice of tests and associated rejection rules
for them, it is the average20 proportion of type I errors out of the
rejections made, where the average is taken (at least conceptually) over many
replicate instances of the experiment.

20 Since the FDR is an expectation value, it does not provide worst case
control: in any single experiment, the so-called false discovery proportion
(FDP), that is the realized value \\(v/r\\) (without the \\(\text{E[ ]}\\)),
could be much higher or lower.

### 6.9.2 The Benjamini-Hochberg algorithm for controlling the FDR

There is a more elegant alternative to the “visual FDR” method of the last
section. The procedure, introduced by Benjamini and Hochberg
([1995](16-chap.html#ref-BH:1995)) has these steps:

  * First, order the p-values in increasing order, \\(p_{(1)} ... p_{(m)}\\)

  * Then for some choice of \\(\varphi\\) (our target FDR), find the largest value of \\(k\\) that satisfies: \\(p_{(k)} \leq \varphi \, k / m\\)

  * Finally reject the hypotheses \\(1, ..., k\\)

We can see how this procedure works when applied to our RNA-Seq p-values
through a simple graphical illustration:

    
    
    phi  = 0.10
    awde = mutate(awde, rank = rank(pvalue))
    m    = nrow(awde)
    
    ggplot(dplyr::filter(awde, rank <= 7000), aes(x = rank, y = pvalue)) +
      geom_line() + geom_abline(slope = phi / m, col = "red")__

[![](06-chap_files/figure-html/fig-testing-BH-1.png)](06-chap_files/figure-
html/fig-testing-BH-1.png "Figure 6.14: Visualization of the Benjamini-
Hochberg procedure. Shown is a zoom-in to the 7000 lowest p-values.")

Figure 6.14: Visualization of the Benjamini-Hochberg procedure. Shown is a
zoom-in to the 7000 lowest p-values.

The method finds the rightmost point where the black (our p-values) and red
lines (slope \\(\varphi / m\\)) intersect. Then it rejects all tests to the
left.

    
    
    kmax = with(arrange(awde, rank),
             last(which(pvalue <= phi * rank / m)))
    kmax __
    
    
    [1] 4099

__

Question 6.15

Compare the value of `kmax` with the number of 4772 from above (Figure 6.13).
Why are they different?

__

Question 6.16

Look at the code associated with the option `method="BH"` of the `p.adjust`
function that comes with R. How does it compare to what we did above?

__

Question 6.17

**Schweder and Spj øtvoll plot**: check out Figures 1–3 in Schweder and
Spjøtvoll ([1982](16-chap.html#ref-SchwederSpjotvoll1982)). Make a similar
plot for the data in `awde`. How does it relate to Figures 6.14 and 6.13?

__

Solution

__

Thirteen years before Benjamini and Hochberg ([1995](16-chap.html#ref-
BH:1995)), Schweder and Spjøtvoll ([1982](16-chap.html#ref-
SchwederSpjotvoll1982)) suggested a diagnostic plot of the observed
\\(p\\)-values that permits estimation of the fraction of true null
hypotheses. For a series of hypothesis tests \\(H_1, ..., H_m\\) with
\\(p\\)-values \\(p_i\\), they suggested plotting

\\[ \left( 1-p_i, N(p_i) \right) \mbox{ for } i \in 1, ..., m, \tag{6.8}\\]

where \\(N(p)\\) is the number of \\(p\\)-values greater than \\(p\\). An
application of this diagnostic plot to `awde$pvalue` is shown in Figure 6.15.
When all null hypotheses are true, each of the \\(p\\)-values is uniformly
distributed in \\([0,1]\\), Consequently, the empirical cumulative
distribution of the sample \\((p_1, ..., p_m)\\) is expected to be close to
the line \\(F(t)=t\\). By symmetry, the same applies to \\((1 - p_1, ..., 1 -
p_m)\\). When (without loss of generality) the first \\(m_0\\) null hypotheses
are true and the other \\(m-m_0\\) are false, the empirical cumulative
distribution of \\((1-p_1, ..., 1-p_{m_0})\\) is again expected to be close to
the line \\(F_0(t)=t\\). The empirical cumulative distribution of
\\((1-p_{m_0+1}, ..., 1-p_{m})\\), on the other hand, is expected to be close
to a function \\(F_1(t)\\) which stays below \\(F_0\\) but shows a steep
increase towards 1 as \\(t\\) approaches \\(1\\). In practice, we do not know
which of the null hypotheses are true, so we only observe a mixture whose
empirical cumulative distribution is expected to be close to

\\[ F(t) = \frac{m_0}{m} F_0(t) + \frac{m-m_0}{m} F_1(t). \tag{6.9}\\]

Such a situation is shown in Figure 6.15. If \\(F_1(t)/F_0(t)\\) is small for
small \\(t\\) (i.e., the tests have reasonable power), then the mixture
fraction \\(\frac{m_0}{m}\\) can be estimated by fitting a line to the left-
hand portion of the plot, and then noting its height on the right. Such a fit
is shown by the red line. Here, we focus on those tests for which the count
data are not all very small numbers (`baseMean>=1`), since for these the
p-value null distribution is sufficiently close to uniform (i.e., does not
위의 genes 들에 대해서만 위와 같은 현상이 발생함)을 보여주기 위해 baseMean >= 1인 유전자들만 필터링했습니다. 여러분은 모든 유전자에 대해 동일한 플롯을 만들어 볼 수도 있습니다.

    
    
    awdef = awde |>
      dplyr::filter(baseMean >=1) |> 
      arrange(pvalue) |>
      mutate(oneminusp = 1 - pvalue,
             N = n() - row_number())
    jj = round(nrow(awdef) * c(1, 0.5))
    slope = with(awdef, diff(N[jj]) / diff(oneminusp[jj]))
    ggplot(awdef) +
      geom_point(aes(x = oneminusp, y = N), size = 0.15) + 
      xlab(expression(1-p[i])) +
      ylab(expression(N(p[i]))) +
      geom_abline(intercept = 0, slope = slope, col = "red3") +
      geom_hline(yintercept = slope, linetype = "dotted") +
      geom_vline(xintercept = 1, linetype = "dotted") +
      geom_text(x = 0, y = slope, label = paste(round(slope)), 
                hjust = -0.1, vjust = -0.25) __

[![](06-chap_files/figure-html/fig-testing-
SchwederSpjotvoll-1.png)](06-chap_files/figure-html/fig-testing-
SchwederSpjotvoll-1.png "그림 6.15: 질문 6.17의 답변에서 설명된 Schweder와 Spjotvoll 플롯.")

그림 6.15: Schweder와 Spjotvoll 플롯.

`awdef`에는 22,853개의 행이 있으며, 따라서 이 단순한 추정치에 따르면 22853-17302=5551개의 대립 가설이 존재합니다.

## 6.10 국소 FDR(Local FDR)

[![](imgs/xkcd1132.png)](imgs/xkcd1132.png "그림 6.16: http://xkcd.com/1132 – 빈도론자는 현재 가용한 데이터만 가질 수 있는 반면, 베이지안은 세계에 대한 이해나 이전 경험을 활용할 수 있습니다. 베이지안으로서 그녀는 우리 태양의 질량이 노바(nova)가 되기에는 너무 작다는 물리학 지식을 충분히 알고 있을 것입니다. 설령 물리학을 모르더라도, 그녀는 경험적 베이지안(empirical Bayesian)이 되어 태양이 폭발하지 않았던 수많은 이전 날들로부터 사전 확률을 가져올 수 있습니다.")

그림 6.16: <http://xkcd.com/1132> – 빈도론자는 현재 가용한 데이터만 가질 수 있는 반면, 베이지안은 세계에 대한 이해나 이전 경험을 활용할 수 있습니다. 베이지안으로서 그녀는 우리 태양의 질량이 노바(nova)가 되기에는 너무 작다는 물리학 지식을 충분히 알고 있을 것입니다. 설령 물리학을 모르더라도, 그녀는 **경험적 베이지안(empirical Bayesian)**이 되어 태양이 폭발하지 않았던 수많은 이전 날들로부터 사전 확률을 가져올 수 있습니다.

이 장의 첫머리에 있는 xkcd 만화는 다중 검정 문제를 오차를 축적하는 방식이라는 다소 불길한 해석으로 끝을 맺었지만, 그림 6.16은 다중 검정의 기회를 강조합니다: 우리가 많은 검정을 수행할 때, 우리는 다중성을 사용하여 단일 검정으로 가능한 것 이상의 이해를 높일 수 있습니다.

[![](06-chap_files/figure-html/fig-testing-lfdr-1.png)](06-chap_files/figure-
html/fig-testing-lfdr-1.png "그림 6.17: 국소 허위 발견율과 f_{alt}(p)의 일부 선택 및 \pi_0=0.6을 사용한 두 그룹 모델; 밀도(상단) 및 분포 함수(하단).")

그림 6.17: 국소 허위 발견율과 두 그룹 모델. \\(f_{\text{alt}}(p)\\)의 일부 선택 및 \\(\pi_0=0.6\\)을 사용함; 밀도(상단) 및 분포 함수(하단).

그림 6.13의 히트맵으로 돌아가 봅시다. 개념적으로 우리는 이를 이른바 두 그룹 모델(two-groups model, [Efron 2010](16-chap.html#ref-Efron2010))의 관점에서 생각할 수 있습니다:

\\[ f(p)= \pi_0 + (1-\pi_0) f_{\text{alt}}(p), \tag{6.10}\\]

여기서 \\(f(p)\\)는 분포의 밀도(데이터가 무한하고 빈이 무한히 작을 때 히스토그램의 모습)이고, \\(\pi_0\\)는 균등 성분의 크기를 나타내는 0과 1 사이의 숫자이며, \\(f_{\text{alt}}\\)는 대립 성분입니다. 이는 우리가 이미 [4장](04-chap.html)에서 보았던 혼합 모델입니다. 혼합 밀도와 주변 밀도 \\(f(p)\\)는 그림 6.17의 상단 패널에 시각화되어 있습니다: 파란색 영역들은 함께 \\(f_{\text{alt}}(p)\\)의 그래프에 해당하고, 회색 영역들은 \\(f_{\text{null}}(p) = \pi_0\\)에 해당합니다. 이제 특정 컷오프 \\(p\\)(예를 들어 그림 6.17에서처럼 \\(p=0.1\\))를 고려한다면, 이 컷오프에서 기각하는 가설이 위양성일 확률을 다음과 같이 계산할 수 있습니다. 우리는 컷오프에서의 \\(f\\) 값(빨간색 선)을 귀무 가설의 기여분(연한 빨간색, \\(\pi_0\\))과 대립 가설의 기여분(더 짙은 빨간색, \\((1-\pi_0) f_{\text{alt}}(p)\\))으로 분해합니다. 그러면 **국소 허위 발견율(local false discovery rate)**은 다음과 같습니다.

\\[ \text{fdr}(p) = \frac{\pi_0}{f(p)}. \tag{6.11}\\]

정의에 따라 이 수치는 0과 1 사이입니다. 그림 6.17에서 \\(\text{fdr}\\)이 \\(p\\)의 단조 증가 함수라는 점에 주목하세요. 이는 fdr이 가장 작은 \\(p\\)에 대해 가장 낮아야 하고, 그 다음 점차 커져서 가장 오른쪽 끝에서 1에 도달해야 한다는 우리의 직관과 일치합니다. 우리는 빨간색 선뿐만 아니라 곡선 아래의 면적에 대해서도 유사한 분해를 할 수 있습니다. 이는 다음과 같습니다.

\\[ F(p) = \int_0^p f(t)\,dt, \tag{6.12}\\]

그리고 전체 면적 \\(F(p)\\)에 대한 짙은 회색 영역(\\(\pi_0\\)에 \\(p\\)를 곱한 값)의 비율은 **꼬리 영역 허위 발견율(tail area false discovery rate)**(Fdr21)입니다.

21 관습적으로 소문자 약어 fdr은 국소(local)를, 대문자 약어 Fdr은 식 6.10의 두 그룹 모델 문맥에서의 꼬리 영역 허위 발견율을 위해 사용합니다. 약어 FDR은 원래의 정의인 식 6.7을 위해 사용되는데, 이는 좀 더 일반적입니다. 즉, 식 6.10의 모델링 가정에 의존하지 않습니다.

\\[ \text{Fdr}(p) = \frac{\pi_0\,p}{F(p)}. \tag{6.13}\\]

우리는 그림 6.21의 진단을 위해 \\(F\\)의 데이터 버전을 사용할 것입니다.

**[qvalue](https://bioconductor.org/packages/qvalue/)**와 **[fdrtool](https://cran.r-project.org/web/packages/fdrtool/)** 패키지는 이러한 모델을 데이터에 적합시키는 기능을 제공합니다.

    
    
    library("fdrtool")
    ft = fdrtool(awde$pvalue, statistic = "pvalue")__

**[fdrtool](https://cran.r-project.org/web/packages/fdrtool/)**에서는 위에서 우리가 \\(\pi_0\\)라고 불렀던 것을 `eta0`라고 부릅니다:

    
    
    ft$param[,"eta0"]__
    
    
         eta0 
    0.8822922 

__

질문 6.18

위의 `fdrtool` 호출로 생성된 플롯들은 무엇을 보여주나요?

__

태스크

리스트 `ft`의 다른 요소들을 탐색해 보세요.

__

질문 6.19

경험적 베이즈(empirical Bayes) 방법에서 "경험적"은 무엇을 의미하나요?

### 6.10.1 국소 대 전체

FDR(또는 Fdr)은 집합의 속성입니다. 이는 다중 검정 분석 과정에서 이루어진 기각 전체의 집합에 적용되는 단일 숫자입니다. 대조적으로 fdr은 국소적인 속성입니다. 이는 개별 가설에 적용됩니다. fdr이 밀도 플롯의 \(x\)축을 따른 각 지점에 대해 계산되었던 반면, Fdr은 빨간색 선의 왼쪽 면적들에 의존했던 그림 6.17을 상기해 보십시오.

__

질문 6.20

경제학에서의 _총비용(total cost)_과 _한계비용(marginal cost)_ 개념을 확인해 보세요. Fdr 및 fdr과의 유사성을 찾을 수 있나요?

__

해결책

__

\\(m\\)개의 제품 세트를 생산하는 생산 공정에서 총비용은 관련된 모든 비용의 합입니다. 제품의 평균 비용은 총비용을 \\(m\\)으로 나눈 가상의 수치입니다. 한계비용은 제품 하나를 추가로 만드는 데 드는 비용이며, 종종 평균 비용과는 매우 다릅니다. 예를 들어, 피아노로 베토벤 소나타 한 곡을 연주하는 법을 배우는 데는 초보자에게 상당한 시간이 걸릴 수 있지만, 그것을 한 번 더 연주하는 데는 비교적 적은 추가 노력이 필요합니다: 즉, 한계비용이 고정비용(따라서 총비용)보다 훨씬 적습니다. 한계비용이 평균 비용보다 높은 경우의 예로는 달리기가 있습니다: 운동화를 신고 나가서 10km를 달리는 것은 대부분의 사람들에게 꽤 견딜 만한(아마도 즐거운) 일이겠지만, 추가로 10km를 더 달릴 때마다 불균형적으로 큰 불쾌감이 더해질 수 있습니다.

### 6.10.2 용어

역사적으로 _다중 검정 보정(multiple testing correction)_과 _조정된 p-값(adjusted p-value)_이라는 용어가 프로세스와 출력물에 사용되어 왔습니다. 허위 발견율의 문맥에서 이러한 용어들은 도움이 되지 않을 뿐만 아니라 혼란을 줄 수 있습니다. 우리는 이 용어들의 사용을 피할 것을 권장합니다. 이 용어들은 우리가 p-값 세트 \\((p_1, ..., p_m)\\)로 시작하여 어떤 전형적인 절차를 적용하고, "보정된" 또는 "조정된" p-값 세트 \\((p_1^{\text{adj}}, ..., p_m^{\text{adj}})\\)를 얻는다는 것을 암시합니다. 그러나 벤자미니-호크버그 방법의 결과물은 p-값이 아니며, FDR, Fdr, fdr 역시 p-값이 아닙니다. FDR과 Fdr은 집합의 속성임을 기억하십시오. 이를 개별 검정과 연관 짓는 것은 평균 비용과 한계 비용을 혼동하는 것만큼이나 말이 되지 않습니다. Fdr과 fdr 역시 상당한 양의 모델링 가정에 의존합니다. 다음 섹션에서 여러분은 벤자미니-호크버그 방법이 유일한 방법이 아니라는 것과, 다중 검정 절차에 입력되는 가설 및 p-값 세트와 그 출력물 사이의 추정되는 직접적인 대응 관계를 더욱 멀어지게 만드는 중요하고 유용한 확장들이 있다는 것을 보게 될 것입니다.

## 6.11 독립 가설 가중치 부여(Independent hypothesis weighting)

지금까지 살펴본 벤자미니-호크버그 방법과 두 그룹 모델은 가설의 _교환 가능성(exchangeability)_을 암시적으로 가정합니다: 우리가 사용하는 전부는 p-값뿐입니다. 이들 외에 어떠한 추가 정보도 고려하지 않습니다. 이것이 항상 최적인 것은 아니며, 여기서는 이를 개선하는 방법들을 공부할 것입니다.

예를 들어봅시다. 직관적으로, 더 많은 수의 리드(reads)가 매핑된 유전자의 신호 대 잡음비(signal-to-noise ratio)는 리드가 적은 유전자보다 더 좋을 것이며, 이는 우리 검정의 검정력에 영향을 줄 것입니다. 관측치 전반에 걸친 정규화된 카운트의 평균을 살펴봅시다. **[DESeq2](https://bioconductor.org/packages/DESeq2/)** 패키지에서 이 수치는 `baseMean`이라 불립니다.

    
    
    awde$baseMean[1]__
    
    
    [1] 708.6022
    
    
    cts = counts(aw, normalized = TRUE)[1, ]
    cts __
    
    
    SRR1039508 SRR1039509 SRR1039512 SRR1039513 SRR1039516 SRR1039517 SRR1039520 
      663.3142   499.9070   740.1528   608.9063   966.3137   748.3722   836.2487 
    SRR1039521 
      605.6024 
    
    
    mean(cts)__
    
    
    [1] 708.6022

다음으로 유전자 전체에 대한 이 수치의 히스토그램을 생성하고, p-값에 대해 플롯합니다(그림 6.18 및 6.19).

    
    
    ggplot(awde, aes(x = asinh(baseMean))) +
      geom_histogram(bins = 60)__

[![](06-chap_files/figure-html/fig-testing-basemean-
hist-1.png)](06-chap_files/figure-html/fig-testing-basemean-hist-1.png
"그림 6.18: baseMean의 히스토그램. 0에 가까운 값부터 약 330,000까지 넓은 동적 범위를 포괄하고 있음을 알 수 있습니다.")

그림 6.18: `baseMean`의 히스토그램. 0에 가까운 값부터 약 330,000까지 넓은 동적 범위를 포괄하고 있음을 알 수 있습니다.

    
    
    ggplot(awde, aes(x = rank(baseMean), y = -log10(pvalue))) +
      geom_hex(bins = 60) +
      theme(legend.position = "none")__

[![](06-chap_files/figure-html/fig-testing-basemean-
scp-1.png)](06-chap_files/figure-html/fig-testing-basemean-scp-1.png
"그림 6.19: baseMean의 순위(rank) 대 p-값의 상용로그 역수(negative logarithm)의 산점도. baseMean 값이 작을 때는 작은 p-값이 나타나지 않습니다. 모든 관측치에 걸친 리드 카운트가 일정 크기 이상인 유전자에 대해서만 차등 발현 검정이 작은 p-값을 내놓을 수 있는 검정력을 갖습니다.")

그림 6.19: `baseMean`의 순위(rank) 대 p-값의 상용로그 역수(negative logarithm)의 산점도. `baseMean` 값이 작을 때는 작은 p-값이 나타나지 않습니다. 모든 관측치에 걸친 리드 카운트가 일정 크기 이상인 유전자에 대해서만 차등 발현 검정이 작은 p-값을 내놓을 수 있는 검정력을 갖습니다.

__

질문 6.21

히스토그램에 왜 \\(\text{asinh}\\) 변환을 사용했을까요? 변환을 하지 않았을 때, 로그 변환을 했을 때, 이동된 로그 변환(즉, \\(\log(x+\text{const.})\\))을 했을 때는 어떤 모습일까요?

__

질문 6.22

산점도에서 왜 p-값에 \\(-\log_{10}\\)을 사용했을까요? `baseMean`에는 왜 순위 변환을 사용했을까요?

편의상, 우리는 `baseMean`을 동일한 크기의 6개 그룹에 해당하는 요인 변수 `group`으로 이산화(discretize)합니다.

    
    
    awde = mutate(awde, stratum = cut(baseMean, include.lowest = TRUE,
      breaks = signif(quantile(baseMean,probs=seq(0,1,length.out=7)),2)))__

그림 6.20과 6.21에서 우리는 `stratum`별로 계층화된 p-값의 히스토그램과 ECDF를 봅니다.

    
    
    ggplot(awde, aes(x = pvalue)) + facet_wrap( ~ stratum, nrow = 4) +
      geom_histogram(binwidth = 0.025, boundary = 0)__

[![](06-chap_files/figure-html/fig-testing-awde-stratified-
hist-1.png)](06-chap_files/figure-html/fig-testing-awde-stratified-hist-1.png
"Figure 6.20: p-value histograms of the airway data, stratified into equally
sized groups defined by increasing value of baseMean.")

Figure 6.20: p-value histograms of the airway data, stratified into equally
sized groups defined by increasing value of `baseMean`.

    
    
    ggplot(awde, aes(x = pvalue, col = stratum)) +
      stat_ecdf(geom = "step") + theme(legend.position = "bottom")__

[![](06-chap_files/figure-html/fig-testing-awde-stratified-
ecdf-1.png)](06-chap_files/figure-html/fig-testing-awde-stratified-ecdf-1.png
"Figure 6.21: Same data as in Figure fig-testing-awde-stratified-hist, shown
with ECDFs.")

Figure 6.21: Same data as in Figure 6.20, shown with ECDFs.

이러한 계층(strata)들에 대해 두 그룹 모델을 따로 적합시킨다면, \\(\pi_0\\)와 \\(f_{\text{alt}}\\).에 대해 상당히 다른 추정치를 얻게 될 것입니다. 가장 낮게 발현된 유전자들의 경우 **[DESeq2](https://bioconductor.org/packages/DESeq2/)** 검정의 검정력이 낮으며, p-값들은 본질적으로 모두 귀무(null) 성분에서 나옵니다. 평균 발현량이 높아질수록 히스토그램에서 작은 p-값 정점의 높이가 높아지는데, 이는 검정의 검정력이 증가함을 반영합니다.

이를 다중 검정 처리를 개선하는 데 사용할 수 있을까요? 그것이 가능하다는 것이 밝혀졌습니다. 한 가지 접근 방식은 **독립 가설 가중치 부여(independent hypothesis weighting, IHW)**입니다 ([Ignatiadis et al. 2016](16-chap.html#ref-Ignatiadis:2016); [Ignatiadis and Huber 2021](16-chap.html#ref-Ignatiadis:JRSSB:2021))22.

22 이 외에도 여러 접근 방식이 있습니다. 예를 들어 Korthauer 등 ([2019](16-chap.html#ref-Korthauer:GB:2019))의 벤치마크 연구나 Ignatiadis와 Huber ([2021](16-chap.html#ref-Ignatiadis:JRSSB:2021)) 논문의 인용 문헌들을 참조하십시오.

    
    
    library("IHW")
    ihw_res = ihw(awde$pvalue, awde$baseMean, alpha = 0.1)
    rejections(ihw_res)__
    
    
    [1] 4892

이를 일반적인 (가중치를 부여하지 않은) 벤자미니-호크버그 방법과 비교해 봅시다:

    
    
    padj_BH = p.adjust(awde$pvalue, method = "BH")
    sum(padj_BH < 0.1)__
    
    
    [1] 4099

가설 가중치를 사용하면 더 많은 기각(rejections)을 얻습니다. 이 데이터의 경우 차이가 두드러지긴 하지만 극적이진 않은데, 이는 이미 신호 대 잡음비가 꽤 높기 때문입니다. 처음부터 검정력이 낮은 다른 상황(예: 반복 수가 적거나, 데이터에 노이즈가 더 많거나, 처리 효과가 덜 급격한 경우)에서는 IHW를 사용하는 효과가 더 뚜렷할 수 있습니다.

`ihw` 함수에 의해 결정된 가중치들을 살펴볼 수 있습니다(그림 6.22).

    
    
    plot(ihw_res)__

[![](06-chap_files/figure-html/fig-testing-
ihwplot-1.png)](06-chap_files/figure-html/fig-testing-ihwplot-1.png
"그림 6.22: ihw 함수에 의해 결정된 가설 가중치. 여기서 함수의 기본 설정은 22개의 계층(strata)을 선택한 반면, 위에서의 수동 탐색(그림 6.20, 6.21)에서는 6개를 사용했습니다. 실제로는 이는 사소한 세부 사항입니다.")

그림 6.22: `ihw` 함수에 의해 결정된 가설 가중치. 여기서 함수의 기본 설정은 22개의 계층(strata)을 선택한 반면, 위에서의 수동 탐색(그림 6.20, 6.21)에서는 6개를 사용했습니다. 실제로는 이는 사소한 세부 사항입니다.

직관적으로 여기서 일어나는 일은, IHW가 `baseMean`이 높은 가설 계층에 더 많은 가중치를 부여하고, 카운트가 매우 낮은 계층에는 낮은 가중치를 부여하기로 선택한 것입니다. 벤자미니-호크버그 방법은 특정한 제1종 오류 예산을 가지고 있는데, 이를 모든 가설에 똑같이 분배하는 대신, 여기서는 어차피 작은 fdr을 가질 가능성이 거의 없는 계층에서 예산을 가져와 많은 가설이 작은 fdr에서 기각될 수 있는 계층에 "투자"하는 것입니다.

__

질문 6.23

왜 그림 6.22는 하나의 곡선이 아니라 5개의 곡선을 보여주나요?

p-값 외에 추가적인 요약 통계량(우리의 경우 `baseMean`)에 의한 계층화 가능성은 많은 다중 검정 상황에서 존재합니다. 비공식적으로 말하자면, 우리는 그러한 이른바 _공변량(covariate)_이 다음과 같아야 합니다:

  * 귀무 가설하에서 우리의 p-값과 통계적으로 독립적이어야 하지만,

  * 두 그룹 모델에서 사전 확률 \\(\pi_0\\) 및/또는 검정력(대립 가설 밀도 \\(f_{\text{alt}}\\)의 형태)에 대한 정보를 제공해야 합니다.

이러한 요구 사항은 그림 6.18—6.21과 같은 진단 플롯을 통해 평가할 수 있습니다.

## 6.12 이 장의 요약

우리는 _단일 가설 검정_ 이면의 개념들을 탐구한 다음 _다중 검정_으로 넘어갔습니다. 우리는 수많은 검정으로부터 나온 결과의 전체 분포를 고려할 수 있게 되면 단일 검정에서 얻은 단일 p-값을 해석할 때의 몇 가지 한계들을 어떻게 극복할 수 있는지 보았습니다. 또한 p-값 외에도 우리 데이터에 종종 추가적인 요약 통계량이 있다는 것도 보았습니다. 우리는 이를 정보성 공변량(informative covariates)이라 불렀으며, 이를 사용하여 p-값에 가중치를 부여하고 전반적으로 더 많거나 더 나은 발견을 얻는 방법을 살펴보았습니다.

_다중 검정_ 시나리오에서의 가설 검정 사용은 _단일 검정_ 사례와는 상당히 다릅니다: 후자의 경우, 가설 검정은 말 그대로 (이상적으로는 사전에 지정된 가설과 데이터 분석 계획을 가진) 길고 비용이 많이 드는 데이터 획득 캠페인의 최종 결과이자 정점일 수 있습니다. 다중 검정의 경우, 그 결과는 종종 중간 단계일 뿐입니다: 방대한 초기 집합을 스크리닝하여 선택된, 가장 가치 있는 가설들의 하위 집합입니다. 이 하위 집합은 이후 더 세심한 분석을 통해 후속 연구가 진행됩니다.

우리는 _허위 발견율_(FDR)의 개념을 보았습니다. 이것이 선택된 가설들의 하위 집합에 대한 평균적인 속성이라는 점을 명심하는 것이 중요합니다. 다른 평균들과 마찬가지로, 개별 가설에 대해서는 아무것도 말해주지 않습니다. 그리고 개별 가설에 실제로 적용되는 _국소 허위 발견율_(fdr)이라는 개념이 있습니다. 그러나 두 그룹 모델이 보여주었듯이, 국소 허위 발견율은 p-값과는 상당히 무관합니다. p-값에 대한 많은 혼란과 좌절은 사람들이 fdr이 담당하는 목적을 위해 p-값을 사용하고 싶어 한다는 사실에서 비롯되는 것 같습니다. 응용 과학의 아주 많은 부분이 국소 허위 발견율이 아닌 p-값에 집중하고 있다는 것은 아마도 역사적 일탈일지 모릅니다. 반면에 실무적인 이유도 있는데, p-값은 즉시 계산되는 반면, fdr은 강력한 모델링 가정 없이는 데이터로부터 추정하거나 제어하기 어렵기 때문입니다.

우리는 진단 플롯의 중요성을 확인했습니다. 특히 다중 검정 분석을 마주할 때는 항상 p-값 히스토그램을 살펴보아야 합니다.

## 6.13 더 읽을거리

  * 다중 검정에 대한 포괄적인 교과서적 처리는 Efron ([2010](16-chap.html#ref-Efron2010))에 의해 제공됩니다.

  * 임상 시험에서의 결과 전환(Outcome switching): <http://compare-trials.org>

  * 가설 가중치에 대해서는 **[IHW](https://bioconductor.org/packages/IHW/)** 비네트, IHW 논문 ([Ignatiadis et al. 2016](16-chap.html#ref-Ignatiadis:2016)) 및 그 안의 참고 문헌들을 참조하십시오.

## 6.14 연습 문제

__

연습 문제 6.1

여러분의 과학적 전문 분야에서 다중 검정에 의존하는 응용 사례를 하나 찾아보십시오. 전형적인 데이터 세트를 찾아 p-값 히스토그램을 그려보세요. 가설들이 모두 교환 가능한가요, 아니면 하나 이상의 정보성 공변량이 있나요? 계층화된 히스토그램을 그려보세요.

__

연습 문제

수리 통계학자들은 대립 가설에 비해 왜 검정의 귀무 가설에 그렇게 많이 집중할까요?

__

연습 문제 6.2

우리는 어떻게 귀무 가설이 참임을 증명할 수 있을까요? 아니면 대립 가설이 참임을요?

__

연습 문제 6.3

6.5절 끝부분의 데이터 복제보다 덜 극단적인 상관된 검정 통계량의 예를 만들어 보세요. 오직 참인 귀무 가설들로만 데이터를 시뮬레이션하고, 어떤 연속형 제어 매개변수의 함수로서 데이터가 완전히 독립적인 반복(열)에서 고도로 상관된 상태로 변하도록 만드십시오. 이 제어 매개변수의 함수로서 (예를 들어 p-값 히스토그램을 통해) 제1종 오류 제어를 확인해 보세요.

__

연습 문제 6.4

발표된 문헌 중에서 p-값 해킹, 결과 전환, HARKing이 작용한 것처럼 보이는 사례를 하나 찾아보십시오.

__

연습 문제 6.5

FDR은 기대값(expectation value)입니다. 즉, 절차의 평균적인 거동을 제어하고 싶을 때 사용됩니다. 최악의 경우(worst case)를 제어하기 위한 방법들이 있을까요?

__

연습 문제 6.6

벤자미니-호크버그 알고리즘의 메모리 및 시간 복잡도는 얼마인가요? IHW 방법은 어떤가요? 검정의 수 \\(m\\)의 함수로서 다항 함수를 적합시킬 수 있나요? 힌트: 가설 검정의 수를 늘려가며 데이터를 시뮬레이션하고, `pryr::object_size`나 동명의 패키지에 있는 `microbenchmark`와 같은 함수를 사용하여 시간 및 메모리 소비를 측정하고, 이들을 이중 로그 플롯(double-logarithmic plot)에서 \\(m\\)에 대해 플롯해 보세요.

Altman, Naomi, and Martin Krzywinski. 2017. “Points of Significance:
Interpreting p Values.” _Nature Methods_ 14 (3): 213–14.
<https://doi.org/10.1038/nmeth.4210>.

Benjamini, Yoav, and Yosef Hochberg. 1995. “Controlling the False Discovery
Rate: A Practical and Powerful Approach to Multiple Testing.” _Journal of the
Royal Statistical Society B_ 57: 289–300.

Efron, Bradley. 2010. _Large-Scale Inference: Empirical Bayes Methods for
Estimation, Testing, and Prediction_. Cambridge University Press.

Head, Megan L, Luke Holman, Rob Lanfear, Andrew T Kahn, and Michael D
Jennions. 2015. “The Extent and Consequences of p-Hacking in Science.” _PLoS
Biology_ 13 (3): e1002106.

Ignatiadis, Nikolaos, and Wolfgang Huber. 2021. “Covariate Powered Cross-
Weighted Multiple Testing.” _Journal of the Royal Statistical Society: Series
B_ 83: 720–51. <https://doi.org/10.1111/rssb.12411>.

Ignatiadis, Nikolaos, Bernd Klaus, Judith Zaugg, and Wolfgang Huber. 2016.
“Data-Driven Hypothesis Weighting Increases Detection Power in Genome-Scale
Multiple Testing.” _Nature Methods_ 13: 577–80.

Korthauer, K., P. K. Kimes, C. Duvallet, A. Reyes, A. Subramanian, M. Teng, C.
Shukla, E. J. Alm, and S. C. Hicks. 2019. “A practical guide to methods
controlling false discoveries in computational biology.” _Genome Biology_ 20
(1): 118.

Schweder, T., and E. Spjøtvoll. 1982. “Plots of P-values to Evaluate Many
Tests Simultaneously.” _Biometrika_ 69: 493–502.
<https://doi.org/10.1093/biomet/69.3.493>.

Storey, John D. 2003. “The Positive False Discovery Rate: A Bayesian
Interpretation and the q-Value.” _The Annals of Statistics_ 31 (6).
<https://doi.org/10.1214/aos/1074290335>.

Wasserstein, Ronald L, and Nicole A Lazar. 2016. “The ASA’s Statement on
p-Values: Context, Process, and Purpose.” _The American Statistician_.

Page built at 01:33 on 2025-09-01 using R version 4.5.1 (2025-06-13)

